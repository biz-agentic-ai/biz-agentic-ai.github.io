## ë¶€ë¡ G: ìœ í†µ/ë¬¼ë¥˜ í‘œì¤€ ì˜¨í†¨ë¡œì§€ Seed ì˜ˆì‹œ (GS1/GoodRelations)

### G.1 DataHub Glossary YAML ì˜ˆì‹œ (GS1/GoodRelations í•µì‹¬ í´ë˜ìŠ¤)

```yaml
version: 1
source: DataNexus_GS1_Importer
owners:
  - "urn:li:corpuser:admin"

nodes:
  - name: "GS1_Core"
    display_name: "GS1 ìœ í†µ í‘œì¤€ ì˜¨í†¨ë¡œì§€"
    description: "GS1 Web Vocabulary ë° GoodRelations ê¸°ë°˜ì˜ ìœ í†µ/ë¬¼ë¥˜ í‘œì¤€ ìš©ì–´ì§‘"
    knowledge_links:
      - label: "GS1 Web Vocab"
        url: "https://www.gs1.org/voc/"

terms:
  - name: "GS1_Product"
    display_name: "ìƒí’ˆ (Product)"
    parentNode: "GS1_Core"
    description: "íŒë§¤ ë˜ëŠ” ë°°ì†¡ì„ ìœ„í•´ ì œê³µë˜ëŠ” ë¬¼ë¦¬ì  ì œí’ˆ ë˜ëŠ” ì„œë¹„ìŠ¤. (ì°¸ì¡°: gs1:Product)"
    customProperties:
      synonyms: "['ì œí’ˆ', 'ë¬¼í’ˆ', 'Item', 'Merchandise', 'Goods']"
      skos_concept: "gs1:Product"
      source_affinity: "í•˜ì´ë¸Œë¦¬ë“œ"
      domain: "Retail"

  - name: "GS1_GTIN"
    display_name: "êµ­ì œ ê±°ë˜ ë‹¨í’ˆ ì‹ë³„ ì½”ë“œ (GTIN)"
    parentNode: "GS1_Core"
    description: "ìƒí’ˆì„ ê³ ìœ í•˜ê²Œ ì‹ë³„í•˜ëŠ” 13ìë¦¬ ë˜ëŠ” 14ìë¦¬ ì½”ë“œ. (ì°¸ì¡°: gs1:gtin)"
    customProperties:
      synonyms: "['ë°”ì½”ë“œ', 'ìƒí’ˆì½”ë“œ', 'EAN', 'UPC']"
      skos_concept: "gs1:gtin"
      relation_type: "identifierOf"  # GTINì€ Productì˜ ì‹ë³„ì
    relatedTerms:
      - "GS1_Product"  # HasA/identifierOf ê´€ê³„ (IsAê°€ ì•„ë‹˜ - GTINì€ Productì˜ ì¢…ë¥˜ê°€ ì•„ë‹ˆë¼ ì‹ë³„ìì„)

  - name: "GR_Offering"
    display_name: "íŒë§¤ ì œì•ˆ (Offering)"
    parentNode: "GS1_Core"
    description: "íŠ¹ì • ìƒí’ˆì„ íŠ¹ì • ê°€ê²©ê³¼ ì¡°ê±´ìœ¼ë¡œ íŒë§¤í•˜ê² ë‹¤ëŠ” ì œì•ˆ. (ì°¸ì¡°: gr:Offering)"
    customProperties:
      synonyms: "['ë”œ', 'ì˜¤í¼', 'Sales Offer', 'í”„ë¡œëª¨ì…˜']"
      skos_concept: "gr:Offering"
    relatedTerms:
      - "GS1_Product"
```

### G.2 DataHub Ingestion Recipe ì˜ˆì‹œ

```yaml
source:
  type: "datahub-business-glossary"
  config:
    file: "./gs1_ontology.yaml"
    enable_patch: true

sink:
  type: "datahub-rest"
  config:
    server: "http://localhost:8080"
    token: "${DATAHUB_ACCESS_TOKEN}"
```

```bash
datahub ingest -c ingestion_recipe.yaml
```

### G.3 CQ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë§¤íŠ¸ë¦­ìŠ¤ (Seed ê²€ì¦)

| CQ ìœ í˜• | ìì—°ì–´ ì§ˆë¬¸ | ê²€ì¦ ëŒ€ìƒ ì˜¨í†¨ë¡œì§€ ê²½ë¡œ | ì„±ê³µ ê¸°ì¤€ |
| :--- | :--- | :--- | :--- |
| FCQ | íŠ¹ì • ìƒí’ˆì˜ ë°”ì½”ë“œ(GTIN) ì •ë³´ê°€ ì •ì˜ë˜ì–´ ìˆëŠ”ê°€? | `GS1_Product` â†’ `GS1_GTIN` | GTIN ìš©ì–´ ì¡´ì¬ ë° Productì™€ ì—°ê²° |
| RCQ | íŒë§¤ ì œì•ˆ(Offering)ì—ëŠ” ì–´ë–¤ ìƒí’ˆì´ í¬í•¨ë˜ëŠ”ê°€? | `GR_Offering` â†’ `GS1_Product` | Offering ì¡°íšŒ ì‹œ Product ì—°ê²° í™•ì¸ |
| VCQ | â€˜ì˜¤í¼â€™ë¡œ ê²€ìƒ‰í•´ë„ â€˜íŒë§¤ ì œì•ˆâ€™ì„ ì°¾ì„ ìˆ˜ ìˆëŠ”ê°€? | `GR_Offering.customProperties.synonyms` | ë™ì˜ì–´ ë§¤ì¹­ìœ¼ë¡œ Offering ê²€ìƒ‰ ê°€ëŠ¥ |
| SCQ | ì´ ì˜¨í†¨ë¡œì§€ëŠ” ì „ììƒê±°ë˜/ë¦¬í…Œì¼ì„ ë‹¤ë£¨ëŠ”ê°€? | `GS1_Product.customProperties.domain` | domain ê°’ì´ Retail/E-commerce |

### G.4 CQ ê²€ì¦ ìë™í™” ì½”ë“œ (Pytest ì˜ˆì‹œ)

```python
import pytest
import yaml

@pytest.fixture
def ontology():
    with open("gs1_ontology.yaml", "r", encoding="utf-8") as f:
        return yaml.safe_load(f)

def test_fcq_gtin_exists(ontology):
    """GTIN ìš©ì–´ ì¡´ì¬ ë° Productì™€ì˜ ì‹ë³„ì ê´€ê³„ ê²€ì¦"""
    terms = ontology["terms"]
    gtin = next((t for t in terms if t["name"] == "GS1_GTIN"), None)
    assert gtin is not None, "GS1_GTIN ìš©ì–´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
    # GTINì€ Productì˜ ì‹ë³„ìì´ë¯€ë¡œ relatedTermsë¡œ ì—°ê²°ë¨ (IsAê°€ ì•„ë‹˜)
    assert "GS1_Product" in gtin.get("relatedTerms", []), "GTINì´ Productì™€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

def test_vcq_synonym_resolution(ontology):
    target_query = "ì˜¤í¼"
    terms = ontology["terms"]
    found = None
    for term in terms:
        synonyms = term.get("customProperties", {}).get("synonyms", "")
        if isinstance(synonyms, str) and target_query in synonyms:
            found = term["name"]
            break
    assert found == "GR_Offering", f"'{target_query}' ê²€ìƒ‰ ì‹œ GR_Offeringì´ ë§¤í•‘ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."

def test_rcq_offering_has_product(ontology):
    terms = ontology["terms"]
    offering = next((t for t in terms if t["name"] == "GR_Offering"), None)
    assert offering is not None, "GR_Offering ìš©ì–´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
    assert "GS1_Product" in offering.get("relatedTerms", []), "Offering-Product ê´€ê³„ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
```

---

## ë¶€ë¡ H: SEOCHO CLI Reference

SEOCHO í”„ë¡œì íŠ¸(`feature-kgbuild` ë¸Œëœì¹˜)ì—ì„œ ì œê³µí•˜ëŠ” CLI ë„êµ¬ ëª…ì„¸ì…ë‹ˆë‹¤.

### H.1 ì¸ë±ì‹± CLI (Indexing)

ë°ì´í„° ì†ŒìŠ¤ë¥¼ ë²¡í„° ì¸ë±ìŠ¤ì™€ ê·¸ë˜í”„ ë°ì´í„°ë² ì´ìŠ¤ì— ì ì¬í•©ë‹ˆë‹¤.

```bash
# ì „ì²´ ì¸ë±ìŠ¤ ë¹Œë“œ
docker exec agent-jupyter-container python -m src.cli.index --all

# ë²¡í„° ì¸ë±ìŠ¤ë§Œ ë¹Œë“œ (LanceDB/FAISS)
docker exec agent-jupyter-container python -m src.cli.index --lancedb

# ê·¸ë˜í”„ ì¸ë±ìŠ¤ë§Œ ë¹Œë“œ (Neo4j)
docker exec agent-jupyter-container python -m src.cli.index --neo4j
```

**ëª…ë ¹ì–´ ì˜µì…˜:**

| ì˜µì…˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `--all` | ëª¨ë“  ì¸ë±ìŠ¤ ë¹Œë“œ (LanceDB + Neo4j) | - |
| `--lancedb` | ë²¡í„° ì¸ë±ìŠ¤ë§Œ ë¹Œë“œ | - |
| `--neo4j` | ê·¸ë˜í”„ ì¸ë±ìŠ¤ë§Œ ë¹Œë“œ | - |
| `--source` | ë°ì´í„° ì†ŒìŠ¤ ê²½ë¡œ | `/workspace/data/` |
| `--config` | ì„¤ì • íŒŒì¼ ê²½ë¡œ | `config.yaml` |
| `--force` | ê¸°ì¡´ ì¸ë±ìŠ¤ ë®ì–´ì“°ê¸° | `false` |

**í™˜ê²½ ë³€ìˆ˜:**

```bash
# í•„ìˆ˜
OPENAI_API_KEY=sk-...

# ë°ì´í„°ë² ì´ìŠ¤ (Docker í™˜ê²½ ê¸°ë³¸ê°’)
NEO4J_URI=bolt://graphrag-neo4j:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_password
LANCEDB_PATH=/workspace/data/lancedb
```

### H.2 í‰ê°€ CLI (Evaluation)

Macro/Ablation ì‹¤í—˜ ë° ë©”íŠ¸ë¦­ ì¸¡ì •ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

```bash
# Macro ì‹¤í—˜ ì‹¤í–‰ (M1~M4)
docker exec agent-jupyter-container python -m src.cli.evaluate --macro

# Ablation ì‹¤í—˜ ì‹¤í–‰ (A1~A6)
docker exec agent-jupyter-container python -m src.cli.evaluate --ablation

# íŠ¹ì • ëª¨ë“œë§Œ ì‹¤í–‰
docker exec agent-jupyter-container python -m src.cli.evaluate --modes lpg,hybrid

# ì „ì²´ ì‹¤í—˜ ì‹¤í–‰
docker exec agent-jupyter-container python -m src.cli.evaluate --all
```

**ëª…ë ¹ì–´ ì˜µì…˜:**

| ì˜µì…˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `--macro` | Macro ì‹¤í—˜ (M1~M4) ì‹¤í–‰ | - |
| `--ablation` | Ablation ì‹¤í—˜ (A1~A6) ì‹¤í–‰ | - |
| `--modes` | íŠ¹ì • ê²€ìƒ‰ ëª¨ë“œ ì¡°í•© (ì½¤ë§ˆ êµ¬ë¶„) | `lpg,rdf,hybrid` |
| `--all` | ëª¨ë“  ì‹¤í—˜ ì‹¤í–‰ | - |
| `--dataset` | í‰ê°€ ë°ì´í„°ì…‹ ê²½ë¡œ | `datasets/eval.json` |
| `--output` | ê²°ê³¼ ì¶œë ¥ ê²½ë¡œ | `results/` |
| `--verbose` | ìƒì„¸ ë¡œê¹… | `false` |

**ì‹¤í—˜ ì„¤ì • íŒŒì¼ ì˜ˆì‹œ (`config/experiments.yaml`):**

```yaml
macro_experiments:
  M1:
    components: [lpg, rdf, hybrid]
    agent_type: hierarchical
  M2:
    components: [lpg, rdf, hybrid]
    agent_type: single
  M3:
    components: [lpg, hybrid]
    agent_type: hierarchical
  M4:
    components: [rdf, hybrid]
    agent_type: hierarchical

ablation_experiments:
  A1: [lpg]
  A2: [rdf]
  A3: [hybrid]
  A4: [lpg, rdf]
  A5: [lpg, hybrid]
  A6: [rdf, hybrid]

metrics:
  - answer_relevance
  - hallucination
  - routing_accuracy
  - context_precision
  - conflict_resolution_score

thresholds:
  routing_accuracy: 0.95
  conflict_resolution_score: 0.95
  hallucination_rate: 0.05
```

### H.3 ë°ì´í„° Export CLI

Opik íŠ¸ë ˆì´ìŠ¤ ë° ë°ì´í„°ì…‹ì„ Exportí•©ë‹ˆë‹¤.

```bash
# íŠ¸ë ˆì´ìŠ¤ Export
docker exec agent-jupyter-container python -m src.cli.export --traces

# ë°ì´í„°ì…‹ Export
docker exec agent-jupyter-container python -m src.cli.export --datasets

# íŠ¹ì • ê¸°ê°„ íŠ¸ë ˆì´ìŠ¤ Export
docker exec agent-jupyter-container python -m src.cli.export --traces \
    --start-date 2026-01-01 \
    --end-date 2026-01-31
```

**ëª…ë ¹ì–´ ì˜µì…˜:**

| ì˜µì…˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `--traces` | Opik íŠ¸ë ˆì´ìŠ¤ Export | - |
| `--datasets` | ëª¨ë“  ë°ì´í„°ì…‹ Export | - |
| `--output` | ì¶œë ¥ ë””ë ‰í† ë¦¬ | `exports/` |
| `--format` | ì¶œë ¥ í˜•ì‹ (`json`, `csv`, `parquet`) | `json` |
| `--start-date` | ì‹œì‘ ì¼ì (YYYY-MM-DD) | - |
| `--end-date` | ì¢…ë£Œ ì¼ì (YYYY-MM-DD) | - |

### H.4 Docker í™˜ê²½ ì„¤ì •

SEOCHO ì»¨í…Œì´ë„ˆ í™˜ê²½ êµ¬ì„±ì„ ìœ„í•œ ëª…ë ¹ì–´ì…ë‹ˆë‹¤.

```bash
# ì „ì²´ ìŠ¤íƒ ì‹œì‘
docker-compose up -d --build

# ê°œë³„ ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d neo4j opik

# Neo4j í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜ (APOC, GDS)
./setup_neo4j_plugins.sh

# Opik ì„¤ì •
./setup-docker-and-opik.sh

# ë¡œê·¸ í™•ì¸
docker-compose logs -f agent-service
```

**Docker Compose ì„œë¹„ìŠ¤ êµ¬ì„±:**

| ì„œë¹„ìŠ¤ | í¬íŠ¸ | ì„¤ëª… |
|--------|------|------|
| `graphrag-neo4j` | 7474, 7687 | Neo4j/DozerDB |
| `agent-service` | 8001 | FastAPI Agent Server |
| `agent-studio` | 8501 | Streamlit UI |
| `opik` | 5173 | LLM Observability |
| `lancedb` | - | ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ (Volume) |

### H.5 ê°œë°œ í™˜ê²½ CLI

ë¡œì»¬ ê°œë°œ í™˜ê²½ êµ¬ì„±ì„ ìœ„í•œ ëª…ë ¹ì–´ì…ë‹ˆë‹¤.

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± ë° ì˜ì¡´ì„± ì„¤ì¹˜
./setup.sh

# ë˜ëŠ” ìˆ˜ë™ ì„¤ì¹˜
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/ -v --cov=src

# ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬
make lint

# ì „ì²´ ë¹Œë“œ
make build
```

**Makefile íƒ€ê²Ÿ:**

| íƒ€ê²Ÿ | ì„¤ëª… |
|------|------|
| `make build` | Docker ì´ë¯¸ì§€ ë¹Œë“œ |
| `make up` | ì»¨í…Œì´ë„ˆ ì‹œì‘ |
| `make down` | ì»¨í…Œì´ë„ˆ ì¤‘ì§€ |
| `make test` | í…ŒìŠ¤íŠ¸ ì‹¤í–‰ |
| `make lint` | ì½”ë“œ í’ˆì§ˆ ê²€ì‚¬ |
| `make index` | ì¸ë±ìŠ¤ ë¹Œë“œ |
| `make evaluate` | í‰ê°€ ì‹¤í–‰ |
| `make clean` | ì„ì‹œ íŒŒì¼ ì •ë¦¬ |

### H.6 CLI ì‚¬ìš© ì˜ˆì‹œ (E2E ì›Œí¬í”Œë¡œìš°)

ì „ì²´ í‰ê°€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì˜ˆì‹œ:

```bash
#!/bin/bash
# evaluate_pipeline.sh

set -e

echo "ğŸ”§ Step 1: í™˜ê²½ ì„¤ì •"
docker-compose up -d

echo "ğŸ“Š Step 2: ì¸ë±ìŠ¤ ë¹Œë“œ"
docker exec agent-jupyter-container python -m src.cli.index --all

echo "ğŸ§ª Step 3: Macro ì‹¤í—˜ ì‹¤í–‰"
docker exec agent-jupyter-container python -m src.cli.evaluate --macro \
    --dataset datasets/production_queries.json \
    --output results/macro_$(date +%Y%m%d)/

echo "ğŸ”¬ Step 4: Ablation ì‹¤í—˜ ì‹¤í–‰"
docker exec agent-jupyter-container python -m src.cli.evaluate --ablation \
    --output results/ablation_$(date +%Y%m%d)/

echo "ğŸ“¤ Step 5: ê²°ê³¼ Export"
docker exec agent-jupyter-container python -m src.cli.export --traces \
    --output exports/traces_$(date +%Y%m%d).json

echo "âœ… í‰ê°€ ì™„ë£Œ!"
echo "ê²°ê³¼ í™•ì¸: results/ ë””ë ‰í† ë¦¬"
echo "Opik ëŒ€ì‹œë³´ë“œ: http://localhost:5173"
```

### H.7 CLI ì¶œë ¥ í˜•ì‹

**í‰ê°€ ê²°ê³¼ JSON ìŠ¤í‚¤ë§ˆ:**

```json
{
  "experiment_id": "M1",
  "timestamp": "2026-02-03T10:30:00Z",
  "config": {
    "components": ["lpg", "rdf", "hybrid"],
    "agent_type": "hierarchical"
  },
  "metrics": {
    "answer_relevance": 4.2,
    "hallucination_rate": 0.03,
    "routing_accuracy": 0.92,
    "context_precision": 0.87,
    "conflict_resolution_score": 0.96,
    "execution_accuracy": 0.85,
    "p95_response_time_ms": 1850
  },
  "quality_gates": {
    "routing_accuracy": {"threshold": 0.95, "passed": false},
    "conflict_resolution_score": {"threshold": 0.95, "passed": true},
    "hallucination_rate": {"threshold": 0.05, "passed": true}
  },
  "note": "ì•„ë˜ëŠ” Quality Gate ë¶€ë¶„ ì‹¤íŒ¨ ì˜ˆì‹œì…ë‹ˆë‹¤ (routing_accuracy 0.92 < ì„ê³„ê°’ 0.95):",
  "summary": {
    "total_queries": 500,
    "successful": 485,
    "failed": 15,
    "avg_latency_ms": 1234
  }
}
```

---

**ì°¸ê³ :** ë³¸ CLI ëª…ì„¸ëŠ” SEOCHO í”„ë¡œì íŠ¸ `feature-kgbuild` ë¸Œëœì¹˜ (https://github.com/tteon/seocho/tree/feature-kgbuild) ê¸°ì¤€ì…ë‹ˆë‹¤. ìµœì‹  ë²„ì „ì€ GitHub ë¦¬í¬ì§€í† ë¦¬ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.
