> **ğŸ“‹ ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§ ì£¼ì˜ (ë¦¬ë·° ë³´ê³ ì„œ Â§3-4):**
> 4ë‹¨ê³„ í’ˆì§ˆ ê²Œì´íŠ¸(Unit â†’ Integration â†’ CQ â†’ E2E) ì¤‘ MVPì—ì„œëŠ” **Stage 1(Unit) + Stage 4(E2E)ë§Œ í•„ìˆ˜** ì ìš©í•©ë‹ˆë‹¤. ìƒì„¸ëŠ” Â§5.3 ì°¸ì¡°.

## 5. í‰ê°€ ë° í’ˆì§ˆ ê´€ë¦¬ (Evaluation Strategy)

### 5.1 ì£¼ìš” ì§€í‘œ (Metrics)

> **Phase ë²”ë¡€:** **1** = MVP í•„ìˆ˜, 1â†’2 = MVPì—ì„œ ë„ì… í›„ Phase 2ì—ì„œ ëª©í‘œ ìƒí–¥, 1.5 = Phase 1 ì•ˆì •í™”, 2 = Phase 2 ê³ ë„í™”, 3 = Phase 3 R&D.
>
> **ğŸ“Š SSOT ë¯¸ëŸ¬ë§ (ì •ì‹ ì¶œì²˜: PRD_04a Â§4.8)**
> - **ë‹¨ìœ„ í‘œê¸°:** ëª¨ë“  ë¹„ìœ¨ ì§€í‘œëŠ” ratio(0~1) í˜•ì‹. ì˜ˆ: 0.05 = 5%
> - ìˆ˜ì¹˜ê°€ ìƒì´í•œ ê²½ìš° **Â§4.8 ê¸°ì¤€ì´ ìš°ì„ **í•©ë‹ˆë‹¤.

#### 5.1.1 Phase 1 MVP í•„ìˆ˜ ì§€í‘œ (10ê°œ)

| ì§€í‘œ | ì„¤ëª… | MVP ê¸°ì¤€ | Phase 2 ëª©í‘œ | Phase |
| :--- | :--- | :--- | :--- | :---: |
| **EX (Execution Accuracy)** | ì‹¤í–‰ ê²°ê³¼ê°’ì˜ ì¼ì¹˜ ì—¬ë¶€ | â‰¥ 0.80 (ratio) | â‰¥ 0.90 | **1 â†’ 2** |
| **VES (Valid Efficiency Score)** | ìƒì„±ëœ ì¿¼ë¦¬ì˜ ì‹¤í–‰ íš¨ìœ¨ì„± | P95 < 3ì´ˆ | â€” | **1** |
| **VPA (Validation Pass Rate)** | í’ˆì§ˆ ê²€ì¦ í†µê³¼ìœ¨ | â‰¥ 0.95 (ratio) | â€” | **1** |
| **CQ Pass Rate** | ì í•©ì„± ì§ˆë¬¸ ê²€ì¦ í†µê³¼ìœ¨ | â‰¥ 0.80 (ratio) | â‰¥ 0.95 | **1 â†’ 2** |
| **Schema Compliance** | ìŠ¤í‚¤ë§ˆ ê°•ì œì„± ì¤€ìˆ˜ìœ¨ (ACCEPT+REMAP) | â‰¥ 0.90 (ratio) | â‰¥ 0.95 | **1 â†’ 2** |
| **Deterministic Query Rate** | í…œí”Œë¦¿ ê¸°ë°˜ ê²°ì •ë¡ ì  ì§ˆì˜ ë¹„ìœ¨ | â‰¥ 0.60 (ratio) | â€” | **1** |
| **Query Router Accuracy** | Query Router ì •í™•ë„ | â‰¥ 0.95 (ratio) | â‰¥ 0.97 | **1 â†’ 2** |
| **Tool Guard Activation Rate** | ë„êµ¬ ê²°ê³¼ ê°€ë“œ ë°œë™ ë¹ˆë„ (ë‚®ì„ìˆ˜ë¡ ì–‘í˜¸) | < 0.05 (ratio) | â€” | **1** |
| **Hallucination Rate** | ê·¼ê±° ì—†ëŠ” ì •ë³´ê°€ ì‘ë‹µì— í¬í•¨ëœ ë¹„ìœ¨ (ë‚®ì„ìˆ˜ë¡ ì–‘í˜¸) | â‰¤ 0.05 (ratio) | â‰¤ 0.03 | **1 â†’ 2** |
| **ConflictResolutionScore** | ë‹¤ì¤‘ ì†ŒìŠ¤ ì¶©ëŒ í•´ê²° í’ˆì§ˆ | â‰¥ 0.95 (ratio) | â‰¥ 0.97 | **1 â†’ 2** |
| **Reasoning Accuracy** | ê´€ê³„ ê¸°ë°˜ ì¶”ë¡ ì˜ ì •í™•ë„ | â‰¥ 0.85 (ratio) | â‰¥ 0.90 | **1 â†’ 2** |

#### 5.1.2 Phase 1.5 ì•ˆì •í™” ì§€í‘œ (4ê°œ)

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œ | Phase |
| :--- | :--- | :--- | :---: |
| QVT (Query Variance Testing) | ì§ˆë¬¸ í‘œí˜„ ë³€í™”ì— ëŒ€í•œ ì¼ê´€ì„± ê²€ì¦ | ì¼ê´€ì„± 90% ì´ìƒ | 1.5 |
| Incremental Update Ratio | ì¦ë¶„ ì—…ë°ì´íŠ¸ ì²˜ë¦¬ ë¹„ìœ¨ | 90% ì´ìƒ | 1.5 |
| SKOS Mapping Coverage | SKOS í‘œì¤€ ë§¤í•‘ ì™„ë£Œìœ¨ | 95% ì´ìƒ | 1.5 |
| Draft Acceptance Rate | LLM ì´ˆì•ˆ ìŠ¹ì¸ìœ¨ (ìˆ˜ì • ì—†ì´) | 50% ì´ìƒ | 1.5 |

#### 5.1.3 Phase 2 ê³ ë„í™” ì§€í‘œ (8ê°œ)

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œ | Phase |
| :--- | :--- | :--- | :---: |
| OCA (Ontology Coverage) | ì˜¨í†¨ë¡œì§€ ì •ì˜ ìš©ì–´ì— ëŒ€í•œ ì •í™•ë„ | 90% ì´ìƒ | 2 |
| External KG Mapping Rate | ì™¸ë¶€ ë°ì´í„° ì—”í„°í‹°ì˜ Glossary ë§¤í•‘ë¥  | 50% ì´ìƒ | 2 |
| ToolsRetriever Routing Accuracy | Agentic Retriever ìë™ ì„ íƒ ì •í™•ë„ | 90% ì´ìƒ | 2 |
| Context Preservation Rate | ì»´íŒ©ì…˜ í›„ í•µì‹¬ ì‚¬ì‹¤ ë³´ì¡´ìœ¨ (Â§4.3.10.10) | 90% ì´ìƒ | 2 |
| Cache Hit Rate | LLM í”„ë¦¬í”½ìŠ¤ ìºì‹œ í™œìš©ë¥  (Implementation Strategy Â§22) | 70% ì´ìƒ | 2 |
| **CTE (Context Token Efficiency)** | ë‹µë³€ í’ˆì§ˆ ì ìˆ˜ / ì£¼ì…ëœ ì»¨í…ìŠ¤íŠ¸ í† í° ìˆ˜ (Â§5.4.4.1) | LPG â‰¥ RDF (ë™ì¼ í’ˆì§ˆ ëŒ€ë¹„) | 2 |
| **KVCache Cost per Query** | Ablation ì‹¤í—˜ë³„ í‰ê·  í”„ë¡¬í”„íŠ¸ í† í° ìˆ˜ Ã— API ë‹¨ê°€ (Â§5.4.4.1) | ì „ì›” ëŒ€ë¹„ ê°ì†Œ ì¶”ì„¸ | 2 |
| **Quality-Cost Pareto Score** | ë¹„ìš©-í’ˆì§ˆ íŒŒë ˆí†  ìµœì ì  ëŒ€ë¹„ í˜„ì¬ êµ¬ì„±ì˜ íš¨ìœ¨ì„± (Â§5.4.4.1) | 0.8 ì´ìƒ (1.0 = íŒŒë ˆí†  ìµœì ) | 2 |

> **ğŸ“Œ CTE/KVCache Cost ìš´ì˜ ê°€ì´ë“œ (KGC2026 ì •ì´íƒœ ë°œí‘œ ì¸ì‚¬ì´íŠ¸ ë°˜ì˜):**
> LPGì™€ RDFëŠ” Generation Stageì—ì„œ Agentì—ê²Œ ì œê³µí•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ì˜ í† í° íš¨ìœ¨ì„±ì´ ë‹¤ë¦…ë‹ˆë‹¤. LPGëŠ” êµ¬ì¡°í™”ëœ Cypher ê²°ê³¼ë¡œ compactí•œ ë°˜ë©´, RDF íŠ¸ë¦¬í”Œì€ verboseí•  ìˆ˜ ìˆì–´ ë™ì¼ ì •ë³´ëŸ‰ ëŒ€ë¹„ í† í° ì†Œë¹„ê°€ ìƒì´í•©ë‹ˆë‹¤. ë‹¨ìˆœ 'ì •í™•ë„'ë§Œì´ ì•„ë‹Œ KVCache ì‹¤ë¬´ ê´€ì ì˜ ë¹„ìš© íš¨ìœ¨ì„±ê¹Œì§€ í‰ê°€í•´ì•¼ ìµœì  ì•„í‚¤í…ì²˜ ê²°ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
> - **ì¸¡ì • ë°©ë²•:** Opik Traceì—ì„œ ê° Agent í˜¸ì¶œ ì‹œ `prompt_tokens`, `completion_tokens`, `cache_creation_input_tokens`, `cache_read_input_tokens`ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì‹¤í—˜ë³„ ì§‘ê³„
> - **ë¹„êµ ê¸°ì¤€:** A1(LPG Only) vs A2(RDF Only) vs A4(LPG+RDF) ê°„ CTE ë¹„êµë¡œ ê° ê·¸ë˜í”„ ëª¨ë¸ì˜ í† í° íš¨ìœ¨ì„± ì •ëŸ‰í™”
> - **ìƒì„¸:** Â§5.4.4.1 Context Token Efficiency ë©”íŠ¸ë¦­ ì •ì˜ ì°¸ì¡°

> **ğŸ“Œ Cache Hit Rate ìš´ì˜ ê°€ì´ë“œ (Claude Code íŒ€ êµí›ˆ ì ìš©):**
> Claude Code íŒ€ì€ ìºì‹œ íˆíŠ¸ìœ¨ì„ ê°€ë™ë¥ (uptime)ì²˜ëŸ¼ ëª¨ë‹ˆí„°ë§í•˜ë©°, ì €í•˜ ì‹œ SEVë¥¼ ì„ ì–¸í•©ë‹ˆë‹¤. DataNexusë„ ë™ì¼ ìˆ˜ì¤€ì„ ì ìš©í•©ë‹ˆë‹¤.
> - **â‰¥ 80%**: ì •ìƒ ìš´ì˜ | **70~80%**: ê²½ê³  + Opik ì•Œë¦¼ | **60~70%**: SEV-3 ì¦‰ì‹œ ì›ì¸ ì¡°ì‚¬ | **< 60%**: SEV-2 ê¸´ê¸‰ íŒ¨ì¹˜
> - **ì£¼ìš” ìºì‹œ ë¯¸ìŠ¤ ì›ì¸:** ë„êµ¬ ì •ì˜ ìˆœì„œ ë³€ê²½, ì„¸ì…˜ ì¤‘ ëª¨ë¸ ì „í™˜, ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë‚´ ë™ì  ê°’(íƒ€ì„ìŠ¤íƒ¬í”„ ë“±), ì»´íŒ©ì…˜ ì‹œ ë³„ë„ í”„ë¦¬í”½ìŠ¤ ì‚¬ìš©
> - **ì¸¡ì • ë°©ë²•:** Anthropic API ì‘ë‹µì˜ `cache_creation_input_tokens` vs `cache_read_input_tokens` ë¹„ìœ¨ë¡œ ê³„ì‚°
> - **ìƒì„¸:** Implementation Strategy Â§22.6, PRD_04c Â§4.3.10.10.3.1 ì°¸ì¡°

#### 5.1.4 Phase 3 R&D ì§€í‘œ (12ê°œ)

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œ | Phase |
| :--- | :--- | :--- | :---: |
| Cross-Source Query Rate | ë‚´ë¶€+ì™¸ë¶€ í†µí•© ê²€ìƒ‰ í™œìš© ì§ˆì˜ ë¹„ìœ¨ | 30% ì´ìƒ | 3 |
| Agent Memory Recall@10 | Graphiti ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ê³¼ê±° ì‚¬ì‹¤ íšŒìˆ˜ìœ¨ | 85% ì´ìƒ | 3 |
| Temporal Query Accuracy | ì‹œê°„ ê¸°ë°˜ ì§ˆì˜ (ê³¼ê±° ì‹œì ) ì •í™•ë„ | 90% ì´ìƒ | 3 |
| Episode Ingestion Latency | ì—í”¼ì†Œë“œ ìˆ˜ì§‘â†’ê·¸ë˜í”„ ë°˜ì˜ ì§€ì—° ì‹œê°„ | 5ì´ˆ ì´ë‚´ (ì‹¤ì‹œê°„) | 3 |
| Personalization Hit Rate | ê°œì¸í™” ì»¨í…ìŠ¤íŠ¸ê°€ ì‘ë‹µì— ë°˜ì˜ëœ ë¹„ìœ¨ | 70% ì´ìƒ | 3 |
| Fact Conflict Detection Rate | ì‚¬ì‹¤ ì¶©ëŒ ìë™ íƒì§€ìœ¨ | 95% ì´ìƒ | 3 |
| Community Coherence Score | ìë™ íƒì§€ëœ ì»¤ë®¤ë‹ˆí‹°ì˜ ì˜ë¯¸ì  ì¼ê´€ì„± | 0.8 ì´ìƒ | 3 |
| Memory Flush Success Rate | Graphiti ì—í”¼ì†Œë“œ ì»¤ë°‹ ì„±ê³µë¥  | 99% ì´ìƒ | 3 |
| Compaction Overhead | ì»´íŒ©ì…˜ìœ¼ë¡œ ì¸í•œ ì¶”ê°€ ì§€ì—° ì‹œê°„ | 3ì´ˆ ì´ë‚´ | 3 |
| Dual Memory Dedup Rate | Vannaâ†”Graphiti ê°„ ì¤‘ë³µ ì €ì¥ ë°©ì§€ìœ¨ (Â§4.3.10.10.8) | 95% ì´ìƒ | 3 |
| Vanna-Graphiti Cross Match | Vanna SQL í…Œì´ë¸”ëª… â†” Graphiti ì—”í„°í‹° êµì°¨ ë§¤ì¹­ìœ¨ | 80% ì´ìƒ | 3 |
| Memory Router Accuracy | DualMemoryRouter ì €ì¥ ëŒ€ìƒ ë¶„ë¥˜ ì •í™•ë„ | 90% ì´ìƒ | 3 |

> **ğŸ“Œ Phase 3 ì§€í‘œ ìš´ì˜ ì•ˆë‚´:** ìœ„ 12ê°œ ì§€í‘œëŠ” Phase 3 R&D ë²”ìœ„ì´ë©°, Graphiti/ì—ì´ì „íŠ¸ ë©”ëª¨ë¦¬ ë„ì… ì‹œ ì¸¡ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤. MVP ì‹œì ì—ì„œëŠ” Â§5.1.1(Phase 1 í•„ìˆ˜ 10ê°œ)ì— ì§‘ì¤‘í•˜ì„¸ìš”.

#### 5.1.5 alive-analysis ë©”íŠ¸ë¦­ 4ë‹¨ê³„ ë¶„ë¥˜ ë§¤í•‘ (Phase 1.5+)

> **ğŸ“Œ alive-analysis ì—°ê³„:** alive-analysisì˜ 4ë‹¨ê³„ ë©”íŠ¸ë¦­ ë¶„ë¥˜ ì²´ê³„(North Star â†’ Leading â†’ Guardrail â†’ Diagnostic)ë¥¼ DataNexus í‰ê°€ ì§€í‘œì— ë§¤í•‘í•©ë‹ˆë‹¤. ì´ ë¶„ë¥˜ëŠ” ì‚¬ìš©ìê°€ ë¶„ì„ ì›Œí¬í”Œë¡œìš° ë‚´ì—ì„œ ë©”íŠ¸ë¦­ì„ ê³„ì¸µì ìœ¼ë¡œ ì´í•´í•˜ê³  ëª¨ë‹ˆí„°ë§í•˜ê¸° ìœ„í•œ ìš´ì˜ ë ˆì´ì–´ì´ë©°, Â§4.8 SSOT ì§€í‘œì˜ ì •ì˜ ìì²´ë¥¼ ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
> - **ìƒì„¸:** PRD_02 Â§3.11.4, Implementation Strategy Â§23.4 ì°¸ì¡°

| alive-analysis ê³„ì¸µ | ì—­í•  | DataNexus ëŒ€ì‘ ì§€í‘œ | ëª¨ë‹ˆí„°ë§ ì£¼ê¸° | ì—ìŠ¤ì»¬ë ˆì´ì…˜ |
|---------------------|------|-------------------|-------------|------------|
| **North Star** | ìµœì¢… ì‚¬ìš©ì ê°€ì¹˜ ëŒ€ë¦¬ | EX (Execution Accuracy) | Daily | í•˜ë½ ì¶”ì„¸ 3ì¼ ì—°ì† â†’ Leading ìë™ ë“œë¦´ë‹¤ìš´ |
| **Leading** | í’ˆì§ˆ ì„ í–‰ ì§€í‘œ | Query Router Accuracy, CQ Pass Rate, Schema Compliance | Per deployment | ê¸°ì¤€ ë¯¸ë‹¬ â†’ Diagnostic ì„¸ë¶€ ë¶„ì„ íŠ¸ë¦¬ê±° |
| **Guardrail** | ì•ˆì „ í•œê³„ì„  (ì ˆëŒ€ ìœ„ë°˜ ë¶ˆê°€) | Hallucination Rate â‰¤ 0.05 (ratio), Cache Hit Rate â‰¥ 0.70 (ratio) | Continuous | 2íšŒ ì—°ì† ìœ„ë°˜ â†’ ìë™ ì•Œë¦¼ + Opik í•˜ì´ë¼ì´íŠ¸ |
| **Diagnostic** | ì›ì¸ ë¶„ì„ìš© ì„¸ë¶€ | CTE, KVCache Cost, VES, Deterministic Query Rate | Weekly | ì´ìƒ ê°ì§€ â†’ ê·¼ë³¸ ì›ì¸ ë¶„ì„ (ALIVE ë£¨í”„ Investigation) |

### 5.2 ì˜¤ë¥˜ ë¶„ì„ (Error Taxonomy)
- Schema Linking ì‹¤íŒ¨
- JOIN ì˜¤ë¥˜
- Nested Query ì˜¤ë¥˜
- ì§‘ê³„ í•¨ìˆ˜(Aggregation) ì˜¤ë¥˜
- ì˜¨í†¨ë¡œì§€ ë¯¸ë§¤í•‘ ì˜¤ë¥˜
- Entity Resolution ì˜¤ë¥˜: ë¬¸ì„œ ì—”í‹°í‹°ì™€ Glossary Term ë§¤ì¹­ ì‹¤íŒ¨
- **ê´€ê³„ ëª¨í˜¸ì„± ì˜¤ë¥˜:** ì„¸ë¶„í™”ë˜ì§€ ì•Šì€ ê´€ê³„ë¡œ ì¸í•œ Multi-hop ì¶”ë¡  ì‹¤íŒ¨
- **ìŠ¤í‚¤ë§ˆ ë¶ˆì¼ì¹˜ ì˜¤ë¥˜:** ë¹„í‘œì¤€ ì—”í‹°í‹° ì¶”ì¶œë¡œ ì¸í•œ ê·¸ë˜í”„ ì˜¤ì—¼
- **ë¼ìš°íŒ… ì˜¤ë¥˜:** ì§ˆì˜ ìœ í˜• ì˜¤ë¶„ë¥˜ë¡œ ì¸í•œ ë¶€ì ì ˆí•œ ì²˜ë¦¬
- **í‘œì¤€ ë§¤í•‘ ì˜¤ë¥˜:** SKOS ë³€í™˜ ì‹œ ì •ë³´ ì†ì‹¤
- **ì´ˆì•ˆ í’ˆì§ˆ ì˜¤ë¥˜:** LLM ìƒì„± ì´ˆì•ˆì˜ ë¶€ì •í™•í•œ ì •ì˜/ê´€ê³„
- **ì´ì¤‘ ë©”ëª¨ë¦¬ ë¶ˆì¼ì¹˜ ì˜¤ë¥˜:** Vanna Tool Memoryì˜ SQL ìŒì´ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”/ì»¬ëŸ¼ì´ Graphiti ì—”í„°í‹°ì™€ ë¶ˆì¼ì¹˜í•˜ì—¬ ë°œìƒí•˜ëŠ” ë§¥ë½ ë‹¨ì ˆ (Â§4.3.10.10.8.4)

---

### 5.3 í…ŒìŠ¤íŠ¸ ì „ëµ ë° ê²€ì¦ ì²´ê³„

DataNexusì˜ í’ˆì§ˆ ë³´ì¦ì„ ìœ„í•´ **4ë‹¨ê³„ ê²€ì¦ í”„ë ˆì„ì›Œí¬**ë¥¼ ì ìš©í•©ë‹ˆë‹¤. ì •ì‹ ìš´ì˜ì—ì„œëŠ” ê° ë‹¨ê³„ê°€ ì´ì „ ë‹¨ê³„ì˜ í†µê³¼ë¥¼ ì „ì œë¡œ í•˜ë©°, í’ˆì§ˆ ê²Œì´íŠ¸(Quality Gate)ë¥¼ í†µê³¼í•´ì•¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.

> **ğŸ“Œ MVP ì˜ˆì™¸:** Phase 1 MVPì—ì„œëŠ” **Stage 1(Unit) + Stage 4(E2E)ë§Œ í•„ìˆ˜** ì ìš©í•©ë‹ˆë‹¤. Stage 2(Integration)ì™€ Stage 3(CQ Validation)ëŠ” Stage 1â†’4 ì§í–‰ì´ ê°€ëŠ¥í•˜ë©°, Phase 1.5 ì´í›„ ìˆœì°¨ ë„ì…í•©ë‹ˆë‹¤.

í…ŒìŠ¤íŠ¸ ìˆœì„œ: **'ë‹¨ìœ„ ê¸°ëŠ¥(Logic) â†’ ë°ì´í„° ë¬´ê²°ì„±(Data) â†’ ë…¼ë¦¬ì  ì í•©ì„±(CQ) â†’ ì „ì²´ ì„±ëŠ¥(E2E)'**

```txt
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DataNexus 4ë‹¨ê³„ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ [Stage 1: Unit Testing] í•µì‹¬ ë¡œì§ ê²€ì¦ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â€¢ Query Router Agent ë¶„ê¸° ë¡œì§ â”‚
â”‚ â€¢ Schema Enforcer ê²€ì¦ ë¡œì§ â”‚
â”‚ â€¢ Impact Analyzer ì˜í–¥ ë¶„ì„ â”‚
â”‚ â€¢ ëª©í‘œ: ê°œë³„ ëª¨ë“ˆ ì •í™•ë„ 95% ì´ìƒ â”‚
â”‚ â–¼ â”‚
â”‚ [Stage 2: Integration Testing] ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â€¢ SKOS Import/Export í˜¸í™˜ì„± â”‚
â”‚ â€¢ DataHub â†” Vanna ë™ê¸°í™” â”‚
â”‚ â€¢ DozerDB ë©€í‹°í…Œë„Œì‹œ ê²©ë¦¬ â”‚
â”‚ â€¢ ëª©í‘œ: íŒŒì´í”„ë¼ì¸ ë¬´ê²°ì„± 100% â”‚
â”‚ â–¼ â”‚
â”‚ [Stage 3: CQ Validation] ë…¼ë¦¬ì  ì í•©ì„± ê²€ì¦ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â€¢ ì í•©ì„± ì§ˆë¬¸(Competency Questions) ì‹œë®¬ë ˆì´ì…˜ â”‚
â”‚ â€¢ ì˜¨í†¨ë¡œì§€ ê²½ë¡œ íƒìƒ‰ ê°€ëŠ¥ì„± â”‚
â”‚ â€¢ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆì˜ ë‹µë³€ ê°€ëŠ¥ì„± â”‚
â”‚ â€¢ ëª©í‘œ: Critical CQ 100%, ì „ì²´ CQ 80%+ â”‚
â”‚ â–¼ â”‚
â”‚ [Stage 4: E2E Evaluation] ì „ì²´ ì„±ëŠ¥ í‰ê°€ â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â€¢ NL2SQL ì •í™•ë„ (EX) â”‚
â”‚ â€¢ ì‘ë‹µ ì‹œê°„ (VES) â”‚
â”‚ â€¢ ì˜¨í†¨ë¡œì§€ ì»¤ë²„ë¦¬ì§€ (OCA) [Phase 2] â”‚
â”‚ â€¢ ëª©í‘œ: EX 80%+ (MVP) / 90%+ (Phase 2), P95 < 3ì´ˆ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.3.1 Stage 1: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Testing)

ê°œë³„ ëª¨ë“ˆì´ ì˜ë„ëŒ€ë¡œ ì‘ë™í•˜ëŠ”ì§€ `pytest` ê¸°ë°˜ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤.

##### 5.3.1.1 Query Router Agent í…ŒìŠ¤íŠ¸

**ëª©ì :** ì§ˆì˜ ìœ í˜•ì— ë”°ë¥¸ ë¼ìš°íŒ… ë¶„ê¸°ê°€ ì •í™•í•œì§€ ê²€ì¦ (PRD ëª©í‘œ: ì •í™•ë„ 95% ì´ìƒ)

| í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ | ì…ë ¥ ì˜ˆì‹œ | ì˜ˆìƒ ë¼ìš°íŒ… | ê²€ì¦ ê¸°ì¤€ |
| :--- | :--- | :--- | :--- |
| ê²°ì •ë¡ ì  ì§ˆì˜ (Deterministic) | "Aì˜ í•˜ìœ„ ì¡°ì§ì€?" | Cypher í…œí”Œë¦¿ | í…œí”Œë¦¿ ID ì •í™• ë§¤ì¹­ |
| í™•ë¥ ë¡ ì  ì§ˆì˜ (Probabilistic) | "ê²½ìŸì‚¬ ëŒ€ë¹„ ê°•ì ì€?" | LLM Fallback | LLM í˜¸ì¶œ í™•ì¸ |
| ê³„ì¸µ íƒìƒ‰ ì§ˆì˜ | "ë§¤ì¶œì˜ ìƒìœ„ ê°œë…ë“¤" | HIERARCHY_ANCESTORS | ì‹ ë¢°ë„ 1.0 |
| ì§‘ê³„ ì§ˆì˜ | "ë¶€ì„œë³„ ë§¤ì¶œ í•©ê³„" | AGGREGATION_BY_GROUP | ì¿¼ë¦¬ ì‹¤í–‰ ì„±ê³µ |

```python
# tests/unit/test_query_router.py
class TestQueryRouter:
    """Query Router Agent ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""

    def test_deterministic_routing_hierarchy(self):
        """ê³„ì¸µ ì§ˆì˜ â†’ Cypher í…œí”Œë¦¿ ë¼ìš°íŒ…"""
        query = "Aì˜ í•˜ìœ„ ì¡°ì§ì€?"
        result = router.classify(query)

        assert result.route == "CYPHER_TEMPLATE"
        assert result.template_id == "HIERARCHY_DESCENDANTS"
        assert result.confidence == 1.0  # ê²°ì •ë¡ ì  = 100%

    def test_probabilistic_routing_analysis(self):
        """ë¶„ì„ ì§ˆì˜ â†’ LLM Fallback"""
        query = "ê²½ìŸì‚¬ ëŒ€ë¹„ ìš°ë¦¬ íšŒì‚¬ì˜ ê°•ì ì„ ë¶„ì„í•´ì¤˜"
        result = router.classify(query)

        assert result.route == "LLM_FALLBACK"
        assert result.confidence >= 0.7

    def test_template_execution_accuracy(self):
        """Cypher í…œí”Œë¦¿ ì‹¤í–‰ ì •í™•ë„"""
        template_result = router.execute_template(
            template_id="TRANSITIVE_CLOSURE",
            params={"start_node": "urn:li:glossaryTerm:ë§¤ì¶œ"}
        )

        assert template_result.execution_success
        assert len(template_result.results) > 0
```

**í’ˆì§ˆ ê²Œì´íŠ¸:** Router ë¶„ë¥˜ ì •í™•ë„ â‰¥ 95%

##### 5.3.1.2 Schema Enforcer í…ŒìŠ¤íŠ¸

**ëª©ì :** ë¹„í‘œì¤€ ìš©ì–´ ê°ì§€ ë° ì²˜ë¦¬ ë¡œì§ì´ ì •í™•í•œì§€ ê²€ì¦

| í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ | ì…ë ¥ íŠ¸ë¦¬í”Œ | ì˜ˆìƒ ìƒíƒœ | ì˜ˆìƒ ì•¡ì…˜ |
| :--- | :--- | :--- | :--- |
| ì •í™• ì¼ì¹˜ | (ìˆœë§¤ì¶œ, CalculatedFrom, ì´ë§¤ì¶œ) | ACCEPT | STORE |
| ë™ì˜ì–´ ë§¤í•‘ | (Net Sales, IsA, ë§¤ì¶œ) | REMAP | STORE (ì •ê·œí™”) |
| ìœ ì‚¬ ë§¤ì¹­ | (ìˆœë§¤ì¶œì•¡, IsA, ë§¤ì¶œ) | REVIEW | QUEUE (ê²€í† ) |
| ë¯¸ë“±ë¡ ìš©ì–´ | (Revenue, IsA, ë§¤ì¶œ) | REJECT | DISCARD |

```python
# tests/unit/test_schema_enforcer.py
class TestSchemaEnforcer:
    """Schema Enforcer ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""

    def test_exact_match_accept(self):
        """ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í‘œì¤€ ìš©ì–´ â†’ ACCEPT"""
        triple = Triple(subject="ìˆœë§¤ì¶œ", predicate="CalculatedFrom", object="ì´ë§¤ì¶œ")
        result = enforcer.validate_triple(triple)

        assert result.subject_status == "ACCEPT"
        assert result.action == "STORE"

    def test_synonym_remap(self):
        """ë™ì˜ì–´ â†’ REMAP í›„ ì •ê·œí™” ì €ì¥"""
        triple = Triple(subject="Net Sales", predicate="IsA", object="ë§¤ì¶œ")
        result = enforcer.validate_triple(triple)

        assert result.subject_status == "REMAP"
        assert result.subject_uri == "urn:li:glossaryTerm:ìˆœë§¤ì¶œ"

    def test_fuzzy_match_review(self):
        """ìœ ì‚¬ë„ 0.85 ì´ìƒ â†’ REVIEW íë¡œ ì „ì†¡"""
        triple = Triple(subject="ìˆœë§¤ì¶œì•¡", predicate="IsA", object="ë§¤ì¶œ")
        result = enforcer.validate_triple(triple)

        assert result.subject_status == "REVIEW"
        assert result.similarity_score >= 0.85

    def test_unknown_term_reject(self):
        """ë¯¸ë“±ë¡ ìš©ì–´ â†’ REJECT"""
        triple = Triple(subject="Revenue", predicate="IsA", object="ë§¤ì¶œ")
        result = enforcer.validate_triple(triple)

        assert result.subject_status == "REJECT"
        assert result.action == "DISCARD"
```

**í’ˆì§ˆ ê²Œì´íŠ¸:** Schema Compliance Rate â‰¥ 90%, False Rejection Rate < 2%

##### 5.3.1.3 Impact Analyzer í…ŒìŠ¤íŠ¸

**ëª©ì :** ì˜¨í†¨ë¡œì§€ ë³€ê²½ ì‹œ ì˜í–¥ ë²”ìœ„ ë¶„ì„ì´ ì •í™•í•œì§€ ê²€ì¦

```python
# tests/unit/test_impact_analyzer.py
class TestImpactAnalyzer:
    """Impact Analyzer ë‹¨ìœ„ í…ŒìŠ¤íŠ¸"""

    def test_term_add_minimal_impact(self):
        """Term ì¶”ê°€ â†’ ìµœì†Œ ì˜í–¥ (ì¦ë¶„ ì—…ë°ì´íŠ¸)"""
        event = ChangeEvent(entity_urn="urn:li:glossaryTerm:ì‹ ê·œìš©ì–´", change_type="CREATE")
        report = analyzer.analyze_change_impact(event)

        assert report.impact_score < 0.1
        assert report.recommended_strategy == "INCREMENTAL"

    def test_hierarchy_change_subtree_impact(self):
        """ê³„ì¸µ êµ¬ì¡° ë³€ê²½ â†’ ì„œë¸ŒíŠ¸ë¦¬ ì „ì²´ ì˜í–¥"""
        event = ChangeEvent(entity_urn="urn:li:glossaryTerm:ë§¤ì¶œ", change_type="HIERARCHY_CHANGE")
        report = analyzer.analyze_change_impact(event)

        assert len(report.affected_nodes) > 10
        assert report.recommended_strategy in ["PARTIAL_REBUILD", "FULL_REBUILD"]

    def test_cost_saving_verification(self):
        """ì¦ë¶„ ì—…ë°ì´íŠ¸ ë¹„ìš© ì ˆê° ê²€ì¦ (ëª©í‘œ: 70% ì´ìƒ)"""
        full_cost = analyzer.estimate_full_reindex_cost()
        incremental_cost = analyzer.estimate_incremental_cost(event)

        assert incremental_cost < full_cost * 0.3
```

#### 5.3.2 Stage 2: í†µí•© í…ŒìŠ¤íŠ¸ (Integration Testing)

ë°ì´í„°ê°€ íë¥´ëŠ” íŒŒì´í”„ë¼ì¸ì˜ ì—°ê²° ìƒíƒœì™€ ë¬´ê²°ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.

##### 5.3.2.1 SKOS í˜¸í™˜ì„± í…ŒìŠ¤íŠ¸

**ëª©ì :** SKOS í‘œì¤€ Import/Export ì‹œ ì •ë³´ ì†ì‹¤ì´ ì—†ëŠ”ì§€ ê²€ì¦

| í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ | ê²€ì¦ í•­ëª© | ì„±ê³µ ê¸°ì¤€ |
| :--- | :--- | :--- |
| DataHub â†’ SKOS Export | ê³„ì¸µ êµ¬ì¡° ë³´ì¡´ | broader/narrower ê´€ê³„ 100% ìœ ì§€ |
| SKOS â†’ DataHub Import | ì™¸ë¶€ ì˜¨í†¨ë¡œì§€ í†µí•© | SHACL ê²€ì¦ í†µê³¼ |
| Round-trip í…ŒìŠ¤íŠ¸ | Export â†’ Import â†’ ë¹„êµ | ë…¸ë“œ/ì—£ì§€ ìˆ˜ ë™ì¼ |

```python
# tests/integration/test_skos_compatibility.py
class TestSKOSCompatibility:
    """SKOS í‘œì¤€ í˜¸í™˜ì„± í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_datahub_to_skos_export(self):
        """DataHub Glossary â†’ RDF/SKOS Export"""
        exporter = SKOSExporter(datahub_client)
        rdf_graph = exporter.export(glossary_urn="urn:li:glossaryNode:GRSì˜ì—…")

        # SHACL ìŠ¤í‚¤ë§ˆ ê²€ì¦
        validation_result = shacl_validator.validate(rdf_graph)
        assert validation_result.conforms

    def test_external_ontology_import(self):
        """ì™¸ë¶€ SKOS ì˜¨í†¨ë¡œì§€ Import (ì˜ˆ: ProtÃ©gÃ©ì—ì„œ ì‘ì„±í•œ íŒŒì¼)"""
        importer = ExternalOntologyImporter()
        result = importer.import_skos(source="fibo_corporate.ttl", target_glossary="urn:li:glossaryNode:ì¬ë¬´")

        assert result.imported_terms > 0
        assert len(result.conflicts) == 0

    def test_roundtrip_integrity(self):
        """Round-trip (Export â†’ Import) ë¬´ê²°ì„±"""
        original = datahub_client.get_glossary("urn:li:glossaryNode:í…ŒìŠ¤íŠ¸")
        rdf_export = exporter.export(original)
        imported = importer.import_from_rdf(rdf_export)

        assert original.term_count == imported.term_count
```

**í’ˆì§ˆ ê²Œì´íŠ¸:** SKOS Mapping Coverage â‰¥ 95%

##### 5.3.2.2 ë™ê¸°í™”(Sync) íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸

**ëª©ì :** DataHub ë³€ê²½ ì‹œ Vanna AI RAG Store ìë™ ë™ê¸°í™” ê²€ì¦

```python
# tests/integration/test_sync_pipeline.py
class TestSyncPipeline:
    """DataHub â†” Vanna ë™ê¸°í™” í†µí•© í…ŒìŠ¤íŠ¸"""

    def test_glossary_change_triggers_sync(self):
        """Glossary ë³€ê²½ â†’ Vanna ì¬í•™ìŠµ íŠ¸ë¦¬ê±°"""
        datahub_client.update_term(
            urn="urn:li:glossaryTerm:ìˆœë§¤ì¶œ",
            definition="ì´ë§¤ì¶œì—ì„œ ë°˜í’ˆ, í• ì¸, ì—ëˆ„ë¦¬ë¥¼ ì°¨ê°í•œ ê¸ˆì•¡ (ë³€ê²½ë¨)"
        )

        event = webhook_listener.wait_for_event(timeout=30)
        assert event.change_type == "UPDATE"

        sync_job = sync_pipeline.get_latest_job()
        assert sync_job.status == "COMPLETED"
```

##### 5.3.2.3 DozerDB ë©€í‹°í…Œë„Œì‹œ í…ŒìŠ¤íŠ¸

**ëª©ì :** ê·¸ë£¹ì‚¬ë³„ ë°ì´í„° ê²©ë¦¬ê°€ ì™„ë²½í•œì§€ ê²€ì¦

```python
# tests/integration/test_multitenancy.py
class TestMultitenancy:
    """DozerDB ë©€í‹°í…Œë„Œì‹œ ê²©ë¦¬ í…ŒìŠ¤íŠ¸"""

    def test_cross_database_isolation(self):
        """í¬ë¡œìŠ¤ DB ì¿¼ë¦¬ ë¶ˆê°€ í™•ì¸"""
        with pytest.raises(PermissionError):
            dozerdb.execute(database="group_a_db", query="MATCH (n) WHERE n.tenant = 'group_b' RETURN n")

    def test_tenant_data_isolation(self):
        """í…Œë„ŒíŠ¸ë³„ ë°ì´í„° ì™„ì „ ë¶„ë¦¬ í™•ì¸"""
        dozerdb.execute("group_a_db", "CREATE (:Product {name: 'Aì œí’ˆ'})")
        dozerdb.execute("group_b_db", "CREATE (:Product {name: 'Aì œí’ˆ'})")

        result_a = dozerdb.execute("group_a_db", "MATCH (p:Product) RETURN count(p)")
        result_b = dozerdb.execute("group_b_db", "MATCH (p:Product) RETURN count(p)")

        assert result_a == 1
        assert result_b == 1
```

**í’ˆì§ˆ ê²Œì´íŠ¸:** íŒŒì´í”„ë¼ì¸ ë¬´ê²°ì„± 100%, í…Œë„ŒíŠ¸ ê²©ë¦¬ 100%

#### 5.3.3 Stage 3: ì í•©ì„± ì§ˆë¬¸ ê²€ì¦ (CQ Validation)

ê¸°ì¡´ PRDì˜ í•µì‹¬ì¸ **Competency Questions**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¨í†¨ë¡œì§€ê°€ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆì˜ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ”ì§€ í‰ê°€í•©ë‹ˆë‹¤.

##### 5.3.3.1 CQ ì‹œë®¬ë ˆì´ì…˜ í…ŒìŠ¤íŠ¸

**ëª©ì :** ì •ì˜ëœ CQì— ëŒ€í•´ ì˜¨í†¨ë¡œì§€ê°€ ë‹µë³€ ê°€ëŠ¥í•œì§€ ê²€ì¦

| CQ ìœ í˜• | ì˜ˆì‹œ ì§ˆë¬¸ | ê²€ì¦ í•­ëª© |
| :--- | :--- | :--- |
| Foundational (FCQ) | "ê³ ê° ìœ í˜•ì„ êµ¬ë¶„í•˜ëŠ” ê°œë…ì´ ì •ì˜ë˜ì–´ ìˆëŠ”ê°€?" | ê°œë… ì¡´ì¬ í™•ì¸ |
| Relationship (RCQ) | "A ê³µì¥ ì´ìŠˆê°€ B ì œí’ˆ ê³µê¸‰ë§ì— ë¯¸ì¹œ ì˜í–¥ì€?" | ê²½ë¡œ íƒìƒ‰ ê°€ëŠ¥ì„± |
| Validating (VCQ) | "ìˆœë§¤ì¶œì€ ì´ë§¤ì¶œì—ì„œ ë¬´ì—‡ì„ ì°¨ê°í•œ ê°’ì¸ê°€?" | ì •ì˜ ì •í™•ì„± |
| Metaproperty (MpCQ) | "VIP ê³ ê°ì˜ ì •ì˜ ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€?" | ë©”íƒ€ ì†ì„± ì™„ì „ì„± |

```python
# tests/cq/test_competency_questions.py
class TestCompetencyQuestions:
    """ì í•©ì„± ì§ˆë¬¸(CQ) ê²€ì¦ í…ŒìŠ¤íŠ¸"""

    def test_foundational_cq_concept_existence(self):
        """FCQ: í•µì‹¬ ê°œë… ì¡´ì¬ í™•ì¸"""
        cq = CompetencyQuestion(
            cq_id="CQ-FCQ-001",
            question="ê³ ê° ìœ í˜•ì„ êµ¬ë¶„í•˜ëŠ” ê°œë…ì´ ì •ì˜ë˜ì–´ ìˆëŠ”ê°€?",
            required_concepts=["ê³ ê°", "VIPê³ ê°", "ì¼ë°˜ê³ ê°", "ì‹ ê·œê³ ê°"]
        )

        result = cq_validator.validate(cq)
        assert result.concept_coverage == 1.0
        assert result.status == "PASS"

    def test_relationship_cq_path_traversal(self):
        """RCQ: ê´€ê³„ ê²½ë¡œ íƒìƒ‰ ê°€ëŠ¥ì„±"""
        cq = CompetencyQuestion(
            cq_id="CQ-RCQ-001",
            question="A ê³µì¥ ì´ìŠˆê°€ B ì œí’ˆ ê³µê¸‰ë§ì— ë¯¸ì¹œ ì˜í–¥ì€?",
            required_relationships=[
                {"subject": "Factory", "predicate": "Impacts", "object": "SupplyChain"},
                {"subject": "SupplyChain", "predicate": "Affects", "object": "Product"}
            ]
        )

        result = cq_validator.validate(cq)
        assert result.relationship_coverage == 1.0

        path = graph_db.find_path(start="urn:li:glossaryTerm:Aê³µì¥", end="urn:li:glossaryTerm:Bì œí’ˆ")
        assert path is not None

    def test_critical_cq_must_pass(self):
        """Critical CQëŠ” 100% í†µê³¼ í•„ìˆ˜"""
        critical_cqs = cq_repository.get_by_priority("Critical")

        for cq in critical_cqs:
            result = cq_validator.validate(cq)
            assert result.status == "PASS", f"Critical CQ ì‹¤íŒ¨: {cq.cq_id}"
```

##### 5.3.3.2 ì¿¼ë¦¬ ìƒì„± ì‹œë®¬ë ˆì´ì…˜

**ëª©ì :** CQë¡œë¶€í„° ì‹¤ì œ SQL/Cypher ì¿¼ë¦¬ê°€ ìƒì„± ê°€ëŠ¥í•œì§€ ê²€ì¦

```python
# tests/cq/test_query_generation.py
class TestCQQueryGeneration:
    """CQ ê¸°ë°˜ ì¿¼ë¦¬ ìƒì„± ì‹œë®¬ë ˆì´ì…˜"""

    def test_cq_to_sql_generation(self):
        """ìì—°ì–´ CQ â†’ SQL ë³€í™˜ ì„±ê³µ ì—¬ë¶€"""
        cq = CompetencyQuestion(question="ì§€ë‚œ ë‹¬ VIP ê³ ê°ì˜ ìˆœë§¤ì¶œ í•©ê³„ëŠ” ì–¼ë§ˆì¸ê°€?")
        generated_sql = vanna_client.generate_sql(cq.question)

        assert sql_validator.is_valid(generated_sql)
        assert "SUM" in generated_sql.upper()

    def test_cq_pass_rate_threshold(self):
        """ì „ì²´ CQ Pass Rate ê²€ì¦"""
        all_cqs = cq_repository.get_all()
        results = [cq_validator.validate(cq) for cq in all_cqs]

        pass_rate = sum(1 for r in results if r.status == "PASS") / len(results)
        assert pass_rate >= 0.80, f"CQ Pass Rate {pass_rate:.1%} < 80%"
```

**í’ˆì§ˆ ê²Œì´íŠ¸:** Critical CQ 100% í†µê³¼, ì „ì²´ CQ Pass Rate â‰¥ 80%

#### 5.3.4 Stage 4: End-to-End ì„±ëŠ¥ í‰ê°€ (E2E Evaluation)

ì‹¤ì œ ì‚¬ìš©ì ê²½í—˜ ê´€ì ì—ì„œ RAGì˜ í’ˆì§ˆì„ ì •ëŸ‰í™”í•©ë‹ˆë‹¤.

##### 5.3.4.1 NL2SQL ì •í™•ë„ ì¸¡ì •

**ëª©ì :** NL2SQL360 ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€ ì •í™•ë„ í‰ê°€

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œ |
| :--- | :--- | :--- |
| EX (Execution Accuracy) | ìƒì„±ëœ SQLì´ ì‹¤ì œ DBì—ì„œ ì˜¬ë°”ë¥¸ ê°’ì„ ë°˜í™˜í•˜ëŠ”ì§€ ì¸¡ì • | MVP â‰¥ 80% / Phase 2 â‰¥ 90% |
| EM (Exact Match) | ìƒì„± ì¿¼ë¦¬ ì™„ì „ ì¼ì¹˜ | â‰¥ 70% |
| VES (Valid Efficiency Score) | ì¿¼ë¦¬ ì‹¤í–‰ íš¨ìœ¨ì„± | P95 < 3ì´ˆ |

```python
# tests/e2e/test_nl2sql_accuracy.py
class TestNL2SQLAccuracy:
    """NL2SQL E2E ì •í™•ë„ í…ŒìŠ¤íŠ¸"""

    def test_execution_accuracy(self):
        """EX: ì‹¤í–‰ ê²°ê³¼ê°’ ì¼ì¹˜ìœ¨"""
        benchmark = NL2SQLBenchmark(test_set="datanexus_test_queries.json")
        results = benchmark.run(vanna_client)

        # MVP ê¸°ì¤€: Â§5.3 Stage 4 í’ˆì§ˆ ê²Œì´íŠ¸ EX â‰¥ 80% (0.80)
        assert results.execution_accuracy >= 0.80
        assert results.exact_match_accuracy >= 0.70

    def test_query_efficiency(self):
        """VES: ì¿¼ë¦¬ ì‘ë‹µ ì‹œê°„"""
        test_queries = load_test_queries()
        response_times = []

        for query in test_queries:
            start = time.time()
            result = vanna_client.generate_and_execute(query)
            response_times.append(time.time() - start)

        p95 = np.percentile(response_times, 95)
        assert p95 < 3.0, f"P95 ì‘ë‹µì‹œê°„ {p95:.2f}ì´ˆ > 3ì´ˆ"
```

##### 5.3.4.2 ì˜¨í†¨ë¡œì§€ ì»¤ë²„ë¦¬ì§€(OCA) ì¸¡ì •

**ëª©ì :** ì‚¬ìš©ì ì§ˆì˜ì˜ í•µì‹¬ ìš©ì–´ê°€ ì˜¨í†¨ë¡œì§€ì™€ ì˜ ë§¤í•‘ë˜ëŠ”ì§€ í‰ê°€

```python
# tests/e2e/test_ontology_coverage.py
# [Phase 2] OCA ì¸¡ì • â€” MVPì—ì„œëŠ” ì´ í…ŒìŠ¤íŠ¸ë¥¼ skip ë˜ëŠ” warningìœ¼ë¡œ ì²˜ë¦¬
# ë˜ëŠ” @pytest.mark.phase2 ë°ì½”ë ˆì´í„° ì‚¬ìš©
class TestOntologyCoverage:
    """ì˜¨í†¨ë¡œì§€ ì»¤ë²„ë¦¬ì§€ E2E í…ŒìŠ¤íŠ¸"""

    def test_entity_resolution_accuracy(self):
        """OCA: ì—”í‹°í‹° ë§¤í•‘ ì •í™•ë„"""
        test_queries = [
            ("ì§€ë‚œë‹¬ ìˆœë§¤ì¶œ", ["ìˆœë§¤ì¶œ", "ê¸°ê°„"]),
            ("VIP ê³ ê°ì˜ ì£¼ë¬¸ í˜„í™©", ["VIPê³ ê°", "ì£¼ë¬¸"]),
            ("Aê³µì¥ ìƒì‚°ëŸ‰", ["Aê³µì¥", "ìƒì‚°ëŸ‰"])
        ]

        total_entities = 0
        matched_entities = 0

        for query, expected_entities in test_queries:
            for entity in expected_entities:
                total_entities += 1
                if entity_resolver.resolve(entity) is not None:
                    matched_entities += 1

        oca = matched_entities / total_entities
        assert oca >= 0.90, f"OCA {oca:.1%} < 90%"
```

#### 5.3.5 í…ŒìŠ¤íŠ¸ ìë™í™” íŒŒì´í”„ë¼ì¸

CI/CD íŒŒì´í”„ë¼ì¸ì— í†µí•©í•˜ì—¬ ë§¤ ë°°í¬ ì „ í’ˆì§ˆ ê²Œì´íŠ¸ë¥¼ ìë™ ê²€ì¦í•©ë‹ˆë‹¤.

```yaml
# .github/workflows/test_pipeline.yml
name: DataNexus Quality Gate

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run Unit Tests
        run: pytest tests/unit/ -v --cov=datanexus --cov-fail-under=90
      - name: Check Router Accuracy
        run: python -m datanexus.router benchmark --threshold 0.95

 integration-tests:
    needs: unit-tests
    runs-on: ubuntu-latest
    services:
      dozerdb:
        image: dozerdb/dozerdb:latest
      qdrant:
        image: qdrant/qdrant:latest
    steps:
      - name: Run Integration Tests
        run: pytest tests/integration/ -v
      - name: Verify SKOS Compatibility
        run: python -m datanexus.skos validate --coverage-threshold 0.95

 cq-validation:
    needs: integration-tests
    steps:
      - name: Run CQ Validation
        run: |
          python -m datanexus.cq validate \
            --config competency_questions.yaml \
            --critical-threshold 1.0 \
            --overall-threshold 0.80

 e2e-evaluation:
    needs: cq-validation
    steps:
      - name: Run E2E Benchmark
        run: |
          python -m datanexus.benchmark run \
            --test-set production_queries.json \
            --ex-threshold 0.80 \
            --p95-threshold 3.0
```

#### 5.3.6 í…ŒìŠ¤íŠ¸ í’ˆì§ˆ ê²Œì´íŠ¸ ìš”ì•½

| ë‹¨ê³„ | í’ˆì§ˆ ê²Œì´íŠ¸ | í†µê³¼ ê¸°ì¤€ | ì‹¤íŒ¨ ì‹œ ì¡°ì¹˜ |
| :--- | :--- | :--- | :--- |
| **Stage 1** | Router Accuracy | â‰¥ 95% | í…œí”Œë¦¿ ì¶”ê°€/ë¶„ë¥˜ê¸° ì¬í•™ìŠµ |
| **Stage 1** | Schema Compliance | â‰¥ 90% | ë™ì˜ì–´ ì‚¬ì „ í™•ì¥ |
| **Stage 2** | SKOS Coverage | â‰¥ 95% | ë§¤í•‘ í…Œì´ë¸” ë³´ì™„ |
| **Stage 2** | Sync Integrity | 100% | íŒŒì´í”„ë¼ì¸ ë””ë²„ê¹… |
| **Stage 3** | Critical CQ Pass | 100% | ì˜¨í†¨ë¡œì§€ ë³´ì™„ í•„ìˆ˜ |
| **Stage 3** | Overall CQ Pass | â‰¥ 80% (Phase 1) | ì˜¨í†¨ë¡œì§€ í™•ì¥ ê²€í†  |
| **Stage 4** | EX Accuracy | MVP â‰¥ 80% / Phase 2 â‰¥ 90% | Few-shot ì˜ˆì œ ì¶”ê°€ |
| **Stage 4** | P95 Response | < 3ì´ˆ | ì¸ë±ìŠ¤/ìºì‹œ ìµœì í™” |

### 5.4 Multi-Agent í‰ê°€ í”„ë ˆì„ì›Œí¬ (SEOCHO)

SEOCHO í”„ë¡œì íŠ¸ì˜ `feature-kgbuild` ë¸Œëœì¹˜ì—ì„œ êµ¬í˜„ëœ ì²´ê³„ì ì¸ GraphRAG í‰ê°€ í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

#### 5.4.1 í‰ê°€ ì•„í‚¤í…ì²˜ ê°œìš”

```txt
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEOCHO Evaluation Framework                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     Macro Experiments (M1~M4)                        â”‚   â”‚
â”‚  â”‚            ì‹œìŠ¤í…œ ë ˆë²¨ ë¹„êµ - ì „ì²´ íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥ í‰ê°€              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     Ablation Study (A1~A6)                           â”‚   â”‚
â”‚  â”‚           ì»´í¬ë„ŒíŠ¸ ë ˆë²¨ ë¶„ì„ - ê°œë³„ ëª¨ë“ˆ ê¸°ì—¬ë„ ì¸¡ì •                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     Metrics Collection                               â”‚   â”‚
â”‚  â”‚  AnswerRelevance | Hallucination | RoutingAccuracy | ContextPrecisionâ”‚   â”‚
â”‚  â”‚                  ConflictResolutionScore                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â”‚                                        â”‚
â”‚                                    â–¼                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                     Opik Integration                                 â”‚   â”‚
â”‚  â”‚              Trace Export | Dataset Management | Dashboard           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 5.4.2 Macro Experiments (ì‹œìŠ¤í…œ ë ˆë²¨ ë¹„êµ)

ì „ì²´ ì‹œìŠ¤í…œ êµ¬ì„±ë³„ ì„±ëŠ¥ì„ ë¹„êµí•˜ì—¬ ìµœì ì˜ ì•„í‚¤í…ì²˜ë¥¼ ê²€ì¦í•©ë‹ˆë‹¤.

| ì‹¤í—˜ ID | êµ¬ì„± ìš”ì†Œ | ëª©ì  | ì˜ˆìƒ ê²°ê³¼ |
|---------|----------|------|----------|
| **M1** | LPG + RDF + HYBRID + Manager | Full System ì„±ëŠ¥ ì¸¡ì • | Baseline (ìµœê³  ì„±ëŠ¥) |
| **M2** | LPG + RDF + HYBRID + Single Agent | Manager Agent íš¨ê³¼ ê²€ì¦ | M1 ëŒ€ë¹„ -5~10% |
| **M3** | LPG + HYBRID (no RDF) | ì˜¨í†¨ë¡œì§€/RDF ê¸°ì—¬ë„ ì¸¡ì • | M1 ëŒ€ë¹„ -10~15% |
| **M4** | RDF + HYBRID (no LPG) | êµ¬ì¡°í™”ëœ LPG ê¸°ì—¬ë„ ì¸¡ì • | M1 ëŒ€ë¹„ -15~20% |

```python
# evaluation/experiments/macro_experiments.py
class MacroExperiments:
    """ì‹œìŠ¤í…œ ë ˆë²¨ Macro ì‹¤í—˜ ì •ì˜"""
    
    EXPERIMENTS = {
        "M1": {
            "name": "Full System with Manager",
            "components": ["lpg", "rdf", "hybrid"],
            "agent_type": "hierarchical",
            "description": "ëª¨ë“  ê²€ìƒ‰ ë°©ì‹ + ê³„ì¸µì  ì—ì´ì „íŠ¸"
        },
        "M2": {
            "name": "Full System Single Agent",
            "components": ["lpg", "rdf", "hybrid"],
            "agent_type": "single",
            "description": "ëª¨ë“  ê²€ìƒ‰ ë°©ì‹ + ë‹¨ì¼ ì—ì´ì „íŠ¸"
        },
        "M3": {
            "name": "LPG + Hybrid (No Ontology)",
            "components": ["lpg", "hybrid"],
            "agent_type": "hierarchical",
            "description": "RDF/ì˜¨í†¨ë¡œì§€ ì œì™¸"
        },
        "M4": {
            "name": "RDF + Hybrid (No LPG)",
            "components": ["rdf", "hybrid"],
            "agent_type": "hierarchical",
            "description": "LPG êµ¬ì¡°í™” ë°ì´í„° ì œì™¸"
        }
    }
    
    def run_experiment(self, experiment_id: str, dataset: str) -> ExperimentResult:
        config = self.EXPERIMENTS[experiment_id]
        agent = self._create_agent(config)
        results = self._evaluate(agent, dataset)
        return ExperimentResult(
            experiment_id=experiment_id,
            metrics=results,
            config=config
        )
```

#### 5.4.3 Ablation Study (ì»´í¬ë„ŒíŠ¸ ë ˆë²¨ ë¶„ì„)

ê°œë³„ ê²€ìƒ‰ ë°©ì‹ì˜ ê¸°ì—¬ë„ë¥¼ ì¸¡ì •í•˜ì—¬ ìµœì  ì¡°í•©ì„ ë„ì¶œí•©ë‹ˆë‹¤.

> **ğŸ“Œ Ablation Study í•´ì„ í•œê³„ ë° êµí˜¸ì‘ìš© ë¶„ì„:**
> ê¸°ì¡´ ê¸°ì—¬ë„ ë¶„ì„(`A4 - A2 = LPG ê¸°ì—¬ë„`)ì€ ì£¼íš¨ê³¼(main effect)ë§Œ ì¶”ì •í•œë‹¤. ë‘ ì»´í¬ë„ŒíŠ¸ê°€ í•¨ê»˜ ì‘ë™í•  ë•Œ ë°œìƒí•˜ëŠ” ì‹œë„ˆì§€ ë˜ëŠ” ê°„ì„­(êµí˜¸ì‘ìš©, interaction effect)ì€ ë³„ë„ ë¶„ì„ì´ í•„ìš”í•˜ë‹¤.
>
> **êµí˜¸ì‘ìš© ê³„ì‚°ì‹:** `Interaction(AÃ—B) = ABì¡°í•© - Aë‹¨ë… - Bë‹¨ë… + Baseline`
>
> | êµí˜¸ì‘ìš© | ê³„ì‚° | ì–‘ìˆ˜ì¼ ë•Œ ì˜ë¯¸ | ìŒìˆ˜ì¼ ë•Œ ì˜ë¯¸ |
> | :--- | :--- | :--- | :--- |
> | LPG Ã— RDF | A4 - A1 - A2 + A3 | LPG+RDF ì‹œë„ˆì§€ â†’ í•˜ì´ë¸Œë¦¬ë“œ ì •ë‹¹í™” | LPG+RDF ê°„ì„­ â†’ ì¤‘ë³µ ì •ë³´ë¡œ í˜¼ë€ |
> | LPG Ã— HYBRID | A5 - A1 - A3 + A3 | êµ¬ì¡°í™”+ë²¡í„° ë³´ì™„ íš¨ê³¼ | êµ¬ì¡°í™” ê²°ê³¼ê°€ ë²¡í„° ê²°ê³¼ì™€ ì¶©ëŒ |
> | RDF Ã— HYBRID | A6 - A2 - A3 + A3 | ì‹œë§¨í‹±+ë²¡í„° ë³´ì™„ íš¨ê³¼ | verbose ì»¨í…ìŠ¤íŠ¸ ì¤‘ë³µ |
>
> **í•´ì„ ê¸°ì¤€:** |ê°’| > 0.05ì´ë©´ ì‹¤ì§ˆì  êµí˜¸ì‘ìš©ìœ¼ë¡œ íŒë‹¨. ì´ ì„ê³„ê°’ì€ Phase 2 ë°˜ë³µ ì‹¤í—˜ì—ì„œ í†µê³„ì ìœ¼ë¡œ ì¬ì„¤ì •í•œë‹¤.
>
> **í†µê³„ì  í•œê³„:** í˜„ì¬ ì„¤ê³„ëŠ” ë°˜ë³µ ì—†ëŠ” ë‹¨ì¼ ì‹¤í–‰(unreplicated 2^k factorial)ì´ë‹¤. êµí˜¸ì‘ìš© ê°’ì˜ ë°©í–¥ì„±(ì‹œë„ˆì§€/ê°„ì„­)ì€ íŒë‹¨í•  ìˆ˜ ìˆìœ¼ë‚˜, p-value ê¸°ë°˜ ìœ ì˜ì„± ì£¼ì¥ì€ ë¶ˆê°€í•˜ë‹¤. Phase 2ì—ì„œ ì‹¤í—˜ë³„ ìµœì†Œ 3íšŒ ë°˜ë³µì„ ë„ì…í•˜ì—¬ ANOVA ê¸°ë°˜ ìœ ì˜ì„± ê²€ì •ì„ ì¶”ê°€í•  ê³„íšì´ë‹¤.

| ì‹¤í—˜ ID | êµ¬ì„± | ë¶„ì„ ëª©ì  |
|---------|------|----------|
| **A1** | LPG Only | LPG ë‹¨ë… ì„±ëŠ¥ |
| **A2** | RDF Only | RDF ë‹¨ë… ì„±ëŠ¥ |
| **A3** | HYBRID Only | ë²¡í„° ê²€ìƒ‰ ë‹¨ë… ì„±ëŠ¥ |
| **A4** | LPG + RDF | ê·¸ë˜í”„ ì¡°í•© ì„±ëŠ¥ |
| **A5** | LPG + HYBRID | LPG + ë²¡í„° ì¡°í•© |
| **A6** | RDF + HYBRID | RDF + ë²¡í„° ì¡°í•© |

```python
# evaluation/experiments/ablation_study.py
class AblationStudy:
    """ì»´í¬ë„ŒíŠ¸ ë ˆë²¨ Ablation ì‹¤í—˜"""
    
    COMBINATIONS = {
        "A1": ["lpg"],
        "A2": ["rdf"],
        "A3": ["hybrid"],
        "A4": ["lpg", "rdf"],
        "A5": ["lpg", "hybrid"],
        "A6": ["rdf", "hybrid"]
    }
    
    def run_ablation(self, dataset: str) -> Dict[str, AblationResult]:
        results = {}
        for ablation_id, components in self.COMBINATIONS.items():
            agent = self._create_ablated_agent(components)
            metrics = self._evaluate(agent, dataset)
            results[ablation_id] = AblationResult(
                ablation_id=ablation_id,
                components=components,
                metrics=metrics
            )
        return results
    
    def analyze_contributions(self, results: Dict) -> ContributionAnalysis:
        """ê° ì»´í¬ë„ŒíŠ¸ì˜ ì£¼íš¨ê³¼(main effect) ê¸°ì—¬ë„ ë¶„ì„
        
        âš ï¸ í•´ì„ í•œê³„ (ì•„ë˜ analyze_interaction_effects ì°¸ì¡°):
        ì´ ë°©ë²•ì€ ê° ì»´í¬ë„ŒíŠ¸ì˜ ë‹¨ë… ê¸°ì—¬ë„(ì£¼íš¨ê³¼)ë§Œ ì¶”ì •í•œë‹¤.
        LPGì™€ RDFê°€ í•¨ê»˜ ìˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì‹œë„ˆì§€(êµí˜¸ì‘ìš© íš¨ê³¼)ëŠ”
        ì´ ê³„ì‚°ì— í¬í•¨ë˜ì§€ ì•ŠëŠ”ë‹¤. ë”°ë¼ì„œ ì•„ë˜ ê²°ê³¼ë¥¼ "LPGê°€ X%pë¥¼
        ê¸°ì—¬í•œë‹¤"ê³  ë‹¨ì •í•˜ë©´ ì•ˆ ë˜ë©°, "RDFê°€ ê³ ì •ëœ ì¡°ê±´ì—ì„œ LPGë¥¼
        ì¶”ê°€í•˜ë©´ ì•½ X%p ë³€í™”ê°€ ê´€ì°°ëœë‹¤" ìˆ˜ì¤€ìœ¼ë¡œ í•´ì„í•´ì•¼ í•œë‹¤.
        """
        # A4 - A2 = LPG ê¸°ì—¬ë„ (RDF ê³ ì •)
        # A4 - A1 = RDF ê¸°ì—¬ë„ (LPG ê³ ì •)
        # etc.
        return ContributionAnalysis(
            lpg_contribution=results["A4"].score - results["A2"].score,
            rdf_contribution=results["A4"].score - results["A1"].score,
            hybrid_contribution=results["A5"].score - results["A1"].score
        )
    
    def analyze_interaction_effects(self, results: Dict) -> InteractionAnalysis:
        """ì»´í¬ë„ŒíŠ¸ ê°„ êµí˜¸ì‘ìš©(interaction effect) ë¶„ì„
        
        2-factor ì‹¤í—˜ ì„¤ê³„ì—ì„œ êµí˜¸ì‘ìš©ì€ ë‘ ìš”ì¸ì˜ ì¡°í•© íš¨ê³¼ê°€
        ê° ìš”ì¸ì˜ ì£¼íš¨ê³¼ í•©ê³¼ ë‹¤ë¥¸ ì •ë„ë¥¼ ì¸¡ì •í•œë‹¤.
        
        êµí˜¸ì‘ìš© = AB_ì¡°í•© - A_ë‹¨ë… - B_ë‹¨ë… + Baseline
        
        ì–‘ìˆ˜: ì‹œë„ˆì§€ (í•¨ê»˜ ì“°ë©´ ê°œë³„ í•©ë³´ë‹¤ ì¢‹ë‹¤)
        ìŒìˆ˜: ê°„ì„­ (í•¨ê»˜ ì“°ë©´ ê°œë³„ í•©ë³´ë‹¤ ë‚˜ì˜ë‹¤)
        0 ê·¼ì²˜: ë…ë¦½ (ì„œë¡œ ì˜í–¥ ì—†ì´ í•©ì‚°ë¨)
        
        ì˜ˆ) LPGÃ—RDF êµí˜¸ì‘ìš©ì´ ì–‘ìˆ˜ì´ë©´, "LPG+RDF í•˜ì´ë¸Œë¦¬ë“œê°€
            15~20% ì¢‹ë‹¤"ëŠ” ì£¼ì¥ì´ ë‹¨ìˆœ í•©ì‚°ì´ ì•„ë‹Œ ì‹œë„ˆì§€ íš¨ê³¼ë¡œ
            ë’·ë°›ì¹¨ëœë‹¤.
        """
        # Baseline: ì•„ë¬´ ê·¸ë˜í”„ ê²€ìƒ‰ ì—†ì´ ë²¡í„°ë§Œ ì‚¬ìš©í•œ ê²½ìš°
        baseline = results["A3"].score
        
        # --- LPG Ã— RDF êµí˜¸ì‘ìš© ---
        # A4(LPG+RDF) - A1(LPG) - A2(RDF) + A3(Baseline)
        lpg_rdf_interaction = (
            results["A4"].score
            - results["A1"].score
            - results["A2"].score
            + baseline
        )
        
        # --- LPG Ã— HYBRID êµí˜¸ì‘ìš© ---
        # A5(LPG+HYBRID) - A1(LPG) - A3(HYBRID) + Baseline_none
        # Baseline_noneì´ ì—†ìœ¼ë¯€ë¡œ A3ì„ ê³µìœ  Baselineìœ¼ë¡œ ì‚¬ìš©
        lpg_hybrid_interaction = (
            results["A5"].score
            - results["A1"].score
            - results["A3"].score
            + baseline
        )
        
        # --- RDF Ã— HYBRID êµí˜¸ì‘ìš© ---
        rdf_hybrid_interaction = (
            results["A6"].score
            - results["A2"].score
            - results["A3"].score
            + baseline
        )
        
        # --- 3-way êµí˜¸ì‘ìš© (M1 Full System í•„ìš”) ---
        # Full(M1) - A4 - A5 - A6 + A1 + A2 + A3
        # â€» M1ì€ Macro ì‹¤í—˜ì´ë¼ agent_typeì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ â†’ ì£¼ì˜
        three_way = None  # M1 ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ ê³„ì‚°
        
        return InteractionAnalysis(
            lpg_rdf=InteractionEffect(
                name="LPG Ã— RDF",
                value=lpg_rdf_interaction,
                interpretation=self._interpret(lpg_rdf_interaction)
            ),
            lpg_hybrid=InteractionEffect(
                name="LPG Ã— HYBRID",
                value=lpg_hybrid_interaction,
                interpretation=self._interpret(lpg_hybrid_interaction)
            ),
            rdf_hybrid=InteractionEffect(
                name="RDF Ã— HYBRID",
                value=rdf_hybrid_interaction,
                interpretation=self._interpret(rdf_hybrid_interaction)
            ),
            three_way=three_way,
            methodology_note=(
                "êµí˜¸ì‘ìš© ë¶„ì„ì€ 2^k Factorial Designì˜ ê°„ì†Œí™” ë²„ì „ì´ë‹¤. "
                "ì—„ë°€í•œ í†µê³„ì  ìœ ì˜ì„± ê²€ì •ì„ ìœ„í•´ì„œëŠ” ë™ì¼ ì‹¤í—˜ì„ ìµœì†Œ "
                "3íšŒ ë°˜ë³µ(replicate)í•˜ì—¬ ë¶„ì‚°ì„ ì¶”ì •í•´ì•¼ í•œë‹¤. í˜„ì¬ ì„¤ê³„ëŠ” "
                "ë°˜ë³µ ì—†ëŠ” ë‹¨ì¼ ì‹¤í–‰(unreplicated)ì´ë¯€ë¡œ, êµí˜¸ì‘ìš© ê°’ì€ "
                "ë°©í–¥ì„± íŒë‹¨ ìš©ë„ë¡œë§Œ í™œìš©í•˜ê³  p-value ê¸°ë°˜ ìœ ì˜ì„± ì£¼ì¥ì€ "
                "í•˜ì§€ ì•ŠëŠ”ë‹¤. Phase 2ì—ì„œ ë°˜ë³µ ì‹¤í—˜ì„ ë„ì…í•˜ì—¬ í†µê³„ì  "
                "ê²€ì •ë ¥ì„ í™•ë³´í•  ê³„íšì´ë‹¤."
            )
        )
    
    @staticmethod
    def _interpret(interaction_value: float) -> str:
        """êµí˜¸ì‘ìš© ê°’ì˜ ì‹¤ë¬´ì  í•´ì„"""
        if interaction_value > 0.05:
            return "SYNERGY: ì¡°í•© íš¨ê³¼ê°€ ê°œë³„ í•©ë³´ë‹¤ í¬ë‹¤ â€” í•˜ì´ë¸Œë¦¬ë“œ ì •ë‹¹í™”"
        elif interaction_value < -0.05:
            return "INTERFERENCE: ì¡°í•© ì‹œ ì˜¤íˆë ¤ ì„±ëŠ¥ ì €í•˜ â€” ì›ì¸ ë¶„ì„ í•„ìš”"
        else:
            return "INDEPENDENT: ì»´í¬ë„ŒíŠ¸ê°€ ë…ë¦½ì ìœ¼ë¡œ ê¸°ì—¬ â€” ë‹¨ìˆœ í•©ì‚° ëª¨ë¸ ì í•©"
    
    def analyze_cost_efficiency(self, results: Dict) -> CostEfficiencyAnalysis:
        """KVCache ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„ (KGC2026 ì¸ì‚¬ì´íŠ¸ ë°˜ì˜)
        
        LPG/RDF ê° ê²€ìƒ‰ ë°©ì‹ì´ Generation Stageì— ì£¼ì…í•˜ëŠ”
        ì»¨í…ìŠ¤íŠ¸ì˜ í† í° ë¹„ìš© ëŒ€ë¹„ ë‹µë³€ í’ˆì§ˆ íš¨ìœ¨ì„±ì„ ë¹„êµí•©ë‹ˆë‹¤.
        """
        cost_efficiency = {}
        for ablation_id, result in results.items():
            # Context Token Efficiency = í’ˆì§ˆ ì ìˆ˜ / í”„ë¡¬í”„íŠ¸ í† í° ìˆ˜
            cte = result.score / result.prompt_tokens if result.prompt_tokens > 0 else 0
            # KVCache Cost = í”„ë¡¬í”„íŠ¸ í† í° Ã— API ë‹¨ê°€ (ìºì‹œ ë¯¸ìŠ¤ë¶„ë§Œ ê³¼ê¸ˆ)
            kvcache_cost = (
                result.cache_creation_tokens * self.PRICE_PER_CREATION_TOKEN
                + result.cache_read_tokens * self.PRICE_PER_READ_TOKEN
                + result.uncached_tokens * self.PRICE_PER_INPUT_TOKEN
            )
            cost_efficiency[ablation_id] = CostEfficiencyResult(
                ablation_id=ablation_id,
                context_token_efficiency=cte,
                kvcache_cost_per_query=kvcache_cost,
                avg_prompt_tokens=result.prompt_tokens,
                avg_context_tokens=result.context_tokens,
                quality_score=result.score
            )
        
        # Quality-Cost Pareto Frontier ê³„ì‚°
        pareto_front = self._compute_pareto_frontier(cost_efficiency)
        
        return CostEfficiencyAnalysis(
            per_experiment=cost_efficiency,
            pareto_frontier=pareto_front,
            lpg_vs_rdf_cte_ratio=(
                cost_efficiency["A1"].context_token_efficiency
                / cost_efficiency["A2"].context_token_efficiency
                if cost_efficiency["A2"].context_token_efficiency > 0 else float('inf')
            ),
            optimal_combination=pareto_front[0].ablation_id  # íŒŒë ˆí†  ìµœì ì 
        )
```

#### 5.4.4 ì‹ ê·œ í‰ê°€ ë©”íŠ¸ë¦­

ê¸°ì¡´ NL2SQL í‰ê°€ ì§€í‘œì— Multi-Agent ì‹œìŠ¤í…œ íŠ¹í™” ë©”íŠ¸ë¦­ì„ ì¶”ê°€í•©ë‹ˆë‹¤.

| ë©”íŠ¸ë¦­ | ìœ í˜• | ì„¤ëª… | ì¸¡ì • ë°©ë²• | ëª©í‘œ ê¸°ì¤€ |
|--------|------|------|----------|----------|
| **AnswerRelevance** | LLM | ì‘ë‹µì´ ì§ˆì˜ì— ì ì ˆí•œì§€ | LLM-as-a-Judge | â‰¥ 4.0/5.0 |
| **Hallucination** | LLM | í™˜ê°/í—ˆêµ¬ ì •ë³´ í¬í•¨ ì—¬ë¶€ | LLM ê¸°ë°˜ íŒ©íŠ¸ì²´í¬ | â‰¤ 5% |
| **RoutingAccuracy** | Custom | ì˜¬ë°”ë¥¸ ë„êµ¬/ì—ì´ì „íŠ¸ ì„ íƒë¥  | Ground Truth ë¹„êµ | â‰¥ 95% |
| **ContextPrecision** | Custom | ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ | Relevance ì ìˆ˜ | â‰¥ 0.85 |
| **ConflictResolutionScore** | Custom | Hierarchy of Truth ì¤€ìˆ˜ìœ¨ | ì¶©ëŒ í•´ê²° ì •í™•ë„ | â‰¥ 95% |
| **ContextTokenEfficiency** | Cost | í† í° ëŒ€ë¹„ ë‹µë³€ í’ˆì§ˆ íš¨ìœ¨ (Â§5.4.4.1) | Score / prompt_tokens | LPG â‰¥ RDF |
| **KVCacheCostPerQuery** | Cost | ì¿¼ë¦¬ë‹¹ KVCache ë¹„ìš© (Â§5.4.4.1) | Opik í† í° ì¶”ì  | ì „ì›” ëŒ€ë¹„ ê°ì†Œ |
| **QualityCostParetoScore** | Cost | ë¹„ìš©-í’ˆì§ˆ íŒŒë ˆí†  íš¨ìœ¨ì„± (Â§5.4.4.1) | íŒŒë ˆí†  í”„ë¡ í‹°ì–´ ê±°ë¦¬ | â‰¥ 0.8 |

```python
# evaluation/metrics/custom_metrics.py
class RoutingAccuracyMetric:
    """ì—ì´ì „íŠ¸ ë¼ìš°íŒ… ì •í™•ë„ ì¸¡ì •"""
    
    def evaluate(self, traces: List[AgentTrace], ground_truth: List[str]) -> float:
        correct = 0
        total = len(traces)
        
        for trace, expected in zip(traces, ground_truth):
            selected_agent = trace.router_decision.selected_agent
            if selected_agent == expected:
                correct += 1
                
        return correct / total if total > 0 else 0.0


class ConflictResolutionScoreMetric:
    """Hierarchy of Truth ì¤€ìˆ˜ìœ¨ ì¸¡ì •"""
    
    def evaluate(self, supervisor_results: List[SupervisorResult]) -> float:
        compliant = 0
        total_conflicts = 0
        
        for result in supervisor_results:
            if result.conflicts_detected > 0:
                total_conflicts += result.conflicts_detected
                if result.resolution_method == "hierarchy_of_truth":
                    # ìš°ì„ ìˆœìœ„ ê·œì¹™ ì¤€ìˆ˜ ì—¬ë¶€ í™•ì¸
                    if self._verify_hierarchy_compliance(result):
                        compliant += result.conflicts_detected
                        
        return compliant / total_conflicts if total_conflicts > 0 else 1.0
    
    def _verify_hierarchy_compliance(self, result: SupervisorResult) -> bool:
        """Hierarchy of Truth ìš°ì„ ìˆœìœ„ ê²€ì¦"""
        for resolution in result.resolutions:
            winner = resolution.selected_source
            losers = resolution.rejected_sources
            winner_priority = self.HIERARCHY[winner.type]
            
            for loser in losers:
                if self.HIERARCHY[loser.type] > winner_priority:
                    return False  # ë‚®ì€ ìš°ì„ ìˆœìœ„ê°€ ì„ íƒë¨
        return True


class HallucinationMetric:
    """í™˜ê° íƒì§€ ë©”íŠ¸ë¦­ (LLM-as-a-Judge)"""
    
    def evaluate(self, responses: List[str], contexts: List[str]) -> float:
        hallucination_count = 0
        
        for response, context in zip(responses, contexts):
            prompt = f"""
            ë‹¤ìŒ ì‘ë‹µì´ ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì›ë˜ì§€ ì•ŠëŠ” ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
            
            ì»¨í…ìŠ¤íŠ¸: {context}
            ì‘ë‹µ: {response}
            
            í™˜ê° ì—¬ë¶€ (YES/NO):
            """
            
            result = self.llm.generate(prompt)
            if "YES" in result.upper():
                hallucination_count += 1
                
        return hallucination_count / len(responses) if responses else 0.0
```

##### 5.4.4.1 Context Token Efficiency ë©”íŠ¸ë¦­ (KGC2026 ì¸ì‚¬ì´íŠ¸ ë°˜ì˜)

> **ğŸ“Œ ì¶œì²˜:** ì •ì´íƒœ, "Mastering Graph Agents: Unifying LPG & RDF Workflows with Opik for Financial GraphRAG" (KGC2026 ë°œí‘œ)
> **í•µì‹¬ ì¸ì‚¬ì´íŠ¸:** LPGì™€ RDFê°€ ì˜í•˜ëŠ” ê²ƒì´ ë”°ë¡œ ìˆìœ¼ë©°, 'ì˜í•œë‹¤'ì˜ ê¸°ì¤€ì€ ë‹¨ìˆœ ì •í™•ë„ë¿ ì•„ë‹ˆë¼ Generation Stageì—ì„œ Agentì—ê²Œ ì œê³µí•˜ëŠ” í”„ë¡¬í”„íŠ¸ ë¹„ìš©(KVCache) ì‹¤ë¬´ ê´€ì ê¹Œì§€ í¬í•¨í•´ì•¼ í•œë‹¤.

LPGì™€ RDFëŠ” ë™ì¼í•œ ë¹„ì¦ˆë‹ˆìŠ¤ ì§ˆì˜ì— ëŒ€í•´ ì„œë¡œ ë‹¤ë¥¸ í˜•íƒœì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. LPGëŠ” Cypher ì¿¼ë¦¬ ê²°ê³¼ë¡œ êµ¬ì¡°í™”ëœ compactí•œ ì‘ë‹µì„ ë°˜í™˜í•˜ëŠ” ë°˜ë©´, RDF íŠ¸ë¦¬í”Œì€ ì‹œë§¨í‹± ì¶”ë¡ ì— ê°•í•˜ì§€ë§Œ verboseí•œ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì°¨ì´ëŠ” API ë¹„ìš©ê³¼ KVCache íš¨ìœ¨ì„±ì— ì§ì ‘ì  ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.

**ë©”íŠ¸ë¦­ ì •ì˜:**

| ë©”íŠ¸ë¦­ | ê³„ì‚°ì‹ | ì¸¡ì • ë‹¨ìœ„ | ë¹„êµ ê¸°ì¤€ |
| :--- | :--- | :--- | :--- |
| **CTE (Context Token Efficiency)** | AnswerRelevance Score / context_tokens | ì ìˆ˜/í† í° | A1 vs A2 vs A4 ê°„ ë¹„êµ |
| **KVCache Cost per Query** | (cache_creation Ã— $rateâ‚) + (cache_read Ã— $rateâ‚‚) + (uncached Ã— $rateâ‚ƒ) | USD/query | ì‹¤í—˜ë³„ ì ˆëŒ€ ë¹„ìš© ë¹„êµ |
| **Quality-Cost Pareto Score** | íŒŒë ˆí†  í”„ë¡ í‹°ì–´ê¹Œì§€ì˜ ì •ê·œí™” ê±°ë¦¬ (0~1) | ë¬´ì°¨ì› | 1.0 = íŒŒë ˆí†  ìµœì  |

**ì¸¡ì • íŒŒì´í”„ë¼ì¸:**

```python
# evaluation/metrics/cost_efficiency_metrics.py
from dataclasses import dataclass
from typing import Dict, List, Tuple

@dataclass
class CostEfficiencyResult:
    ablation_id: str
    context_token_efficiency: float  # CTE = score / context_tokens
    kvcache_cost_per_query: float    # USD per query
    avg_prompt_tokens: int
    avg_context_tokens: int          # LPG/RDF ì»¨í…ìŠ¤íŠ¸ í† í°ë§Œ ë¶„ë¦¬ ì¸¡ì •
    quality_score: float

class ContextTokenEfficiencyMetric:
    """LPG/RDF ì»¨í…ìŠ¤íŠ¸ì˜ í† í° íš¨ìœ¨ì„± ì¸¡ì •
    
    KGC2026 ë°œí‘œì—ì„œ ì œì‹œëœ KVCache ì‹¤ë¬´ ê´€ì ì„ DataNexus
    Ablation ì‹¤í—˜ì— ì ìš©í•©ë‹ˆë‹¤.
    """
    
    # Anthropic Claude API ìš”ê¸ˆ ê¸°ì¤€ (2026.02 ê¸°ì¤€)
    PRICE_PER_INPUT_TOKEN = 0.000003      # $3/MTok (uncached)
    PRICE_PER_CREATION_TOKEN = 0.00000375  # $3.75/MTok (cache write)
    PRICE_PER_READ_TOKEN = 0.0000003      # $0.30/MTok (cache read)
    
    def evaluate(self, traces: List[AgentTrace]) -> Dict[str, CostEfficiencyResult]:
        """Ablation ì‹¤í—˜ë³„ ë¹„ìš© íš¨ìœ¨ì„± í‰ê°€"""
        results = {}
        
        for trace in traces:
            # Opik Traceì—ì„œ í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
            token_usage = self._extract_token_usage(trace)
            
            # CTE ê³„ì‚°: í’ˆì§ˆ ì ìˆ˜ / ì»¨í…ìŠ¤íŠ¸ í† í° ìˆ˜
            cte = (
                trace.answer_relevance_score / token_usage.context_tokens
                if token_usage.context_tokens > 0 else 0
            )
            
            # KVCache ë¹„ìš© ê³„ì‚°
            kvcache_cost = (
                token_usage.cache_creation_tokens * self.PRICE_PER_CREATION_TOKEN
                + token_usage.cache_read_tokens * self.PRICE_PER_READ_TOKEN
                + token_usage.uncached_tokens * self.PRICE_PER_INPUT_TOKEN
            )
            
            results[trace.experiment_id] = CostEfficiencyResult(
                ablation_id=trace.experiment_id,
                context_token_efficiency=cte,
                kvcache_cost_per_query=kvcache_cost,
                avg_prompt_tokens=token_usage.total_prompt_tokens,
                avg_context_tokens=token_usage.context_tokens,
                quality_score=trace.answer_relevance_score
            )
        
        return results
    
    def _extract_token_usage(self, trace: AgentTrace) -> TokenUsage:
        """Opik Traceì—ì„œ LPG/RDFë³„ ì»¨í…ìŠ¤íŠ¸ í† í° ë¶„ë¦¬ ì¶”ì¶œ
        
        Agentë³„ tool_call ê²°ê³¼ì˜ í† í° ìˆ˜ë¥¼ ë¶„ë¦¬ ì¸¡ì •:
        - Graph Agent (LPG): Cypher ê²°ê³¼ í† í°
        - Graph Agent (RDF): SPARQL/Triple ê²°ê³¼ í† í°
        - Vector Agent: ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ í† í°
        """
        context_tokens = 0
        for step in trace.steps:
            if step.agent_type in ["graph_lpg", "graph_rdf", "vector"]:
                context_tokens += step.output_tokens
        
        return TokenUsage(
            total_prompt_tokens=trace.total_prompt_tokens,
            context_tokens=context_tokens,
            cache_creation_tokens=trace.cache_creation_input_tokens,
            cache_read_tokens=trace.cache_read_input_tokens,
            uncached_tokens=trace.total_prompt_tokens - trace.cache_read_input_tokens
        )
    
    def compute_pareto_frontier(
        self, results: Dict[str, CostEfficiencyResult]
    ) -> List[CostEfficiencyResult]:
        """ë¹„ìš©-í’ˆì§ˆ íŒŒë ˆí†  í”„ë¡ í‹°ì–´ ê³„ì‚°
        
        Xì¶•: KVCache Cost (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        Yì¶•: Quality Score (ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)
        íŒŒë ˆí†  ìµœì : ë¹„ìš©ì„ ë” ì¤„ì´ë©´ í’ˆì§ˆì´ ë–¨ì–´ì§€ëŠ” ì§€ì 
        """
        points = sorted(results.values(), key=lambda r: r.kvcache_cost_per_query)
        frontier = []
        max_quality = -1
        
        for point in points:
            if point.quality_score > max_quality:
                frontier.append(point)
                max_quality = point.quality_score
        
        return frontier
```

**Ablation ì‹¤í—˜ë³„ ê¸°ëŒ€ ë¹„ìš©-í’ˆì§ˆ í”„ë¡œíŒŒì¼:**

| ì‹¤í—˜ ID | êµ¬ì„± | ì˜ˆìƒ ì»¨í…ìŠ¤íŠ¸ íŠ¹ì„± | CTE ê°€ì„¤ |
|---------|------|------------------|----------|
| **A1** | LPG Only | Compact (Cypher ê²°ê³¼: í…Œì´ë¸”/JSON) | ë†’ìŒ (ì ì€ í† í°ìœ¼ë¡œ êµ¬ì¡°í™”ëœ ë‹µë³€) |
| **A2** | RDF Only | Verbose (Triple ì—´ê±°, ì¶”ë¡  ì²´ì¸) | ë‚®ìŒ (ì‹œë§¨í‹± í’ë¶€í•˜ë‚˜ í† í° ë‹¤ëŸ‰ ì†Œë¹„) |
| **A3** | HYBRID Only | ì¤‘ê°„ (ì²­í¬ ê¸°ë°˜ ë¬¸ì„œ ê²€ìƒ‰) | ì¤‘ê°„ |
| **A4** | LPG + RDF | ë³µí•© (êµ¬ì¡° + ì‹œë§¨í‹± ë³‘í•©) | A1, A2ì˜ ê°€ì¤‘ í‰ê·  ë¶€ê·¼ |
| **A5** | LPG + HYBRID | LPG compact + ë¬¸ì„œ ë³´ê°• | A1ë³´ë‹¤ ë‚®ìœ¼ë‚˜ í’ˆì§ˆ ìƒìŠ¹ |
| **A6** | RDF + HYBRID | RDF verbose + ë¬¸ì„œ ì¤‘ë³µ ê°€ëŠ¥ | ìµœì € CTE ìœ„í—˜ (í† í° ìµœë‹¤) |

**Opik ëŒ€ì‹œë³´ë“œ í™•ì¥:**

| íŒ¨ë„ | ì‹œê°í™” | ìš©ë„ |
|------|--------|------|
| **CTE Comparison** | A1~A6 ë§‰ëŒ€ ê·¸ë˜í”„ (CTE ê°’) | LPG vs RDF í† í° íš¨ìœ¨ì„± ì¦‰ì‹œ ë¹„êµ |
| **Cost-Quality Scatter** | X: KVCache Cost, Y: Quality Score | íŒŒë ˆí†  í”„ë¡ í‹°ì–´ ì‹œê°í™” |
| **Token Breakdown** | Stacked Bar (LPG/RDF/Vector ì»¨í…ìŠ¤íŠ¸) | ì‹¤í—˜ë³„ í† í° êµ¬ì„± ë¶„ì„ |
| **Cost Trend** | ì‹œê³„ì—´ ë¼ì¸ì°¨íŠ¸ (ì¼/ì£¼ë³„) | KVCache ë¹„ìš© ì¶”ì´ ëª¨ë‹ˆí„°ë§ |

#### 5.4.5 Opik ì—°ë™ (LLM Observability)

Opik(Comet ML)ê³¼ ì—°ë™í•˜ì—¬ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì¶”ì í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.

```python
# evaluation/integrations/opik_integration.py
from opik import Opik

class OpikEvaluationTracker:
    """Opik ê¸°ë°˜ ì‹¤í—˜ ì¶”ì """
    
    def __init__(self, project_name: str = "datanexus-eval"):
        self.opik = Opik(project_name=project_name)
        self.cost_metric = ContextTokenEfficiencyMetric()  # Â§5.4.4.1
        
    def log_experiment(self, experiment: ExperimentResult):
        """ì‹¤í—˜ ê²°ê³¼ ë¡œê¹… (í’ˆì§ˆ + ë¹„ìš© ë©”íŠ¸ë¦­ í†µí•©)"""
        self.opik.log({
            "experiment_id": experiment.experiment_id,
            "metrics": experiment.metrics.to_dict(),
            "cost_metrics": {
                "context_token_efficiency": experiment.cost_metrics.cte,
                "kvcache_cost_per_query": experiment.cost_metrics.kvcache_cost,
                "avg_context_tokens": experiment.cost_metrics.avg_context_tokens,
                "quality_cost_pareto_score": experiment.cost_metrics.pareto_score,
            } if experiment.cost_metrics else {},
            "config": experiment.config,
            "timestamp": experiment.timestamp
        })
        
    def export_traces(self, trace_ids: List[str], output_path: str):
        """íŠ¸ë ˆì´ìŠ¤ Export"""
        traces = self.opik.get_traces(trace_ids)
        with open(output_path, "w") as f:
            json.dump(traces, f, indent=2)
            
    def create_dataset(self, name: str, queries: List[str], ground_truths: List[str]):
        """í‰ê°€ ë°ì´í„°ì…‹ ìƒì„±"""
        dataset = self.opik.create_dataset(
            name=name,
            data=[
                {"query": q, "ground_truth": gt}
                for q, gt in zip(queries, ground_truths)
            ]
        )
        return dataset.id
```

**Opik ëŒ€ì‹œë³´ë“œ í™œìš©:**

| ê¸°ëŠ¥ | ì„¤ëª… | ìš©ë„ |
|------|------|------|
| **Trace Viewer** | ì—ì´ì „íŠ¸ ì‹¤í–‰ ì²´ì¸ ì‹œê°í™” | ë””ë²„ê¹…, ë³‘ëª© ë¶„ì„ |
| **Metrics Dashboard** | ì‹¤í—˜ë³„ ë©”íŠ¸ë¦­ ë¹„êµ ì°¨íŠ¸ | ì„±ëŠ¥ ì¶”ì´ ëª¨ë‹ˆí„°ë§ |
| **Dataset Manager** | í‰ê°€ ë°ì´í„°ì…‹ ë²„ì „ ê´€ë¦¬ | ì¬í˜„ ê°€ëŠ¥í•œ í‰ê°€ |
| **A/B Comparison** | ì‹¤í—˜ ê°„ ì§ì ‘ ë¹„êµ | ì•„í‚¤í…ì²˜ ê²°ì • |
| **Cost-Quality Analysis** | CTE/KVCache ë¹„ìš©-í’ˆì§ˆ íŒŒë ˆí†  ì°¨íŠ¸ (Â§5.4.4.1) | LPG vs RDF í† í° íš¨ìœ¨ì„± ë¹„êµ |

#### 5.4.6 í‰ê°€ í’ˆì§ˆ ê²Œì´íŠ¸ (SEOCHO í™•ì¥)

| ë‹¨ê³„ | í’ˆì§ˆ ê²Œì´íŠ¸ | í†µê³¼ ê¸°ì¤€ | ì‹¤íŒ¨ ì‹œ ì¡°ì¹˜ |
| :--- | :--- | :--- | :--- |
| **Macro** | M1 vs M2 ì°¨ì´ | â‰¤ 10% | Manager ë¡œì§ ê²€í†  |
| **Macro** | M1 vs M3 ì°¨ì´ | â‰¥ 10% | ì˜¨í†¨ë¡œì§€ ê¸°ì—¬ë„ ê²€ì¦ ì™„ë£Œ |
| **Ablation** | A4 > A1 + A2 | Synergy í™•ì¸ (êµí˜¸ì‘ìš© > 0.05) | ì¡°í•© íš¨ê³¼ ê²€ì¦ â€” `analyze_interaction_effects()` ì°¸ì¡° |
| **Metrics** | RoutingAccuracy | â‰¥ 95% | Router ë¶„ë¥˜ê¸° ì¬í•™ìŠµ |
| **Metrics** | ConflictResolutionScore | â‰¥ 95% | Hierarchy ë¡œì§ ê²€í†  |
| **Metrics** | Hallucination Rate | â‰¤ 0.05 (ratio) | ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ ê°œì„  |
| **Cost** | CTE (A1 vs A2 ë¹„êµ) | LPG CTE â‰¥ RDF CTE | RDF ì»¨í…ìŠ¤íŠ¸ ì••ì¶• ì „ëµ ê²€í†  |
| **Cost** | KVCache Cost ì¶”ì´ | ì „ì›” ëŒ€ë¹„ ì¦ê°€ â‰¤ 10% | í”„ë¡¬í”„íŠ¸ ìµœì í™” + ìºì‹œ ì¸ì‹ í”„ë£¨ë‹ ê°•í™” |
| **Cost** | Quality-Cost Pareto Score | â‰¥ 0.8 | ë¹„ìš© ëŒ€ë¹„ í’ˆì§ˆ ì €í•˜ êµ¬ì„± ì œê±° ê²€í†  |

---

> **ğŸ“Œ ë©”ë‰´ êµ¬ì¡° ì°¸ì¡°:** ì‚¬ìš©ì ë©”ë‰´(Â§6.6) ë° ê´€ë¦¬ì ë©”ë‰´(Â§6.7)ëŠ” [PRD_06_Requirements_Roadmap_final.md](PRD_06_Requirements_Roadmap_final.md)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

---

### 5.5 ì—ëŸ¬ ì²˜ë¦¬ ë° Fallback ì „ëµ

> **âš ï¸ ì—ëŸ¬ ì²˜ë¦¬ êµ¬ì²´í™” ë¯¸í¡ (ë¦¬ë·° ë³´ê³ ì„œ Â§1-4)**

ê¸°ì¡´ Â§5.2ì˜ Error TaxonomyëŠ” ë¶„ë¥˜ë§Œ ìˆê³  ëŒ€ì‘ ì „ëµì´ ë¶€ì¬í•©ë‹ˆë‹¤. ì•„ë˜ì— ì—ëŸ¬ ìœ í˜•ë³„ êµ¬ì²´ì  ì²˜ë¦¬ íë¦„ì„ ì •ì˜í•©ë‹ˆë‹¤.

#### 5.5.1 NL2SQL ì—ëŸ¬ ì²˜ë¦¬ íë¦„

```txt
[SQL ìƒì„± ì‹¤íŒ¨]
    â”œâ”€â†’ Syntax Error â†’ Vanna ì¬ì‹œë„ (max 2íšŒ, ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸)
    â”‚       â””â”€â†’ ì¬ì‹œë„ ì‹¤íŒ¨ â†’ "ì§ˆë¬¸ì„ ë‹¤ì‹œ í‘œí˜„í•´ì£¼ì„¸ìš”" + ìœ ì‚¬ ì§ˆë¬¸ ì œì•ˆ
    â”œâ”€â†’ Schema Linking ì‹¤íŒ¨ â†’ DataHubì—ì„œ ìœ ì‚¬ í…Œì´ë¸”/ì»¬ëŸ¼ ê²€ìƒ‰
    â”‚       â””â”€â†’ í›„ë³´ ë°œê²¬ â†’ "í˜¹ì‹œ [í›„ë³´]ë¥¼ ë§ì”€í•˜ì‹œë‚˜ìš”?" í™•ì¸ ì§ˆë¬¸
    â”‚       â””â”€â†’ í›„ë³´ ì—†ìŒ â†’ "í•´ë‹¹ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" + ì¹´íƒˆë¡œê·¸ ê²€ìƒ‰ ì•ˆë‚´
    â”œâ”€â†’ Execution Timeout (>30ì´ˆ) â†’ ì¿¼ë¦¬ ì·¨ì†Œ + ì§‘ê³„ ë²”ìœ„ ì¶•ì†Œ ì œì•ˆ
    â””â”€â†’ Permission Denied â†’ "ì ‘ê·¼ ê¶Œí•œì´ ì—†ëŠ” ë°ì´í„°ì…ë‹ˆë‹¤" + ê¶Œí•œ ìš”ì²­ ì•ˆë‚´
```

#### 5.5.2 RAG ê²€ìƒ‰ ì—ëŸ¬ ì²˜ë¦¬ íë¦„

```txt
[ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨]
    â”œâ”€â†’ Empty Results â†’ ê²€ìƒ‰ì–´ í™•ì¥ (ë™ì˜ì–´ ê¸°ë°˜) ì¬ì‹œë„
    â”‚       â””â”€â†’ ì¬ì‹œë„ ì‹¤íŒ¨ â†’ "ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" + ê²€ìƒ‰ í‚¤ì›Œë“œ ì œì•ˆ
    â”œâ”€â†’ Low Relevance (score < 0.6) â†’ ê²°ê³¼ ì œê³µ + "ê´€ë ¨ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤" ê²½ê³ 
    â””â”€â†’ ApeRAG ì„œë¹„ìŠ¤ ì¥ì•  â†’ NL2SQLë§Œìœ¼ë¡œ ë¶€ë¶„ ì‘ë‹µ + "ë¬¸ì„œ ê²€ìƒ‰ ì¼ì‹œ ì¤‘ë‹¨" ì•Œë¦¼
```

#### 5.5.3 Agent ê°„ í†µì‹  ì—ëŸ¬ ì²˜ë¦¬

| ì—ëŸ¬ ìœ í˜• | ê°ì§€ ë°©ë²• | Fallback ì „ëµ | ì‚¬ìš©ì ì•ˆë‚´ |
|----------|----------|--------------|-----------|
| Graph Agent íƒ€ì„ì•„ì›ƒ | 30ì´ˆ ì´ˆê³¼ | Vector Agent ê²°ê³¼ë§Œìœ¼ë¡œ ì‘ë‹µ | "ê·¸ë˜í”„ ê²€ìƒ‰ì´ ì§€ì—°ë˜ì–´ ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤" |
| Supervisor ì¶©ëŒ í•´ê²° ì‹¤íŒ¨ | ConflictResolutionScore < 0.5 | ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„ ì†ŒìŠ¤ë§Œ ì‚¬ìš© | "ë³µìˆ˜ ì†ŒìŠ¤ ê°„ ì •ë³´ê°€ ìƒì´í•˜ì—¬ ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ê²°ê³¼ë¥¼ ì œê³µí•©ë‹ˆë‹¤" |
| ì „ì²´ Agent ì¥ì•  | ëª¨ë“  Agent ì‘ë‹µ ì—†ìŒ | ê¸°ë³¸ LLM ì‘ë‹µ (ì»¨í…ìŠ¤íŠ¸ ì—†ì´) | "ì‹œìŠ¤í…œ ì¼ì‹œ ì¥ì• ë¡œ ì¼ë°˜ì ì¸ ë‹µë³€ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤" |

---

### 5.6 ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€

> **âš ï¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ êµ¬ì²´í™” ë¯¸í¡ (ë¦¬ë·° ë³´ê³ ì„œ Â§1-5)**

| ì§€í‘œ | ì¸¡ì • ë°©ë²• | MVP ê¸°ì¤€ | Phase 2 ê¸°ì¤€ | ì¸¡ì • ë„êµ¬ |
|------|----------|---------|-------------|----------|
| **ì‘ë‹µ ì‹œì‘ ì‹œê°„** | ì²« SSE ì´ë²¤íŠ¸ê¹Œì§€ | â‰¤ 2ì´ˆ | â‰¤ 1ì´ˆ | Opik Trace |
| **ì „ì²´ ì‘ë‹µ ì‹œê°„ (P95)** | ë§ˆì§€ë§‰ SSE ì´ë²¤íŠ¸ê¹Œì§€ | â‰¤ 5ì´ˆ | â‰¤ 3ì´ˆ | Opik Trace |
| **SQL ìƒì„± ì‹œê°„** | Vanna generate_sql í˜¸ì¶œ ì‹œê°„ | â‰¤ 3ì´ˆ | â‰¤ 2ì´ˆ | Vanna Metrics |
| **ê·¸ë˜í”„ ì¿¼ë¦¬ ì‹œê°„** | Cypher ì‹¤í–‰ ì‹œê°„ | â‰¤ 2ì´ˆ | â‰¤ 1ì´ˆ | Neo4j Metrics |
| **RAG ê²€ìƒ‰ ì‹œê°„** | ApeRAG API ì‘ë‹µ ì‹œê°„ | â‰¤ 2ì´ˆ | â‰¤ 1.5ì´ˆ | ApeRAG Metrics |
| **ë™ì‹œ ì‚¬ìš©ì** | ì„±ëŠ¥ ì €í•˜ ì—†ëŠ” ìµœëŒ€ ë™ì‹œ ì ‘ì† | 50ëª… | 200ëª… | k6/Locust |
| **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰** | Agent ì„œë¹„ìŠ¤ ì»¨í…Œì´ë„ˆ ê¸°ì¤€ | â‰¤ 4GB | â‰¤ 8GB | Prometheus |

#### 5.6.1 NL2SQL Baseline ì •í™•ë„ ì»¨í…ìŠ¤íŠ¸ (ì™¸ë¶€ ë²¤ì¹˜ë§ˆí¬)

> **ğŸ“Œ ë°°ê²½:** DataNexusì˜ EX(Execution Accuracy) ëª©í‘œ(MVP â‰¥ 80%, Phase 2 â‰¥ 90%)ê°€ í˜„ì‹¤ì ì¸ì§€ íŒë‹¨í•˜ë ¤ë©´ ì—…ê³„ baselineì„ ì´í•´í•´ì•¼ í•œë‹¤. Snowflakeê°€ ê³µê°œí•œ ë‚´ë¶€ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ì™€ Vanna AI ì»¤ë®¤ë‹ˆí‹° ì‹¤ì¸¡ê°’ì„ ì¢…í•©í•˜ì—¬ ì•„ë˜ í‘œë¡œ ì •ë¦¬í•œë‹¤.

| ì¡°ê±´ | ì •í™•ë„ | ì¶œì²˜ |
|------|--------|------|
| GPT-4o ë‹¨ë… (RAG ì—†ìŒ, ìŠ¤í‚¤ë§ˆë§Œ ì œê³µ) | ~51% | Snowflake ë‚´ë¶€ ë²¤ì¹˜ë§ˆí¬ (Cortex Analyst Behind the Scenes) |
| RAG ê¸°ë°˜ Text-to-SQL (Q-SQL ìŒ + DDL + ë¬¸ì„œ) | ~70-75% | MITB For All (2025.06), Vanna AI ì‹¤ì¸¡ |
| Snowflake Cortex Analyst (Semantic View + RAG + Multi-Agent) | ~85-90% (ì¶”ì •) | Snowflake ê³µì‹ ë¸”ë¡œê·¸ |
| **DataNexus ëª©í‘œ (ì˜¨í†¨ë¡œì§€ + RAG + Multi-Agent)** | **â‰¥ 80% (MVP) / â‰¥ 90% (Phase 2)** | **ë³¸ PRD** |

**ì‹œì‚¬ì :**
- LLM ë‹¨ë…ìœ¼ë¡œëŠ” 51%ì— ë¶ˆê³¼í•˜ë¯€ë¡œ, RAG ì—†ëŠ” NL2SQLì€ í”„ë¡œë•ì…˜ ë¶ˆê°€. DataNexusê°€ Vanna RAGë¥¼ ì±„íƒí•œ í•µì‹¬ ê·¼ê±°ì„
- Vanna RAG ì ìš©ë§Œìœ¼ë¡œ 20%p ì´ìƒ ê°œì„  ê°€ëŠ¥í•˜ë©°, DataNexusì˜ ì˜¨í†¨ë¡œì§€ ì»¨í…ìŠ¤íŠ¸ ì£¼ì…(Â§4.3)ì€ ì¶”ê°€ 10-15%p í–¥ìƒ ì˜ˆìƒ
- MVP 80% ëª©í‘œëŠ” RAG + ì˜¨í†¨ë¡œì§€ ì¡°í•© ì‹œ ë‹¬ì„± ê°€ëŠ¥í•œ í˜„ì‹¤ì  ìˆ˜ì¤€
- Phase 2 ëª©í‘œ 90%ëŠ” Tool Memory ìë™ í•™ìŠµ(Â§3.10) + Few-shot í™•ëŒ€(Â§4.2.4) + ì˜¨í†¨ë¡œì§€ ê³ ë„í™” ì „ì œ

**Ablation ì‹¤í—˜ ì—°ê³„:**
- ì‹¤í—˜ A1(ì˜¨í†¨ë¡œì§€ ì œê±°)ì—ì„œ ì •í™•ë„ í•˜ë½í­ì´ 15-20%pë©´, ì˜¨í†¨ë¡œì§€ ê¸°ì—¬ë„ê°€ ì…ì¦ë¨
- RAG ë‹¨ë… baseline(~70%)ê³¼ ë¹„êµí•˜ì—¬ ì˜¨í†¨ë¡œì§€ ì¶”ê°€ íš¨ê³¼ë¥¼ ì •ëŸ‰ ì¸¡ì •
- ê²½ìŸ ì†”ë£¨ì…˜ ì •í™•ë„ ë¹„êµëŠ” [ë¶€ë¡ B.8.5](./PRD_Appendix_AB_final.md) ì°¸ì¡°

> **ğŸ“Œ ì°¸ê³ :** Training ë°ì´í„° í¬ë§· ë° ê´€ë¦¬ ì „ëµì€ [PRD_03 Â§4.2.4](./PRD_03_Data_Pipeline_final.md) ì°¸ì¡°

---

### 5.7 ì™¸ë¶€ RAG ë²¤ì¹˜ë§ˆí‚¹ ì „ëµ (AutoRAG-Research)

> **ì˜¤ë²„ì—”ì§€ë‹ˆì–´ë§ ì£¼ì˜ (ë¦¬ë·° ë³´ê³ ì„œ Â§3-4 ì—°ì¥):**
> AutoRAG-Research í”„ë ˆì„ì›Œí¬ì˜ ì§ì ‘ í†µí•©(ì„¤ì¹˜, í”ŒëŸ¬ê·¸ì¸ ê°œë°œ, PostgreSQL+VectorChord ìŠ¤íƒ ì¶”ê°€)ì€ Phase 1 MVP ë²”ìœ„ì—ì„œ **ëª…ì‹œì ìœ¼ë¡œ ì œì™¸**í•©ë‹ˆë‹¤. MVP íŒŒì´í”„ë¼ì¸ì´ ì•ˆì •í™”ë˜ì§€ ì•Šì€ ìƒíƒœì—ì„œ ì™¸ë¶€ ë²¤ì¹˜ë§ˆí¬ë¥¼ ëŒë ¤ë„ ì˜ë¯¸ ìˆëŠ” ë¹„êµê°€ ë¶ˆê°€ëŠ¥í•˜ë©°, ì»¤ìŠ¤í…€ í”ŒëŸ¬ê·¸ì¸ ê°œë°œ ê³µìˆ˜ê°€ í•µì‹¬ ê¸°ëŠ¥ ê°œë°œì„ ì €í•´í•©ë‹ˆë‹¤.

**ì°¸ì¡°:** https://github.com/NomaDamas/AutoRAG-Research (Apache-2.0, v0.0.2)

#### 5.7.1 Phase 1 (MVP): ì„¤ê³„ ì°¸ê³  ìë£Œ í™œìš©

AutoRAG-Researchê°€ êµ¬í˜„í•œ SOTA íŒŒì´í”„ë¼ì¸ì˜ ì•„í‚¤í…ì²˜ì™€ ë…¼ë¬¸ ë ˆí¼ëŸ°ìŠ¤ë¥¼ SEOCHO ì„¤ê³„ ì‹œ ì°¸ê³ í•©ë‹ˆë‹¤. ë³„ë„ ì„¤ì¹˜ë‚˜ í†µí•© ì—†ì´ ì½”ë“œ ë¦¬ë”©ê³¼ ë…¼ë¬¸ ì°¸ì¡° ìˆ˜ì¤€ìœ¼ë¡œë§Œ í™œìš©í•©ë‹ˆë‹¤.

| AutoRAG-Research íŒŒì´í”„ë¼ì¸ | ì°¸ê³  ë…¼ë¬¸ | SEOCHO ì„¤ê³„ ì‹œì‚¬ì  |
|---------------------------|----------|-------------------|
| MAIN-RAG (Multi-Agent Filtering) | ACL 2025 | Router + Supervisor íŒ¨í„´ì˜ í•„í„°ë§ ì „ëµ ë¹„êµ. SEOCHOì˜ Hierarchy of Truth ì¶©ëŒ í•´ê²°ê³¼ MAIN-RAGì˜ ë‹¤ì¤‘ ì—ì´ì „íŠ¸ í•„í„°ë§ ì ‘ê·¼ë²• ê°„ ì°¨ì´ì  ë¶„ì„ |
| IRCoT (Interleaving Retrieval with CoT) | ACL 2023 | Multi-hop Inference ì„¤ê³„ ì‹œ ê²€ìƒ‰-ì¶”ë¡  ì¸í„°ë¦¬ë¹™ íŒ¨í„´ ì°¸ê³ . SEOCHOì˜ Graph + SQL ê²°í•© ì¿¼ë¦¬ì— CoT ê¸°ë°˜ ì¤‘ê°„ ê²€ìƒ‰ ë‹¨ê³„ ì ìš© ê°€ëŠ¥ì„± ê²€í†  |
| ET2RAG (Majority Voting on Context Subsets) | Preprint 2025 | ì»¨í…ìŠ¤íŠ¸ ì„œë¸Œì…‹ ë‹¤ìˆ˜ê²° íˆ¬í‘œ ë°©ì‹ì„ Supervisorì˜ ë‹¤ì¤‘ ì†ŒìŠ¤ ì‘ë‹µ ì‹ ë¢°ë„ í‰ê°€ì— ì°¸ê³  |
| HyDE (Hypothetical Document Embeddings) | ACL 2023 | ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ Taxonomy Injectionê³¼ HyDEì˜ ê°€ìƒ ë¬¸ì„œ ìƒì„± ì ‘ê·¼ë²• ê°„ ì¿¼ë¦¬ í™•ì¥ íš¨ê³¼ ë¹„êµ |
| Hybrid RRF / Hybrid CC | - | ApeRAG ë²¡í„°/ê·¸ë˜í”„ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ì˜ ìœµí•© ì „ëµ ì„¤ê³„ ì‹œ RRF vs Convex Combination íŠ¸ë ˆì´ë“œì˜¤í”„ ì°¸ê³  |

**í™œìš© ë°©ë²•:** AutoRAG-Research GitHub ë ˆí¬ì§€í† ë¦¬ì˜ `autorag_research/` ë””ë ‰í† ë¦¬ì—ì„œ í•´ë‹¹ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ ì½”ë“œë¥¼ ë¦¬ë·°í•˜ê³ , SEOCHO ì„¤ê³„ ë¬¸ì„œ(`.claude/DESIGN-*.md`)ì— ì°¸ê³  ì‚¬í•­ì„ ê¸°ë¡í•©ë‹ˆë‹¤.

**ê¸ˆì§€ ì‚¬í•­ (Phase 1):**
- AutoRAG-Research íŒ¨í‚¤ì§€ ì„¤ì¹˜ ê¸ˆì§€
- PostgreSQL + VectorChord ë³„ë„ ìŠ¤íƒ êµ¬ì„± ê¸ˆì§€
- ì»¤ìŠ¤í…€ í”ŒëŸ¬ê·¸ì¸ ê°œë°œ ì°©ìˆ˜ ê¸ˆì§€
- ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°ì…‹(BEIR, RAGBench ë“±) ìˆ˜ì§‘/ì‹¤í–‰ ê¸ˆì§€

#### 5.7.2 Phase 2 (ì•ˆì •í™” ì´í›„): ì •ëŸ‰ ë²¤ì¹˜ë§ˆí‚¹ ë„ì…

Phase 2.0ì—ì„œ DataNexusì˜ í•µì‹¬ íŒŒì´í”„ë¼ì¸(NL2SQL, í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰, ë©€í‹°ì—ì´ì „íŠ¸ ë¼ìš°íŒ…)ì´ í’ˆì§ˆ ê¸°ì¤€ì„ (EX â‰¥ 90%, P95 < 3s â€” Â§5.1 Phase 2 ëª©í‘œ ê¸°ì¤€)ì„ ë‹¬ì„±í•œ ì´í›„ì— AutoRAG-Researchë¥¼ í™œìš©í•œ ì •ëŸ‰ ë¹„êµë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.

**Phase 2 ë„ì… ì „ì œì¡°ê±´:**
- Stage 4 E2E í’ˆì§ˆ ê²Œì´íŠ¸ í†µê³¼ (Â§5.3.6)
- ë‚´ë¶€ ë²¤ì¹˜ë§ˆí¬ ê¸°ì¤€ì„  í™•ë¦½ (EX, VES, QVT ì¸¡ì • ì™„ë£Œ)
- DataNexus íŒŒì´í”„ë¼ì¸ì˜ API ì¸í„°í˜ì´ìŠ¤ ì•ˆì •í™”

**Phase 2 ë²¤ì¹˜ë§ˆí‚¹ ìˆœì„œ:**

| ìˆœì„œ | ì‘ì—… | ë°ì´í„°ì…‹ | ëª©ì  | ì˜ˆìƒ ê³µìˆ˜ |
|------|------|---------|------|-----------|
| 1 | AutoRAG-Research í™˜ê²½ êµ¬ì¶• | BEIR (scifact) | í”„ë ˆì„ì›Œí¬ ë™ì‘ í™•ì¸ + ê¸°ì¤€ì„  | 3ì¼ |
| 2 | MrTyDi í•œêµ­ì–´ ê²€ìƒ‰ í‰ê°€ | MrTyDi (ko) | í•œêµ­ì–´ ê²€ìƒ‰ ì„±ëŠ¥ ê°ê´€ì  ì¸¡ì • | 3ì¼ |
| 3 | RAGBench E2E í‰ê°€ | RAGBench | ê²€ìƒ‰+ìƒì„± í’ˆì§ˆ ì¢…í•© ë¹„êµ | 5ì¼ |
| 4 | datanexus-hybrid-search í”ŒëŸ¬ê·¸ì¸ | BEIR, RAGBench | ApeRAG í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ vs SOTA ë¹„êµ | 2ì£¼ |

**Phase 3+ í™•ì¥ (ì„ íƒ):**
- datanexus-seocho-rag í”ŒëŸ¬ê·¸ì¸: SEOCHO ë©€í‹°ì—ì´ì „íŠ¸ E2E RAG vs MAIN-RAG ë¹„êµ
- BRIGHT ì¶”ë¡  ì§‘ì•½í˜• ë²¤ì¹˜ë§ˆí¬: Multi-hop Inference í’ˆì§ˆ í‰ê°€
- Open-RAGBench ë©€í‹°ëª¨ë‹¬: ApeRAG MinerU íŒŒì‹± í’ˆì§ˆ í‰ê°€

#### 5.7.3 í’ˆì§ˆ ê²Œì´íŠ¸ ì—°ë™ (Phase 2+)

AutoRAG-Research ë©”íŠ¸ë¦­ì„ DataNexus ë‚´ë¶€ í’ˆì§ˆ ì§€í‘œì™€ êµì°¨ ê²€ì¦í•©ë‹ˆë‹¤.

| DataNexus ë‚´ë¶€ ì§€í‘œ | AutoRAG-Research ë©”íŠ¸ë¦­ | êµì°¨ ê²€ì¦ ëª©ì  |
|--------------------|----------------------|---------------|
| EX Accuracy (Â§5.1) | nDCG@10 + ROUGE-L | ë‚´ë¶€ ì¸¡ì •ì¹˜ì˜ ì™¸ë¶€ ë°ì´í„°ì…‹ ëŒ€ë¹„ ì¼ë°˜í™” ê°€ëŠ¥ì„± í™•ì¸ |
| Hallucination Rate (Â§5.1) | BERTScore-F1 | í™˜ê° íƒì§€ ê¸°ì¤€ì˜ ê°ê´€ì„± ê²€ì¦ |
| Query Router Accuracy (Â§5.1) | ì»¤ìŠ¤í…€ ë©”íŠ¸ë¦­ í”ŒëŸ¬ê·¸ì¸ | MAIN-RAG ëŒ€ë¹„ ë¼ìš°íŒ… íš¨ìœ¨ ë¹„êµ |
