[{"content":"외부와 말이 안 통했다 이전 글에서 DataHub + DozerDB 이중 구조로 내부 온톨로지 문제를 풀었다. 내부 시스템에서만 쓰기에는 충분했다.\n문제는 외부 시스템과의 연동이었다. 금융 도메인을 탐색하다가 FIBO(Financial Industry Business Ontology)를 발견했는데, 금융업계 표준 용어 체계로 \u0026ldquo;Financial Product\u0026rdquo;, \u0026ldquo;Loan\u0026rdquo;, \u0026ldquo;Interest Rate\u0026rdquo; 같은 개념이 계층으로 정리돼 있다. 유통 쪽도 마찬가지다. GS1의 GPC(Global Product Classification)에는 \u0026ldquo;의류 → 여성복 → 원피스\u0026quot;처럼 상품 분류 체계가 표준으로 잡혀 있다. 의료엔 SNOMED CT, 제조엔 ISA-95. 도메인마다 수천 개 용어가 이미 정리돼 있는데, 이걸 가져다 쓸 수 있으면 온톨로지를 밑바닥부터 만들 필요가 없다.\nFIBO 파일을 열어봤다. OWL 포맷이었다. DozerDB 그래프에 넣으려니 구조 자체가 안 맞았다. 반대 방향도 마찬가지 — DataNexus 온톨로지를 고객사 기존 시스템(Collibra, TopBraid 같은)에 내보내고 싶어도 표준 포맷이 없으니 방법이 없었다. 내부에서는 잘 돌아가는데 밖으로 꺼내는 순간 무용지물이 되는 상황.\n외부 호환이 안 되면 생기는 문제가 한두 개가 아니다. 대기업은 이미 Collibra나 Alation 같은 메타데이터 관리 툴을 쓰고 있는 경우가 많다. DataNexus를 도입한다고 기존 용어 체계를 버리진 않는다. 표준 포맷으로 내보낼 수 있으면 공존이 가능한데, 못하면 용어 수백 개를 수작업으로 옮겨야 한다. 그것만으로 몇 달이 날아간다.\n유통 그룹처럼 백화점·마트·온라인몰이 각각 \u0026ldquo;매출\u0026quot;을 다르게 정의하는 경우, 그룹 차원에서 용어를 통합하거나 최소한 매핑하려면 공통 포맷이 있어야 한다. 없으면 관계사마다 따로 논다. 금융권은 감독 기관에 데이터 계보(lineage)나 용어 정의를 보고해야 하는 규제 요건도 있다. 거기에 벤더 종속(vendor lock-in) 문제까지. DataNexus를 쓰다가 다른 플랫폼으로 바꿔야 할 수도 있는데, 표준 포맷으로 Export가 되면 옮길 수 있지만 안 되면 갇힌다. 도입을 결정하는 자리에서 이게 꽤 크게 작용한다.\n내부에서만 통하는 언어로는 외부와 대화할 수 없다.\n같은 그래프인데 언어가 다르다 DozerDB는 LPG(Labeled Property Graph) 방식을 쓴다.\n노드(동그라미)에 이름과 속성을 붙인다: 순매출 {definition: \u0026quot;총매출-반품-에누리\u0026quot;} 노드 사이에 화살표를 긋고, 그 화살표에도 속성을 단다: -[MANUFACTURES {since: \u0026quot;2024-01-01\u0026quot;}]-\u0026gt; 핵심은 화살표 자체에 \u0026ldquo;언제부터\u0026rdquo;, \u0026ldquo;신뢰도 얼마\u0026rdquo; 같은 정보를 달 수 있다는 점이다. 이전 글에서 MANUFACTURES, STOCKS 관계를 만들 때 이걸 활용했다.\nSKOS를 포함한 웹 표준들은 완전히 다른 체계를 쓴다. RDF(Resource Description Framework) — 모든 정보를 세 단어짜리 문장으로 쪼갠다.\n순매출 → broader → 매출 (순매출의 상위 개념은 매출이다) 순매출 → prefLabel → \u0026quot;순매출\u0026quot;@ko (한국어 이름은 \u0026ldquo;순매출\u0026quot;이다) 주술목(주어-서술어-목적어), 이 세 단어가 하나의 단위다. 트리플(triple) 이라고 부른다.\n여기서 갈린다. LPG는 관계에 속성을 자유롭게 붙일 수 있지만, RDF는 트리플이 원자 단위라서 관계 자체에 속성을 직접 달 수 없다. 대신 URI 기반이라 전 세계 어디서든 같은 개념을 같은 주소로 가리킬 수 있다. 시스템 간 데이터 교환에는 RDF가 압도적이다.\n내부 표현력의 LPG, 외부 호환성의 RDF. DataNexus에는 둘 다 필요했다.\nOWL은 과하고, RDFS는 부족하고 RDF 세계에도 표준이 여러 개다.\nOWL(Web Ontology Language) 은 가장 강력하다. 클래스 상속, 제약 조건, 자동 추론까지 지원한다. 법률 문서에 비유할 수 있다 — 모든 조항과 예외를 정밀하게 기술할 수 있는 대신 추론 엔진(Reasoner)을 별도로 띄워야 하고 학습 곡선이 가파르다. FIBO가 OWL인 이유도 금융 규제의 복잡성 때문이다.\nDataNexus가 하려는 건 추론이 아니다. \u0026ldquo;객단가가 뭔지, 어떤 테이블의 어떤 컬럼에 있는지\u0026quot;를 NL2SQL 엔진에 알려주는 맥락 제공이다. OWL은 과했다.\nRDFS(RDF Schema) 는 반대로 너무 가볍다. subClassOf 정도는 되는데 동의어나 용어 정의를 달 표준 속성이 없다.\nSKOS(Simple Knowledge Organization System) 가 딱 맞았다. 이름부터 \u0026ldquo;단순한 지식 조직 체계\u0026quot;다. 도서관 분류 체계나 시소러스(Thesaurus: 동의어·유의어·상하위어를 매핑해둔 용어 관계 사전)를 표현하려고 만든 W3C 표준인데 — DataNexus가 하는 일이 정확히 비즈니스 용어 사전 관리다. 핏이 맞을 수밖에 없다.\nSKOS 개념이 DataNexus 구조에 어떻게 대응되는지 정리하면:\nSKOS DataNexus (DataHub + DozerDB) 쉽게 말하면 skos:Concept Glossary Term / Entity 노드 용어 하나 skos:broader IsA 관계 (상위 개념) \u0026ldquo;객단가는 매출지표의 일종\u0026rdquo; skos:narrower IsA 역방향 (하위 개념) \u0026ldquo;매출지표의 하위에 객단가\u0026rdquo; skos:related RelatedTo 계열 \u0026ldquo;관련 있는 용어\u0026rdquo; * skos:prefLabel Term name (한국어 대표명) 공식 이름 skos:altLabel 동의어 (영문, 약어) \u0026ldquo;객단가\u0026rdquo; = \u0026ldquo;ATV\u0026rdquo;, \u0026ldquo;Average Transaction Value\u0026rdquo; skos:definition Term definition 용어 뜻풀이 skos:ConceptScheme 도메인별 용어 묶음 \u0026ldquo;유통 용어집\u0026rdquo;, \u0026ldquo;재무 용어집\u0026rdquo; * 주의할 점이 있다. skos:related는 양방향이다. \u0026ldquo;A related B\u0026quot;이면 자동으로 \u0026ldquo;B related A\u0026quot;도 성립한다. DozerDB의 SELLS나 SUPPLIED_BY 같은 관계는 방향이 있다. A매장이 B상품을 판매한다고 B상품이 A매장을 판매하진 않는다. 이 방향 정보는 SKOS로 내보낼 때 손실된다. 뒤에서 다시 다룬다.\nDozerDB 위에 SKOS를 얹다 원칙은 간단했다. 기존 그래프를 건드리지 않는다.\nDozerDB에 이미 들어간 MANUFACTURES, STOCKS, CALCULATED_FROM 같은 관계를 바꾸면 기존 쿼리가 전부 깨진다. 잘 돌아가는 구조를 표준 맞추겠다고 뒤집는 건 현장에서 가장 흔한 삽질이다.\n기존 노드 위에 SKOS 메타데이터를 오버레이 했다. 투명 필름 한 장 덮는 느낌이다.\n// 기존 Entity 노드에 SKOSConcept 라벨과 SKOS 속성을 추가 MATCH (net:Entity {name: \u0026#39;순매출\u0026#39;}) SET net:SKOSConcept SET net.skos_prefLabel = \u0026#39;순매출\u0026#39; SET net.skos_altLabel = [\u0026#39;Net Sales\u0026#39;, \u0026#39;순매출액\u0026#39;] SET net.skos_definition = \u0026#39;총매출에서 반품과 에누리를 차감한 금액\u0026#39; SET net.skos_inScheme = \u0026#39;finance-terms\u0026#39; 유통 도메인도 똑같다.\n// 유통 도메인 용어 예시 MATCH (atv:Entity {name: \u0026#39;객단가\u0026#39;}) SET atv:SKOSConcept SET atv.skos_prefLabel = \u0026#39;객단가\u0026#39; SET atv.skos_altLabel = [\u0026#39;ATV\u0026#39;, \u0026#39;Average Transaction Value\u0026#39;, \u0026#39;객단\u0026#39;] SET atv.skos_definition = \u0026#39;총매출액을 구매 고객수로 나눈 값\u0026#39; SET atv.skos_inScheme = \u0026#39;retail-terms\u0026#39; 기존 Entity 노드는 그대로다. SKOSConcept이라는 라벨과 skos_ 접두사 속성이 위에 붙을 뿐. 기존 Cypher 쿼리에는 영향이 없다.\nbroader/narrower 관계는 두 가지 방법이 있었다. BROADER, NARROWER 엣지를 IsA와 나란히 미리 만들어두거나, 기존 IsA 관계를 Export 시점에 skos:broader로 바꿔 출력하거나.\n후자를 택했다. 엣지를 이중으로 만들면 IsA가 바뀔 때마다 BROADER도 동기화해야 한다. 동기화가 어긋나면 데이터가 꼬인다. 원천(Source of Truth)은 하나여야 한다. Export 시점에 한 번 변환하는 게 단순하고 안전하다.\n가져오기와 내보내기 표준이 들어가면서 두 가지가 가능해졌다.\n가져오기 — FIBO에서 금융 용어를, GS1 GPC에서 상품 분류 체계를 DataNexus로 끌어오는 경우다. FIBO는 원래 OWL로 배포되지만 SKOS로 변환된 파생 버전도 있다. GPC도 마찬가지로 SKOS 매핑이 가능하다. \u0026ldquo;의류 → 여성복 → 원피스\u0026rdquo; 같은 상품 계층을 그대로 가져와서 유통 고객사 온톨로지의 뼈대로 쓸 수 있다. OWL의 복잡한 제약 조건은 빠지지만, DataNexus에 필요한 건 용어 이름·정의·상하위 관계뿐이다. SKOS 서브셋으로 충분하다.\n내보내기 — DataNexus 용어를 고객사 시스템으로 보내는 경우. DozerDB 그래프에서 특정 도메인(예: retail-terms)의 노드와 관계를 꺼내서 SKOS Turtle 포맷으로 변환한다.\n@prefix skos: \u0026lt;http://www.w3.org/2004/02/skos/core#\u0026gt; . @prefix dnx: \u0026lt;http://datanexus.ai/ontology/\u0026gt; . dnx:atv a skos:Concept ; skos:prefLabel \u0026#34;객단가\u0026#34;@ko ; skos:altLabel \u0026#34;ATV\u0026#34;@en, \u0026#34;Average Transaction Value\u0026#34;@en ; skos:definition \u0026#34;총매출액을 구매 고객수로 나눈 값\u0026#34;@ko ; skos:broader dnx:sales-metrics ; skos:inScheme dnx:retail-terms . dnx:sales-metrics a skos:Concept ; skos:prefLabel \u0026#34;매출지표\u0026#34;@ko ; skos:narrower dnx:atv, dnx:net-sales, dnx:upt ; skos:inScheme dnx:retail-terms . 유통 현장에서 \u0026ldquo;객단가\u0026quot;라고 부르는 걸 어떤 시스템에서는 \u0026ldquo;ATV\u0026quot;로, 어떤 곳에서는 \u0026ldquo;평균구매단가\u0026quot;로 부른다. altLabel에 이 별칭들을 다 넣어두면 NL2SQL 엔진이 어떤 이름으로 질문이 들어와도 같은 테이블을 찾을 수 있다. 이 파일을 Collibra든 TopBraid이든 SKOS를 지원하는 어떤 시스템에든 넣을 수 있다.\n가져오기/내보내기가 되면 앞서 얘기한 문제들이 풀린다. 유통 그룹에서 백화점은 \u0026ldquo;매출\u0026quot;을 점포별 POS 합산으로, 온라인몰은 결제 완료 기준으로, 마트는 반품 차감 후 기준으로 각각 정의하고 있다고 하자. 각 관계사가 DataNexus에 자기 용어를 SKOS로 내보내면, 그룹 본사에서 이걸 받아 매핑 테이블을 만들 수 있다. \u0026ldquo;백화점의 매출 = 온라인몰의 확정매출 = 마트의 순매출\u0026quot;이라는 관계가 표준 포맷으로 잡히는 거다. 금융 고객사라면 감독 기관에 용어 정의와 데이터 계보를 보고해야 할 때 SKOS Turtle 파일을 그대로 제출하거나, 기관이 요구하는 포맷으로 변환할 수 있다. 표준이 없으면 이런 건 전부 수작업이다.\nSchema.org 같은 RDFS/OWL 기반 표준은 이 SKOS 레이어 범위 밖이다. 필요해지면 별도 변환기를 만들면 되지만 당장 우선순위는 아니다.\n남은 한계 SKOS로 전부 해결되진 않는다.\nSKOS에는 레이블 자체에 메타데이터를 붙이는 확장(SKOS-XL)이 있다. \u0026ldquo;순매출\u0026quot;이라는 이름이 언제 등록됐는지, 누가 승인했는지를 기록할 수 있다. 다국어 레이블 관리가 복잡해지면 꺼내 써야 할 수도 있는데, 아직은 안 넣었다.\nOWL 수준의 추론도 SKOS 범위 밖이다. \u0026ldquo;A가 B의 하위이고, B가 C의 하위이면, A는 C의 하위다\u0026rdquo; 같은 자동 추론. 온톨로지 규모가 작을 땐 없어도 되는데, 수천 개 용어가 쌓이면 얘기가 달라질 수 있다.\n가장 아쉬운 건 커스텀 관계 Export다. DozerDB의 SELLS, STOCKS, SUPPLIED_BY 같은 유통 도메인 특화 관계는 SKOS 표준에 대응하는 게 없다. \u0026ldquo;A매장이 B상품을 판매한다\u0026quot;는 방향이 있는 관계인데, skos:related로 뭉뚱그리면 방향과 의미가 사라진다. dnx:sells 같은 커스텀 네임스페이스로 확장하면 정보는 보존되는데, 받는 쪽이 이 커스텀 관계를 이해할 수 있어야 한다. 정보 손실 vs 호환성 — 트레이드오프다.\n80%는 SKOS 표준으로 커버하고, 20%는 DozerDB 커스텀 관계로 보완한다. 표준이 못 담는 부분은 내부 확장으로 채우되, 무리해서 표준 안에 구겨넣지 않는다.\n다음 글 온톨로지를 만들었는데, 이게 제대로 된 건지 어떻게 알까. 다음 글에서는 CQ(Competency Questions)로 온톨로지를 사전 검증하는 방법을 다룬다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/004-skos-compatibility-layer/","summary":"DataNexus 온톨로지를 외부와 연결하기 위해 SKOS를 선택한 이유. LPG와 RDF, 두 그래프 모델을 잇는 호환 레이어 설계.","title":"4. SKOS 호환 레이어를 왜 넣었는가"},{"content":"\rGoogle Colab에서 실습하기\r왜 Glossary를 온톨로지로 쓰려 했나 DataNexus의 핵심 아이디어는 단순하다. 비즈니스 용어 사이의 관계를 그래프로 정의해두면, NL2SQL 엔진이 그 그래프를 참조해서 자연어를 SQL로 바꿀 수 있다. 이 그래프가 온톨로지다.\n온톨로지라고 하면 학술 논문에나 나올 것 같은데, 실체는 별거 없다. \u0026ldquo;순매출은 매출의 한 종류다(IsA)\u0026rdquo;, \u0026ldquo;매출은 총매출, 반품, 에누리를 포함한다(HasA)\u0026rdquo;. 사람 머릿속에 있는 업무 지식을 기계가 읽을 수 있게 옮긴 것뿐이다.\n이걸 어디에 저장할지가 고민이었다. 온톨로지 전용 시스템을 하나 더 띄우면 관리 포인트가 늘어난다. 이미 DataHub를 메타데이터 플랫폼으로 쓰고 있었고, 거기 Business Glossary가 딸려 있었다. 용어 등록, 관계 설정 다 된다. 이전 글에서 Glossary의 관계 4종(IsA, HasA, RelatedTo, Values)이면 비즈니스 용어 계층구조를 충분히 표현할 수 있다고 봤었다.\n시스템 하나를 줄일 수 있다는 게 매력적이었다. GraphQL API로 프로그래밍 접근도 되고, 용어가 변경되면 Kafka MCL(Metadata Change Log) 이벤트가 자동으로 나간다. 나쁘지 않은 출발점이었다.\nGlossary에 용어를 넣기 시작했다 DataHub 세팅하고 제일 먼저 한 게 Glossary Term 등록이었다. \u0026ldquo;순매출 IsA 매출\u0026rdquo;, \u0026ldquo;매출 HasA 총매출, 반품, 에누리\u0026rdquo;. 이런 식으로 용어를 넣고 관계를 걸었다.\n기본 계층구조는 깔끔하게 들어갔다. 매출 → 총매출, 순매출 → 실매출.\n문제는 그 다음이었다.\n관계 4종의 한계: \u0026ldquo;공장과 제품\u0026rdquo; 실제 업무 데이터를 모델링하면서 벽에 부딪혔다.\n\u0026ldquo;A 공장에서 생산된 B 제품\u0026quot;과 \u0026ldquo;A 공장에 재고가 있는 B 제품\u0026rdquo;. 둘 다 공장과 제품 사이의 관계인데, 하나는 생산(Manufactures), 하나는 재고(Stocks)다. 의미가 완전히 다르다.\nDataHub Glossary에서 이걸 표현하면? 둘 다 RelatedTo가 된다. \u0026ldquo;공장 RelatedTo 제품\u0026quot;이 두 개 생기는데, 어느 게 생산이고 어느 게 재고인지 구분할 방법이 없다.\n이게 왜 치명적이냐면—DataNexus의 NL2SQL 엔진이 온톨로지를 보고 SQL을 만들기 때문이다. \u0026ldquo;A 공장에서 생산된 제품 목록 보여줘\u0026quot;라는 질문이 들어오면, 엔진은 공장-제품 관계를 찾아서 해당 테이블과 JOIN 경로를 결정한다.\n사용자 질문: \u0026ldquo;A 공장에서 생산된 제품은?\u0026quot;\n온톨로지 조회: 공장 → RelatedTo → 제품 (생산? 재고? 알 수 없음)\n→ LLM이 production 테이블 대신 inventory 테이블을 JOIN할 수 있음 → 잘못된 결과 반환\n관계 유형이 RelatedTo 하나뿐이니 엔진한테는 판단 근거가 없다. 잘못된 JOIN을 타면 사용자에게 엉뚱한 데이터가 나간다.\n확장하려면 재배포가 필요하다 DataHub에서 관계를 세분화하면 되지 않느냐. 안 된다.\nPDL(Persona Data Language)로 새 Aspect를 정의하고, @Relationship 어노테이션으로 관계 유형을 선언하고, DataHub를 빌드해서 재배포해야 한다. 관계 유형 하나 추가할 때마다 이 사이클을 돌려야 한다.\n비즈니스 모델링을 하다 보면 관계는 계속 늘어난다. \u0026ldquo;공급(Supplies)\u0026rdquo;, \u0026ldquo;검수(Inspects)\u0026rdquo;, \u0026ldquo;반품(Returns)\u0026rdquo;\u0026hellip; 업무 맥락에 따라 수십 가지가 필요해지는데, 하나마다 코드 고치고 재배포하는 건 현실적이지 않다.\n파고 들어가니 더 나왔다 관계 유형만 문제가 아니었다.\n동의어 충돌 \u0026ldquo;순매출\u0026quot;과 \u0026ldquo;실매출\u0026quot;을 동의어로 등록했다. 같은 개념인데 이름만 다른 경우다. 그런데 두 용어 모두 \u0026ldquo;Net Sales\u0026quot;라는 영문 동의어를 갖고 있었다. 하나의 영문명에 한글 용어 두 개가 매핑된 상황—DataHub는 이걸 그냥 넘긴다. 경고도 없다.\nNL2SQL에서 동의어 매핑이 꼬이면 엔진이 엉뚱한 용어를 참조한다. 용어가 수백 개를 넘어가면 이런 충돌을 사람 눈으로 잡을 수 없다. 커스텀 검증 로직을 따로 짜야 한다는 뜻이다.\n시각화 DataHub UI는 데이터 계보(Lineage) 탐색에 맞춰져 있다. 테이블 A → 테이블 B로 데이터가 흐르는 방향성 있는 트리.\n온톨로지는 구조가 다르다. 노드 수십~수백 개가 다대다로 엮인 그물망이다. \u0026ldquo;제품\u0026quot;이 \u0026ldquo;공장\u0026rdquo;, \u0026ldquo;창고\u0026rdquo;, \u0026ldquo;거래처\u0026rdquo;, \u0026ldquo;카테고리\u0026quot;와 전부 다른 관계로 연결되어 있고, 그 노드들끼리 또 서로 물려 있다. DataHub에는 이런 그래프를 탐색할 화면 자체가 없다.\n만들어 놓고 전체 그림을 못 보면 관리가 안 된다.\n관계에 속성을 붙일 수 없다 이게 제일 문제였다.\nDataHub Glossary에서 \u0026ldquo;A RelatedTo B\u0026quot;를 설정하면 그 관계에 아무것도 더 달 수 없다. 실무에서는 관계 자체에 정보가 필요한 경우가 많다.\n신뢰도(confidence) 가 대표적이다. 자동 추출된 관계는 0.7, 전문가가 직접 정의한 관계는 0.95—이 차이를 NL2SQL 엔진이 알아야 한다. 유효 기간(temporal) 도 마찬가지다. 조직 개편으로 부서-제품 매핑이 바뀌면, \u0026ldquo;이 관계가 언제부터 언제까지 유효한지\u0026quot;를 추적해야 한다. 카디널리티(cardinality) 는 JOIN 전략에 직접 영향을 준다.\n조직 개편으로 부서-제품 매핑이 바뀌면, 과거 시점 조직 구조로 현재 데이터를 조회하게 된다. 리포트 수치가 안 맞는 전형적인 원인이다. 관계에 시간축이 없으면 이걸 막을 방법이 없다.\n정리: 되는 것과 안 되는 것 되는 것 안 되는 것 용어 정의 (name, definition) 세분화된 관계 유형 (MANUFACTURES, STOCKS 등) 동의어 등록 (커스텀 필드) 동의어 중복/충돌 자동 감지 4종 관계 (IsA, HasA, RelatedTo, Values) 관계에 속성 부여 (신뢰도, 유효 기간) GraphQL API로 프로그래밍 접근 복잡한 그래프 탐색 UI Kafka MCL 이벤트 스트림 재배포 없는 실시간 관계 유형 확장 DataHub Glossary는 용어 사전으로서는 쓸 만하다. 온톨로지 저장소로는 표현력이 모자랐다.\n역할을 나눴다: DataHub + DozerDB Glossary를 통째로 버리는 건 답이 아니었다. 용어 정의의 원천(Source of Truth)으로 DataHub를 대체할 게 없다. GraphQL API, Kafka MCL 이벤트—이 인프라를 다른 도구에서 바닥부터 만드는 건 시간 낭비다.\n각자 잘하는 걸 맡겼다.\nDataHub Glossary → 용어 정의와 기본 관계의 원천 (Source of Truth) DozerDB → 세분화된 관계, 속성 달린 엣지, 그래프 추론 담당 DozerDB를 고른 건 Cypher 쿼리를 쓸 수 있어서다. 관계(엣지)에 속성을 자유롭게 붙일 수 있고, 관계 유형을 추가할 때 스키마 변경이나 재배포가 필요 없다.\n동기화 흐름은 단순하다. DataHub에서 Glossary Term이 바뀌면 Kafka MCL 이벤트가 나간다. 이벤트를 구독하는 Consumer가 DozerDB 온톨로지 그래프에 반영한다. 이름이나 정의 같은 기본 정보는 DataHub가 쥐고 있고, DozerDB는 그 위에 세분화된 관계와 속성을 얹는다.\nDozerDB에서의 관계 정의 아까 문제됐던 \u0026ldquo;공장-제품\u0026rdquo; 관계가 DozerDB에서는 이렇게 풀린다.\n// 엔티티 생성 (DataHub에서 동기화된 용어) CREATE (factory:Entity {name: \u0026#39;A공장\u0026#39;, type: \u0026#39;Factory\u0026#39;}) CREATE (product:Entity {name: \u0026#39;B제품\u0026#39;, type: \u0026#39;Product\u0026#39;}) // 생산 관계 — 시작 시점과 신뢰도를 속성으로 기록 CREATE (factory)-[:MANUFACTURES { since: \u0026#39;2024-01-01\u0026#39;, confidence: 0.95 }]-\u0026gt;(product) // 재고 관계 — 별도 엣지, 수량과 갱신 시점 CREATE (factory)-[:STOCKS { quantity: 500, last_updated: \u0026#39;2026-02-01\u0026#39; }]-\u0026gt;(product) MANUFACTURES와 STOCKS가 별개의 관계 유형이다. \u0026ldquo;A 공장에서 생산된 제품\u0026quot;이라는 질문이 오면 엔진이 MANUFACTURES를 찾아서 production 테이블로 정확히 JOIN한다. RelatedTo 하나로 퉁치던 것과는 근본적으로 다르다.\n파생 지표도 그래프에 넣었다 파생 지표 정의를 Excel로 관리하면 원본 용어가 바뀔 때 파생 시트가 안 따라간다. \u0026ldquo;순매출 = 총매출 - 반품 - 에누리\u0026quot;에서 총매출 정의가 바뀌었는데 순매출 쪽은 그대로—이런 불일치가 리포트까지 올라간다.\n이번에는 CALCULATED_FROM 관계로 계산식 자체를 그래프에 넣었다.\n// 순매출의 계산 구조를 관계로 표현 MATCH (net:Entity {name: \u0026#39;순매출\u0026#39;}) MATCH (gross:Entity {name: \u0026#39;총매출\u0026#39;}) MATCH (returns:Entity {name: \u0026#39;반품\u0026#39;}) MATCH (discounts:Entity {name: \u0026#39;에누리\u0026#39;}) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(gross) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(returns) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(discounts) 계산식이 바뀌면 관계를 수정한다. 변경 이력은 그래프 DB가 추적한다. Excel 시트 어딘가에 묻혀서 누가 언제 고쳤는지 모르는 것보다 낫다.\n남은 문제: 표준 호환 DataHub Glossary 모델은 DataHub만의 구조다. 업계에는 FIBO(금융), Schema.org(범용) 같은 표준 온톨로지가 있다. 산업 표준을 가져오거나 DataNexus 온톨로지를 밖으로 내보내려면 표준 포맷을 지원해야 하는데, 지금 구조로는 DataNexus 안에서만 통하는 독자 체계다.\n외부 상호운용성 없는 온톨로지는 쓰임이 제한된다.\n다음 글에서 SKOS 호환 레이어를 왜 넣었는지 다룬다.\nGoogle Colab에서 실습하기\rDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/003-datahub-glossary-as-ontology/","summary":"DataHub의 Business Glossary를 온톨로지 저장소로 쓰려고 했다. 되는 것과 안 되는 것, 그리고 우회한 방법.","title":"3. DataHub Glossary를 온톨로지로 쓸 수 있을까"},{"content":"비교 후보군 후보가 너무 많았다.\n메타데이터 카탈로그만 해도 DataHub, Amundsen, Apache Atlas, OpenMetadata. 상용까지 포함하면 Collibra, Alation도 있다. NL2SQL 엔진, 문서 지식엔진, 그래프 DB까지 네 축을 채워야 하는데 조합이 기하급수적으로 불어났다.\n엑셀 시트에 비교표를 만들었다. 행이 후보 도구, 열이 평가 기준. 3주쯤 지나니까 탭이 7개로 늘어나 있었다. 선택지가 많으면 안 고르는 게 문제다. 하나를 고르면 나머지와의 조합이 바뀌고, 다시 처음부터 비교해야 한다.\n네 가지 컴포넌트, 각각의 요건 이전 글에서 DataNexus의 네 가지 컴포넌트를 정의했다. 메타데이터 카탈로그, NL2SQL 엔진, 문서 지식엔진, 그래프 DB.\n양보할 수 없는 공통 기준이 세 가지 있었다. 오픈소스일 것. 멀티테넌시를 지원하거나 구현 가능할 것 — 그룹사별 데이터 격리는 필수다. 프로덕션 레디일 것 — 커뮤니티 활성도, 릴리즈 주기, 문서화 수준까지 봤다.\n컴포넌트마다 추가 요건도 달랐다. 메타데이터 카탈로그는 Business Glossary에서 용어 간 관계를 정의할 수 있어야 하고, 변경 이벤트를 실시간으로 내보낼 수 있어야 했다. NL2SQL 엔진 쪽은 사용자별 컨텍스트 분리와 Row-level Security. 문서 지식엔진은 벡터 검색만으로 안 되고 그래프 검색까지 하이브리드로 돌려야 했다. 그래프 DB는 Multi-DB와 Cypher 쿼리 지원이 전제였다.\n이 기준을 들고 후보를 걸렀다.\n메타데이터 카탈로그 DataHub, OpenMetadata, Amundsen, Apache Atlas, 상용(Collibra/Alation). 다섯을 놓고 봤다.\n상용은 먼저 빠졌다. 라이선스 비용도 문제지만 이 프로젝트에서 필요한 건 카탈로그의 Glossary를 온톨로지 저장소처럼 쓰는 거다. 상용 Glossary가 강력하긴 한데 내부 데이터 모델에 접근해서 커스터마이징하는 데 한계가 있다.\nApache Atlas는 Hadoop 생태계에 묶여 있다. HBase, Solr, Kafka를 전부 띄워야 한다. 2016년 설계 그대로인데 클라우드 네이티브 환경에서 돌리기엔 무겁다. Amundsen은 검색 중심 카탈로그로는 괜찮은데 Glossary에서 용어 간 관계를 정의하는 기능이 빈약하다. 온톨로지 저장소로 쓸 수 없었다.\n끝까지 고민한 건 OpenMetadata다. 아키텍처가 깔끔하고 데이터 품질 측정이 내장돼 있어서 단독 카탈로그로는 훌륭했다. 문제는 Glossary 관계가 Parent-Child와 RelatedTerms 위주라는 점. 상속(IsA)과 포함(HasA)을 명확히 구분해야 하는 온톨로지 표현에는 모자랐다. 실시간 이벤트 동기화도 웹훅 방식이라 대규모 스트리밍에서 Kafka 네이티브 대비 신뢰성이 떨어졌다.\nDataHub를 고른 이유는 명확하다.\nGlossary 관계가 4종이다. IsA(상속), HasA(포함), Values(값 목록), RelatedTo(일반 연관). 이 네 가지면 비즈니스 용어 간 계층을 표현할 수 있다. \u0026ldquo;순매출 IsA 매출\u0026rdquo;, \u0026ldquo;매출 HasA 총매출, 반품, 에누리\u0026rdquo; 같은 식이다.\nGraphQL API도 한몫했다. 메타데이터를 프로그래밍 방식으로 읽고 쓸 수 있어야 NL2SQL 엔진의 RAG Store에 온톨로지를 자동 동기화하는데, GraphQL이면 필요한 필드만 골라서 가져온다.\n결정적이었던 건 Kafka MCL 이벤트다. Metadata Change Log를 Kafka로 내보내는 구조인데, Glossary Term이 바뀌면 이벤트가 발행된다. 이걸 구독해서 그래프 DB 온톨로지를 실시간 동기화할 수 있다. 메타데이터 변경을 수동으로 반영하는 건 규모가 커질수록 반드시 누락이 생긴다. 양보할 수 없는 요건이었다.\nNL2SQL 엔진 처음에는 직접 만들까 생각했다. 대화형 BI 솔루션을 구축하면서 NL2SQL에 GPT와 Gemini를 붙이고, 프롬프트 엔지니어링을 최적화하고, 멀티에이전트 아키텍처까지 설계하는 데까지 갔었다.\n거기서 배운 게 두 가지다. DDL만으로는 LLM이 비즈니스 맥락을 이해할 수 없다는 것. 그리고 처음부터 만들면 사용자 인증, 쿼리 로깅, 데이터 필터링, 응답 스트리밍, 쿼리 학습까지 부수 기능이 한없이 불어난다는 것. 견적을 내보니 1개월 넘게 잡아먹힐 판이었다.\n그때 Vanna가 2.0으로 올라왔다.\n1.x는 단순했다. Python 클래스 하나 상속받아서 train(), ask() 호출하는 구조. 프로토타이핑엔 괜찮은데 프로덕션에 넣기엔 부족했다. 사용자별 컨텍스트 분리도 안 되고 보안 기능도 없었다.\n2.0은 다른 물건이다. Agent 기반 아키텍처로 바뀌면서 독립적인 구성 요소를 조합하는 방식이 됐고, 모든 컴포넌트에 사용자 ID가 자동 전파되는 User-Aware 구조가 들어갔다. Row-level Security가 프레임워크 수준에서 지원된다. 성공한 쿼리를 자동 학습하는 Tool Memory도 내장. 테이블이나 차트 같은 Rich UI Component를 실시간 전송하는 Streaming까지 갖췄다.\nUser-Aware와 Row-level Security가 결정적이었다. DataNexus는 그룹사별로 데이터를 격리해야 하는데 NL2SQL 엔진 레벨에서 이걸 지원한다는 건 직접 구현할 코드가 대폭 줄어든다는 뜻이다.\nTool Memory도 컸다. NL2SQL 정확도를 올리는 가장 확실한 방법 중 하나가 성공 쿼리를 축적해서 유사 질문에 재활용하는 건데 이게 프레임워크에 내장돼 있다. 직접 구현하면 쿼리 저장, 유사도 매칭, 버전 관리까지 만져야 하는데 그 공수가 통째로 빠진다.\n문서 지식엔진 벡터 검색만으로는 부족하다.\n사업보고서나 내부 정책문서를 검색할 때 벡터 유사도만으로 청크를 가져오면 맥락이 끊긴다. \u0026ldquo;A사업부의 매출 인식 기준\u0026quot;을 찾고 싶은데 벡터 검색은 \u0026ldquo;매출\u0026quot;이 포함된 청크를 유사도 순으로 나열할 뿐이다. A사업부와 매출 인식 기준의 관계라든가, 기준이 언제 바뀌었는지 같은 그래프 구조 정보는 벡터에 안 담긴다.\nApeRAG는 세 가지 검색을 조합해서 이 문제를 푼다. 임베딩 기반 의미 검색인 Vector Search, 고유명사나 코드명처럼 문자열 자체가 중요한 Full-text Search, 문서에서 추출한 엔티티 간 관계를 그래프로 탐색하는 GraphRAG. 이 셋을 동시에 돌린다.\n이 하이브리드가 DataNexus와 특히 잘 맞는 이유가 있다. DataHub의 Glossary Term을 ApeRAG Entity Extraction의 Taxonomy로 주입하면 문서에서 추출된 엔티티가 자동으로 비즈니스 용어와 연결된다. Exact Match → Synonym Match → Fuzzy Match(임계값 0.85) → Context Match, 4단계 Entity Resolution을 거치는 구조다.\nMinerU 통합도 빠뜨릴 수 없다. 엔터프라이즈 문서에는 복잡한 테이블, 수식, 다단 레이아웃이 흔한데 일반 PDF 파서로는 테이블 행/열이 깨진다. 특히 사업보고서처럼 테이블 안에 병합 셀이 난무하는 문서는 파싱 결과가 처참하다. MinerU는 문서 구조를 보존하면서 파싱하기 때문에 이 문제를 정면으로 해결한다.\n그래프 DB 가장 큰 변수는 Neo4j 라이선스였다.\nCommunity Edition과 Enterprise Edition의 결정적 차이는 Multi-DB다. Community는 인스턴스 하나에 그래프 하나. Enterprise는 같은 인스턴스 안에서 여러 데이터베이스를 만들 수 있다.\nDataNexus에서 Multi-DB는 필수다. 그룹사별로 온톨로지 그래프를 격리해야 한다. groupA_ontology_db, groupB_ontology_db처럼 테넌트별 데이터베이스를 분리하고 사용자 권한으로 접근을 제어하는 구조. Community 단일 DB에 전부 넣고 라벨로 구분하는 건 보안상 말이 안 된다.\n그렇다고 Neo4j Enterprise 라이선스를 살 수는 없다. 오픈소스 프로젝트의 원칙에 어긋난다.\nDozerDB가 이 딜레마를 풀었다. Neo4j Community Edition 위에 Enterprise 기능을 얹는 오픈소스 플러그인인데 Multi-DB를 지원한다. CREATE DATABASE로 테넌트별 그래프를 만들 수 있고, Cypher 쿼리도 그대로 쓴다.\nArangoDB도 봤다. 멀티모델(문서 + 그래프 + 키밸류)이 매력적인데 Cypher를 쓸 수 없다. 자체 쿼리 언어 AQL이 그래프 탐색에는 괜찮지만 Neo4j 생태계의 라이브러리나 도구를 못 쓰게 된다. 온톨로지를 Cypher로 질의하는 패턴과 레퍼런스가 압도적으로 많기 때문에 생태계 호환성을 택했다.\nDozerDB의 한계도 안다. Fabric — 크로스 DB 쿼리 — 은 아직 미지원이라 서로 다른 데이터베이스를 한 번의 Cypher로 질의하는 건 불가능하다. Phase 3 이후로 미뤘다. 당장은 단일 테넌트 내 질의만으로 충분하다.\n네 개를 연결하면 네 가지를 나란히 놓으면 도구 네 개다. 연결해야 파이프라인이 된다.\nDataHub에서 Glossary Term이 바뀌면 Kafka MCL 이벤트가 발행된다. 이 이벤트가 DozerDB 온톨로지 그래프에 실시간 반영되고, 동시에 Vanna의 RAG Store에도 들어간다. NL2SQL 프롬프트에 주입되는 맥락이 자동 갱신되는 셈이다. ApeRAG의 Entity Extraction은 DataHub Glossary를 Taxonomy로 참조하니까 문서 검색 결과도 최신 용어 체계에 연결된다.\n한 곳에서 용어를 고치면 네 군데가 동시에 바뀐다. 메타데이터 변경을 수동으로 전파하는 구조는 규모가 커질수록 반드시 어딘가 누락된다. 이 파이프라인이 그 문제를 막는다.\n다음 글 DataHub의 Business Glossary를 온톨로지로 쓸 때의 한계와 우회를 다룬다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/002-architecture-decisions/","summary":"DataNexus의 기술 스택을 DataHub + Vanna + ApeRAG + DozerDB로 결정한 과정. 후보군에서 탈락한 것들과 그 이유.","title":"2. 4개의 오픈소스를 이 조합으로 결정하기까지"},{"content":"\u0026ldquo;VIP 기준이 뭐죠?\u0026rdquo; 유통사 BI Agent 프로젝트에서 있었던 일이다.\n현업 담당자가 테스트 중에 물었다. \u0026ldquo;지난달 VIP 고객 매출 알려줘.\u0026rdquo; 시스템이 숫자를 뱉어냈는데, 담당자 표정이 좋지 않았다. \u0026ldquo;이거 뭔가 이상한데요. VIP 기준이 우리 팀이랑 다른 것 같아요.\u0026rdquo;\n확인해 보니 마케팅의 VIP와 CRM의 VIP가 달랐다. 매출도 문제였다. 순매출이냐 총매출이냐에 따라 수억 단위로 차이가 난다.\n이건 이 프로젝트만의 문제가 아니다. 60TB급 DW를 클라우드로 옮길 때도 봤고, 54억짜리 차세대 정보계를 6개 벤더와 13개월 동안 만들 때도 봤다. 차세대 정보계에서는 벤더마다 \u0026ldquo;매출\u0026quot;과 \u0026ldquo;원가\u0026quot;의 기준이 달라서 데이터 정합성 맞추는 데만 몇 달을 날렸다. 290M/M이 투입된 프로젝트에서 용어 하나 안 맞으면 생기는 비용은 상상 이상이다.\n엔터프라이즈 DW에는 테이블과 컬럼이 있다. 없는 건 맥락이다. \u0026ldquo;이 컬럼이 비즈니스에서 뭘 의미하는지\u0026quot;가 기계가 읽을 수 있는 형태로 어디에도 정의되어 있지 않다.\nDataNexus는 여기서 출발했다.\nNL2SQL은 만능이 아니다 요즘 NL2SQL 도구가 많다. 자연어를 SQL로 바꿔주는 것 자체는 이미 된다.\n실환경에 붙여보면 얘기가 달라진다. 유통사 프로젝트에서 직접 겪었는데, 벤치마크에서 점수 잘 받는 모델을 실제 DW에 연결하니까 체감 정확도가 확 떨어졌다. 카드사·통신사·공공데이터까지 내외부 데이터를 통합해 놓은 환경이었다. LLM이 이 복잡도를 감당하지 못했다.\n대기업 DW의 DDL을 열어보면 원인이 보인다. T_CUST_MST.CUST_GRD_CD, T_ORD_DTL.SALE_AMT 같은 약어 테이블이 수천 개다. 벤치마크 DB의 customer_name, order_date와는 차원이 다르다. 같은 회사인데도 사업부마다 테이블 네이밍 규칙이 다르고, \u0026ldquo;매출\u0026quot;이라는 단어 하나가 사업부마다 다른 테이블을 가리킨다.\n파생 지표는 더 골치다. \u0026ldquo;순매출\u0026quot;은 단일 컬럼이 아니다. SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT) 같은 계산식인데, 이 공식은 어떤 DDL에도 안 적혀 있다. 현업 머릿속에 있거나, 잘해야 누군가의 Excel 정의서 어딘가에 묻혀 있다.\nNL2SQL의 병목은 SQL 생성 능력이 아니다. 맥락이 없다.\n온톨로지라는 선택 대화형 BI 솔루션을 직접 만들면서 프롬프트 엔지니어링을 아무리 최적화해도 DDL만으로는 한계가 뚜렷했다. 멀티에이전트 아키텍처도 설계해 봤는데, 근본 문제는 같았다. LLM에게 줄 맥락 자체가 없다.\n온톨로지를 붙이기로 했다.\n거창한 얘기가 아니다. 실용적으로 보면 이런 것이다:\n# 순매출 용어 정의 - term: 순매출 definition: 총매출에서 반품과 에누리를 차감한 금액 formula: SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT) synonyms: [Net Sales, 순매출액, 넷세일즈] related_tables: [T_SALE_DTL, T_RTN_DTL] owner: 재무팀 이런 용어 정의를 메타데이터 카탈로그에 등록하고, NL2SQL 엔진의 RAG Store에 자동 동기화한다. LLM이 \u0026ldquo;순매출\u0026quot;이라는 단어를 봤을 때 어떤 테이블의 어떤 컬럼을 어떤 계산식으로 조합해야 하는지 알게 되는 구조다.\n처리 흐름은 이렇다:\n온톨로지 적용 전후 차이 — 내부 목표치가 EX(Execution Accuracy) 기준 +15~20%p 향상이다. MVP에서 EX 80% 이상, 안정화 단계에서 90% 이상. 현실적인 수치인지는 만들어 보면서 검증한다.\nDDL 붙여넣기로는 안 되는 이유 대기업 DW의 DDL을 다 붙여넣으면 수십만 토큰이다. 테이블이 수백, 수천 개인 환경에서는 컨텍스트 윈도우에 다 못 넣는다. 넣더라도 LLM이 그 안에서 정확한 테이블을 골라내는 건 Needle-in-a-Haystack 문제다.\n보안 이슈도 있다. 기업 내부 스키마를 외부 API에 보낼 수 없다. Row-level Security도 걸린다. 같은 \u0026ldquo;매출\u0026quot;이라도 A그룹사 사용자와 B그룹사 사용자가 봐야 하는 범위가 다르다.\n가장 큰 문제는 지속성이다. DDL은 바뀐다. 비즈니스 용어 정의도 바뀐다. 차세대 정보계를 오픈한 뒤에도 단계별 릴리즈를 계속하면 매번 메타데이터가 변경된다. 일회성 프롬프트가 아니라, 변경을 감지해서 자동으로 RAG Store를 갱신하는 파이프라인이 필요하다.\n따로 플랫폼을 만들어야겠다고 생각했다.\nDataNexus가 하려는 것 네 가지 컴포넌트로 구성된다.\n메타데이터 카탈로그 — 비즈니스 용어 정의, 테이블 메타, 데이터 계보를 한 곳에서 관리한다. 온톨로지의 원천(Source of Truth). NL2SQL 엔진 — 자연어를 SQL로 변환하되, 온톨로지에서 가져온 맥락을 프롬프트에 주입한다. DDL만 던져주는 방식과 정확도 차이가 확 난다. 문서 지식엔진 — 사업보고서, 정책문서 같은 비정형 데이터를 GraphRAG + 벡터 하이브리드로 검색한다. 그래프 DB — 온톨로지를 지식 그래프로 저장한다. 그룹사별 Multi-DB 격리까지. 한 줄로 요약하면: 카탈로그에서 정의한 온톨로지가 NL2SQL과 문서검색에 자동 동기화되어, 사용자의 자연어 질문에 맥락을 입혀준다. 각 컴포넌트에 사용한 오픈소스와 선정 이유는 다음 글에서 다룬다.\n왜 지금인가 \u0026ldquo;순매출 정의가 뭔지\u0026quot;는 ChatGPT가 아무리 똑똑해져도 모른다. 이건 기업 내부에만 존재하는 지식이다.\nLLM이 나오면서 문제의 프레임이 바뀌었다. 범용 모델이 빠르게 좋아지고 있고, 단순 기획이나 문서 생성은 곧 commodity가 된다. \u0026ldquo;기업 데이터의 맥락을 이해하는 능력\u0026quot;이 가치를 유지하려면, 그 맥락을 구조화해서 기계에 주입하는 시스템이 있어야 한다.\n이건 LLM 연구에서 말하는 Non-verifiable Domain에 해당한다. 수학이나 코딩은 정답을 자동 검증할 수 있다. 기업 내부의 암묵적 지식, 역할별 해석 차이, 비공개 운영 데이터는 그렇지 않다. 외부에서 즉시 판별하기 어려운 영역. 이런 데이터 위에 쌓는 경쟁 우위를 AI 전략에서는 Data Moat라고 부른다.\n이 우위가 영구적이라고는 생각하지 않는다. 범용 모델의 일반화 속도를 DataNexus의 데이터 축적 속도가 앞서야 한다. 시간이 중요하다.\n방어선은 네 가지다:\n온톨로지 기반 맥락 — 도메인 전문가가 용어를 정제할수록 두꺼워지는 메타데이터 카탈로그 역할별 해석 차이 — 같은 질문이라도 재무팀과 마케팅팀에 다른 응답을 주는 페르소나 최적화. 사용 패턴이 쌓일수록 개인화된다. 시간축 지식 그래프 — Temporal Knowledge Graph로 \u0026ldquo;작년 4분기 기준 VIP 정의\u0026quot;와 \u0026ldquo;올해 기준 VIP 정의\u0026quot;를 구분 비공개 운영 데이터 — 그룹사별 그래프 DB 격리 + Row-level Security. 각 그룹사의 데이터가 독립 자산이 된다. 올해 상반기까지 MVP를 내고 데이터 축적 루프를 돌리는 게 목표다.\n이 블로그의 목적 DataNexus를 만들면서 부딪히는 의사결정, 삽질, 해결 과정을 기록한다.\n다룰 것들:\n기술 스택을 선정한 과정 (후보군 탈락 사유 포함) 메타데이터 카탈로그의 Business Glossary를 온톨로지로 쓸 때의 한계와 우회 SKOS 호환 레이어를 넣은 이유 NL2SQL 엔진의 User-Aware 설계와 Row-level Security CQ(Competency Questions)로 온톨로지를 사전 검증하는 법 Query Router에서 결정론적 vs 확률론적 라우팅을 나누는 기준 에이전트 태스크를 쪼개는 79% Rule 이론보다는 실제로 부딪힌 문제와 그걸 어떻게 풀었는지 — 또는 아직 못 풀었는지 — 를 쓸 예정이다.\n다음 글 DataNexus의 기술 스택 — 4개의 오픈소스를 이 조합으로 결정하기까지의 과정. 후보군에서 탈락한 것들과 그 이유를 정리한다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/001-why-datanexus/","summary":"\u003ch2 id=\"vip-기준이-뭐죠\"\u003e\u0026ldquo;VIP 기준이 뭐죠?\u0026rdquo;\u003c/h2\u003e\n\u003cp\u003e유통사 BI Agent 프로젝트에서 있었던 일이다.\u003c/p\u003e\n\u003cp\u003e현업 담당자가 테스트 중에 물었다. \u0026ldquo;지난달 VIP 고객 매출 알려줘.\u0026rdquo; 시스템이 숫자를 뱉어냈는데, 담당자 표정이 좋지 않았다. \u0026ldquo;이거 뭔가 이상한데요. VIP 기준이 우리 팀이랑 다른 것 같아요.\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e확인해 보니 마케팅의 VIP와 CRM의 VIP가 달랐다. 매출도 문제였다. 순매출이냐 총매출이냐에 따라 수억 단위로 차이가 난다.\u003c/p\u003e\n\u003cp\u003e이건 이 프로젝트만의 문제가 아니다. 60TB급 DW를 클라우드로 옮길 때도 봤고, 54억짜리 차세대 정보계를 6개 벤더와 13개월 동안 만들 때도 봤다. 차세대 정보계에서는 벤더마다 \u0026ldquo;매출\u0026quot;과 \u0026ldquo;원가\u0026quot;의 기준이 달라서 데이터 정합성 맞추는 데만 몇 달을 날렸다. 290M/M이 투입된 프로젝트에서 용어 하나 안 맞으면 생기는 비용은 상상 이상이다.\u003c/p\u003e","title":"1. 왜 DataNexus를 만드는가"},{"content":"Junho Lee (이준호) Data \u0026amp; AI Platform Architect | PM\n20년 넘게 DW/BI 현장에서 대규모 DW 클라우드 전환부터 차세대 정보계 구축까지 직접 설계하고 리드해왔다. Web/ERP 개발자로 시작해서 DW/BI 엔지니어, Technical Lead, 컨설팅 본부장을 거쳤고, 지금은 온톨로지 기반 AI 데이터 플랫폼을 만들고 있다.\n경력 요약 커리어 전반부는 엔터프라이즈 DW/BI에 집중했다. 대용량 DW의 클라우드 전환을 Tech Leader로 수행했고, 차세대 정보계 프로젝트를 멀티벤더 PMO로 운영했다. 소매·통신·제조·건설 등 산업 도메인을 가리지 않고 프로젝트를 수행해왔다.\n컨설팅 조직을 직접 빌딩한 경험도 있다. 2명으로 시작한 팀을 20명까지 키우고, 연 매출을 7배 이상 성장시켰다. 채용, 교육, 기술 조직 운영, Presales, C레벨 대상 세미나까지 — 기술만 하는 사람은 아니다.\n최근에는 데이터와 AI의 접점에서 일하고 있다. LLM 기반 BI Agent를 구축하면서 NL2SQL의 실환경 한계를 직접 경험했고, 그 과정에서 온톨로지 기반 접근의 필요성을 확신하게 됐다. 지금은 DataNexus라는 통합 데이터 에이전트 플랫폼을 설계/구축 중이다.\nDataNexus \u0026ldquo;Everyone is an Analyst.\u0026rdquo;\n엔터프라이즈 데이터 분석의 구조적 문제를 풀기 위한 플랫폼이다. 자연어로 사내 데이터를 탐색하고 분석하는 AI 에이전트 — 말은 쉬운데, 실환경에서는 테이블명이 T_CUST_MST 같은 약어 투성이고, \u0026ldquo;순매출\u0026quot;이라는 단어 하나에도 부서마다 계산 로직이 다르다. DDL만으로는 LLM이 비즈니스 맥락을 이해할 수 없다.\nDataNexus는 온톨로지 기반 NL2SQL 엔진, GraphRAG, Data Catalog를 결합해서 이 간극을 메운다. 오픈소스를 조합한 아키텍처로, 비정형 문서와 정형 DB를 하나의 인터페이스로 다루는 구조다.\n이 블로그는 DataNexus를 만들어가는 과정을 기록한다. 아키텍처 결정, 기술 선택의 이유, 삽질과 해결 과정을 있는 그대로 남긴다.\n기술 영역 AI/ML — 온톨로지 LLM RAG, NL2SQL, Langchain, MCP, 멀티에이전트 시스템 설계 DW/Data Platform — Azure Synapse, BigQuery, Redshift, PostgreSQL, Oracle, Yellowbrick, Palantir Foundry BI — Power BI, Tableau, MicroStrategy, Qlik Sense, Looker, Superset ETL/ELT — ADF, SAP Data Services, IBM DataStage, Informatica, Databricks, SSIS Cloud — Azure (Synapse, ADF, ML), AWS (Redshift, S3, Glue), GCP (BigQuery, Gemini) Graph/Catalog — DataHub, Neo4j(DozerDB), ApeRAG Contact GitHub: @biz-agentic-ai LinkedIn: linkedin.com/in/leejuno ","permalink":"https://biz-agentic-ai.github.io/about/","summary":"이준호 - Data \u0026amp; AI Platform Architect","title":"About"}]