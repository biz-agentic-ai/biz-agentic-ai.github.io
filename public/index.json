[{"content":"\rGoogle Colab에서 실습하기\r왜 Glossary를 온톨로지로 쓰려 했나 DataNexus의 핵심 아이디어는 단순하다. 비즈니스 용어 사이의 관계를 그래프로 정의해두면, NL2SQL 엔진이 그 그래프를 참조해서 자연어를 SQL로 바꿀 수 있다. 이 그래프가 온톨로지다.\n온톨로지라고 하면 학술 논문에나 나올 것 같은데, 실체는 별거 없다. \u0026ldquo;순매출은 매출의 한 종류다(IsA)\u0026rdquo;, \u0026ldquo;매출은 총매출, 반품, 에누리를 포함한다(HasA)\u0026rdquo;. 사람 머릿속에 있는 업무 지식을 기계가 읽게 옮긴 것이다.\n문제는 이걸 어디에 저장하느냐였다. 온톨로지 전용 시스템을 하나 더 띄우면 관리 포인트가 늘어난다. 이미 DataHub를 메타데이터 플랫폼으로 쓰고 있었고, 거기에 Business Glossary가 있었다. 용어 등록, 관계 설정 다 된다. 이전 글에서 Glossary의 관계 4종(IsA, HasA, RelatedTo, Values)이면 비즈니스 용어 계층구조를 표현할 수 있다고 판단했었다.\nGlossary를 온톨로지 저장소로 겸용하면 시스템 하나를 줄인다. GraphQL API로 프로그래밍 접근이 되고, 용어가 변경되면 Kafka MCL(Metadata Change Log) 이벤트가 자동 발행된다. 나쁘지 않은 출발점이었다.\nGlossary에 용어를 넣기 시작했다 DataHub 세팅하고 제일 먼저 한 게 Glossary Term 등록이었다. \u0026ldquo;순매출 IsA 매출\u0026rdquo;, \u0026ldquo;매출 HasA 총매출, 반품, 에누리\u0026rdquo;. 이런 식으로 용어를 넣고 관계를 걸었다.\n기본적인 계층구조는 잘 들어갔다. 매출 → 총매출, 순매출 → 실매출. 깔끔했다.\n문제는 그 다음이었다.\n관계 4종의 한계: \u0026ldquo;공장과 제품\u0026rdquo; 실제 업무 데이터를 모델링하면서 벽에 부딪혔다.\n\u0026ldquo;A 공장에서 생산된 B 제품\u0026quot;과 \u0026ldquo;A 공장에 재고가 있는 B 제품\u0026rdquo;. 둘 다 공장과 제품 사이의 관계다. 하나는 생산(Manufactures), 하나는 재고(Stocks). 의미가 완전히 다르다.\nDataHub Glossary에서 이 두 관계를 표현하면? 둘 다 RelatedTo. \u0026ldquo;공장 RelatedTo 제품\u0026quot;이 두 개 생기는데, 어느 게 생산이고 어느 게 재고인지 구분이 안 된다.\n이게 왜 치명적이냐면, DataNexus의 NL2SQL 엔진이 온톨로지를 보고 SQL을 만들기 때문이다. \u0026ldquo;A 공장에서 생산된 제품 목록 보여줘\u0026quot;라는 질문이 들어오면, 엔진은 공장-제품 관계를 찾고 거기에 해당하는 테이블과 JOIN 경로를 결정한다.\n사용자 질문: \u0026ldquo;A 공장에서 생산된 제품은?\u0026quot;\n온톨로지 조회: 공장 → RelatedTo → 제품 (생산? 재고? 알 수 없음)\n→ LLM이 production 테이블 대신 inventory 테이블을 JOIN할 수 있음 → 잘못된 결과 반환\n관계 유형이 RelatedTo 하나뿐이니, 엔진한테는 판단 근거가 없다. 잘못된 JOIN 경로를 타면 사용자에게 엉뚱한 데이터가 나간다.\n확장하려면 재배포가 필요하다 그러면 DataHub에서 관계를 세분화하면 되지 않느냐. 이게 쉽지 않다.\nPDL(Persona Data Language)로 새 Aspect를 정의하고 @Relationship 어노테이션으로 관계 유형을 선언하고 DataHub를 빌드해서 재배포해야 한다 관계 유형 하나 추가할 때마다 이 사이클을 돌아야 한다. 비즈니스 현장에서 모델링하다 보면 관계는 계속 늘어난다. \u0026ldquo;공급(Supplies)\u0026rdquo;, \u0026ldquo;검수(Inspects)\u0026rdquo;, \u0026ldquo;반품(Returns)\u0026rdquo;\u0026hellip; 업무 맥락에 따라 수십 가지가 필요해지는데, 하나마다 코드 수정하고 재배포하는 건 말이 안 된다.\n파고 들어가니 더 나왔다 관계 유형만 문제가 아니었다.\n동의어 충돌 \u0026ldquo;순매출\u0026quot;과 \u0026ldquo;실매출\u0026quot;을 동의어로 등록했다. 같은 개념의 다른 이름이다. 그런데 두 용어 모두 \u0026ldquo;Net Sales\u0026quot;라는 영문 동의어를 갖고 있었다. 하나의 영문명에 한글 용어 두 개가 매핑된 상황인데, DataHub는 이걸 그냥 넘긴다. 경고도 없다.\nNL2SQL에서 동의어 매핑이 꼬이면 엔진이 엉뚱한 용어를 참조한다. 용어가 수백 개를 넘어가면 이런 충돌을 눈으로 잡는 건 불가능하다. 결국 커스텀 검증 로직을 따로 짜야 한다는 뜻이다.\n시각화 DataHub UI는 데이터 계보(Lineage) 보는 데 맞춰져 있다. 테이블 A → 테이블 B로 데이터가 흐르는 방향성 있는 트리.\n온톨로지는 구조 자체가 다르다. 노드 수십~수백 개가 다대다로 엮인 그물망이다. \u0026ldquo;제품\u0026quot;이 \u0026ldquo;공장\u0026rdquo;, \u0026ldquo;창고\u0026rdquo;, \u0026ldquo;거래처\u0026rdquo;, \u0026ldquo;카테고리\u0026quot;와 전부 다른 관계로 연결되어 있고, 그 노드들이 또 서로 물려 있다. DataHub에는 이런 그래프를 탐색하는 화면 자체가 없다. 온톨로지를 만들어 놓고 전체 그림을 못 보면 관리할 수가 없다.\n관계에 속성을 붙일 수 없다 이게 제일 컸다.\nDataHub Glossary에서 \u0026ldquo;A RelatedTo B\u0026quot;를 설정하면, 그 관계에 아무것도 더 붙일 수 없다. 실무에서는 관계 자체에 정보가 필요한 경우가 많다.\n**신뢰도(confidence)**가 대표적이다. 자동 추출된 관계는 0.7, 전문가가 직접 정의한 관계는 0.95. 이 차이를 NL2SQL 엔진이 알아야 한다. **유효 기간(temporal)**도 빠질 수 없다. 조직 개편으로 부서-제품 매핑이 바뀌면, \u0026ldquo;이 관계가 언제부터 언제까지 유효한지\u0026quot;를 추적해야 한다. **카디널리티(cardinality)**는 JOIN 전략에 직접 영향을 준다.\nL사 차세대 정보계 프로젝트(54억, 13개월짜리) 할 때 비슷한 문제를 겪었다. 조직 개편이 프로젝트 중간에 터졌는데, 과거 시점의 조직 구조로 현재 데이터를 조회하는 바람에 리포트 수치가 안 맞았다. 관계의 시간축을 관리하지 않으면 생기는 전형적인 사고다. 같은 걸 반복하고 싶지 않았다.\n정리: 되는 것과 안 되는 것 되는 것 안 되는 것 용어 정의 (name, definition) 세분화된 관계 유형 (MANUFACTURES, STOCKS 등) 동의어 등록 (커스텀 필드) 동의어 중복/충돌 자동 감지 4종 관계 (IsA, HasA, RelatedTo, Values) 관계에 속성 부여 (신뢰도, 유효 기간) GraphQL API로 프로그래밍 접근 복잡한 그래프 탐색 UI Kafka MCL 이벤트 스트림 재배포 없는 실시간 관계 유형 확장 DataHub Glossary는 용어 사전으로서는 훌륭하지만, 온톨로지 저장소로는 표현력이 모자랐다.\n역할을 나눴다: DataHub + DozerDB Glossary를 완전히 버리는 건 답이 아니었다. 용어 정의의 원천(Source of Truth)으로 DataHub를 대체할 게 없다. GraphQL API, Kafka MCL 이벤트—이 인프라를 다른 도구에서 바닥부터 만드는 건 시간 낭비다.\n그래서 각자 잘하는 걸 맡겼다.\nDataHub Glossary → 용어 정의와 기본 관계의 원천 (Source of Truth) DozerDB → 세분화된 관계, 속성 달린 엣지, 그래프 추론 담당 DozerDB를 고른 이유는 Cypher 쿼리를 쓸 수 있는 그래프 DB이기 때문이다. 관계(엣지)에 속성을 자유롭게 붙이고, 관계 유형을 추가할 때 스키마 변경도 재배포도 필요 없다.\n동기화 흐름은 간단하다. DataHub에서 Glossary Term이 바뀌면 Kafka MCL 이벤트가 나간다. 이벤트를 구독하는 Consumer가 DozerDB 온톨로지 그래프에 반영한다. 이름, 정의 같은 기본 정보는 DataHub가 쥐고 있고, DozerDB는 그 위에 세분화된 관계와 속성을 얹는 구조다.\nDozerDB에서의 관계 정의 아까 문제됐던 \u0026ldquo;공장-제품\u0026rdquo; 관계. DozerDB에서는 이렇게 풀린다.\n// 엔티티 생성 (DataHub에서 동기화된 용어) CREATE (factory:Entity {name: \u0026#39;A공장\u0026#39;, type: \u0026#39;Factory\u0026#39;}) CREATE (product:Entity {name: \u0026#39;B제품\u0026#39;, type: \u0026#39;Product\u0026#39;}) // 생산 관계 — 시작 시점과 신뢰도를 속성으로 기록 CREATE (factory)-[:MANUFACTURES { since: \u0026#39;2024-01-01\u0026#39;, confidence: 0.95 }]-\u0026gt;(product) // 재고 관계 — 별도 엣지, 수량과 갱신 시점 CREATE (factory)-[:STOCKS { quantity: 500, last_updated: \u0026#39;2026-02-01\u0026#39; }]-\u0026gt;(product) MANUFACTURES와 STOCKS가 별개의 관계 유형이다. \u0026ldquo;A 공장에서 생산된 제품\u0026quot;이라는 질문이 오면, 엔진이 MANUFACTURES를 찾아서 production 테이블로 정확히 JOIN한다. RelatedTo 하나로 퉁치던 것과는 근본적으로 다르다.\n파생 지표도 그래프에 넣었다 이전 회사에서, 파생 지표 정의를 Excel로 관리하다가 반나절을 날린 적이 있다. \u0026ldquo;순매출 = 총매출 - 반품 - 에누리\u0026quot;가 시트 어딘가에 적혀 있었는데, 총매출 정의가 바뀌면서 순매출 시트는 업데이트가 안 됐다. 리포트 수치가 안 맞아서 고객사 미팅에서 곤란했다.\n이번에는 CALCULATED_FROM 관계로 계산식 자체를 그래프에 넣었다.\n// 순매출의 계산 구조를 관계로 표현 MATCH (net:Entity {name: \u0026#39;순매출\u0026#39;}) MATCH (gross:Entity {name: \u0026#39;총매출\u0026#39;}) MATCH (returns:Entity {name: \u0026#39;반품\u0026#39;}) MATCH (discounts:Entity {name: \u0026#39;에누리\u0026#39;}) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(gross) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(returns) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(discounts) 계산식이 바뀌면 관계를 수정한다. 변경 이력은 그래프 DB가 알아서 추적한다. Excel 시트 어딘가에 묻혀서 누가 언제 고쳤는지도 모르는 것보다 낫다.\n남은 문제: 표준 호환 DataHub Glossary 모델은 DataHub만의 구조다. 업계에는 FIBO(금융), Schema.org(범용) 같은 표준 온톨로지가 있다. 산업 표준을 가져오거나 DataNexus 온톨로지를 밖으로 내보내려면 표준 포맷 지원이 필요한데, 지금 구조로는 DataNexus 안에서만 통하는 독자 체계가 된다.\n외부 상호운용성이 없는 온톨로지는 가치가 제한된다.\n다음 글에서 SKOS 호환 레이어를 왜 넣었는지 다룬다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/003-datahub-glossary-as-ontology/","summary":"DataHub의 Business Glossary를 온톨로지 저장소로 쓰려고 했다. 되는 것과 안 되는 것, 그리고 우회한 방법.","title":"3. DataHub Glossary를 온톨로지로 쓸 수 있을까"},{"content":"비교 후보군 후보가 너무 많았다.\n메타데이터 카탈로그만 해도 DataHub, Amundsen, Apache Atlas, OpenMetadata. 상용까지 포함하면 Collibra, Alation도 있다. NL2SQL 엔진, 문서 지식엔진, 그래프 DB까지 네 축을 채워야 하는데 조합의 수가 기하급수적으로 불어났다.\n구글 시트에 비교표를 만들었다. 행이 후보 도구, 열이 평가 기준. 3주쯤 지나니까 시트가 7개 탭으로 늘어나 있었다. 선택지가 많으면 안 고르는 게 문제다. 하나를 고르면 나머지와의 조합이 바뀌고, 다시 처음부터 비교해야 한다.\n네 가지 컴포넌트, 각각의 요건 이전 글에서 DataNexus의 네 가지 컴포넌트를 정의했다. 메타데이터 카탈로그, NL2SQL 엔진, 문서 지식엔진, 그래프 DB. 각 컴포넌트마다 양보할 수 없는 요건이 있었다.\n공통 기준은 셋이다.\n오픈소스일 것. 엔터프라이즈 라이선스 비용은 이 프로젝트의 성격과 맞지 않는다. 멀티테넌시를 지원하거나 구현 가능할 것. 그룹사별 데이터 격리는 필수다. 프로덕션 레디일 것. 커뮤니티 활성도, 릴리즈 주기, 문서화 수준을 봤다. 여기에 컴포넌트별로 추가 요건이 붙었다.\n컴포넌트 핵심 요건 메타데이터 카탈로그 Business Glossary에서 용어 간 관계 정의 가능, 변경 이벤트를 실시간으로 내보낼 수 있을 것 NL2SQL 엔진 사용자별 컨텍스트 분리, Row-level Security 내장, 학습 루프 문서 지식엔진 벡터 검색 + 그래프 검색 하이브리드, 복잡한 문서(테이블/수식) 파싱 그래프 DB Multi-DB(데이터베이스별 격리), Cypher 쿼리 지원 이 기준을 들고 후보를 걸렀다.\n메타데이터 카탈로그 DataHub, Amundsen, Apache Atlas, 상용(Collibra/Alation). 넷을 놓고 봤다.\n상용은 먼저 빠졌다. 라이선스 비용도 문제지만, 이 프로젝트에서 필요한 건 카탈로그의 Glossary를 온톨로지 저장소처럼 쓰는 것이다. 상용 Glossary가 충분히 강력하긴 한데, 내부 데이터 모델에 접근해서 커스터마이징하는 데 한계가 있다.\nApache Atlas는 Hadoop 생태계에 묶여 있다. HBase, Solr, Kafka를 전부 띄워야 한다. 2016년에 설계된 아키텍처가 그대로인데, 클라우드 네이티브 환경에서 운영하기엔 무겁다.\nAmundsen은 깔끔한 도구다. 검색 중심 카탈로그로는 괜찮다. 문제는 Glossary. 용어 간 관계를 정의하는 기능이 제한적이어서 온톨로지 저장소로 쓰기엔 부족했다.\nDataHub를 선택한 결정적 이유는 세 가지다.\nGlossary 관계 4종. IsA(상속), HasA(포함), Values(값 목록), RelatedTo(일반 연관). 이 네 가지면 비즈니스 용어 간 계층구조를 표현할 수 있다. \u0026ldquo;순매출 IsA 매출\u0026rdquo;, \u0026ldquo;매출 HasA 총매출, 반품, 에누리\u0026rdquo; 같은 식이다.\nGraphQL API. 메타데이터를 프로그래밍 방식으로 읽고 쓸 수 있다. NL2SQL 엔진의 RAG Store에 온톨로지를 자동 동기화하려면 API가 유연해야 하는데, GraphQL이면 필요한 필드만 골라서 가져온다.\nKafka MCL 이벤트. Metadata Change Log라는 이벤트 스트림을 Kafka로 내보낸다. Glossary Term이 변경되면 이벤트가 발행되고, 이걸 구독해서 그래프 DB의 온톨로지를 실시간 동기화할 수 있다. 이전 프로젝트에서 메타데이터 변경을 수동으로 반영하다가 얼마나 고생했는지 기억나서, 이 부분은 양보할 수 없었다.\nNL2SQL 엔진 처음에 직접 만들까 생각했다. 이미 대화형 BI 솔루션을 만든 경험이 있었다. NL2SQL에 GPT와 Gemini를 붙이고, 프롬프트 엔지니어링을 최적화하고, 멀티에이전트 아키텍처를 설계하는 데까지 갔었다.\n그 경험에서 배운 게 두 가지다. DDL만으로는 LLM이 비즈니스 맥락을 이해할 수 없다는 것. 처음부터 만들면 사용자 인증, 쿼리 로깅, 데이터 필터링, 응답 스트리밍, 쿼리 학습까지 부수 기능이 한없이 불어난다는 것. 산정해 보니 1개월 이상이었다.\n그때 Vanna가 2.0으로 업데이트됐다.\n1.x는 단순했다. Python 클래스 하나를 상속받아서 train(), ask() 같은 메서드를 호출하는 구조. 프로토타이핑에는 좋은데 프로덕션에 넣기엔 부족하다. 사용자별 컨텍스트 분리가 안 되고, 보안 기능도 없었다.\n2.0은 다른 물건이다.\n변화 의미 Agent 기반 아키텍처 독립적인 Agent 구성 요소를 조합하는 구조. 도구를 갈아 끼울 수 있다 User-Aware 모든 컴포넌트에 사용자 ID가 자동 전파. 테넌트별 쿼리 컨텍스트 분리 Row-level Security 사용자별 데이터 필터링이 프레임워크 수준에서 지원 Tool Memory 성공한 쿼리를 자동 학습. 같은 패턴의 질문이 오면 이전 성공 사례를 참고 Streaming 테이블, 차트 같은 Rich UI Component를 실시간 전송 User-Aware와 Row-level Security가 결정적이었다. DataNexus는 그룹사별로 데이터를 격리해야 한다. 이걸 NL2SQL 엔진 레벨에서 지원한다는 건 직접 구현할 코드가 대폭 줄어든다는 뜻이다.\nTool Memory도 컸다. NL2SQL 정확도를 올리는 가장 확실한 방법 중 하나가 성공 쿼리를 축적해서 유사 질문에 재활용하는 건데, 프레임워크에 내장되어 있다. 이전에 직접 만들 때 이 부분을 따로 구현하느라 꽤 시간을 썼던 터라 반가웠다.\n문서 지식엔진 벡터 검색만으로는 부족하다.\n사업보고서나 내부 정책문서를 검색할 때, 벡터 유사도만으로 청크를 가져오면 맥락이 끊긴다. \u0026ldquo;A사업부의 매출 인식 기준\u0026quot;을 찾고 싶은데, 벡터 검색은 \u0026ldquo;매출\u0026quot;이 포함된 청크를 유사도 순으로 나열할 뿐이다. A사업부와 매출 인식 기준 사이의 관계, 이 기준이 언제 바뀌었는지 같은 그래프 구조의 정보는 벡터에 안 담긴다.\nApeRAG는 세 가지 검색을 결합한다.\nVector Search — 임베딩 기반 의미 검색. 기본. Full-text Search — 키워드 기반 정확 매칭. 고유명사나 코드명처럼 의미보다 문자열 자체가 중요할 때. GraphRAG — 문서에서 추출한 엔티티 간 관계를 그래프로 구성하고, 그래프 탐색으로 관련 정보를 찾는다. 이 하이브리드가 DataNexus와 맞는 이유가 있다. DataHub의 Glossary Term을 ApeRAG의 Entity Extraction에 Taxonomy로 주입하면, 문서에서 추출된 엔티티가 자동으로 비즈니스 용어와 연결된다. Exact Match → Synonym Match → Fuzzy Match(임계값 0.85) → Context Match. 4단계 Entity Resolution을 거친다.\nMinerU 통합도 빠뜨릴 수 없다. 엔터프라이즈 문서에는 복잡한 테이블, 수식, 다단 레이아웃이 흔하다. 일반 PDF 파서로는 테이블의 행/열 구조가 깨진다. 차세대 정보계 프로젝트 때 사업보고서 파싱으로 고생한 적이 있어서, 문서 구조를 보존하면서 파싱하는 MinerU의 가치를 알고 있었다.\n그래프 DB 가장 큰 변수는 Neo4j의 라이선스 구조다.\nNeo4j는 Community Edition과 Enterprise Edition으로 나뉜다. 결정적 차이는 Multi-DB. Community는 단일 데이터베이스만 지원한다. 하나의 인스턴스에 하나의 그래프. Enterprise는 같은 인스턴스 안에서 여러 데이터베이스를 만들 수 있다.\nDataNexus에서 Multi-DB는 필수다. 그룹사별로 온톨로지 그래프를 격리해야 한다. groupA_ontology_db, groupB_ontology_db처럼 테넌트별 데이터베이스를 분리하고, 사용자 권한에 따라 접근을 제어한다. Community의 단일 DB에 모든 테넌트 데이터를 넣고 라벨로 구분하는 건 보안상 허용할 수 없다.\nNeo4j Enterprise 라이선스를 사는 건 이 프로젝트의 원칙에 어긋난다.\nDozerDB가 이 딜레마를 풀었다. Neo4j Community Edition 위에 Enterprise 기능을 얹는 오픈소스 플러그인이다. Multi-DB를 지원한다. CREATE DATABASE로 테넌트별 그래프를 만들 수 있고, Cypher 쿼리도 그대로 쓴다.\nArangoDB도 봤다. 멀티모델(문서 + 그래프 + 키밸류)을 지원하는 점은 매력적인데, Cypher를 쓸 수 없다. ArangoDB의 쿼리 언어 AQL이 그래프 탐색에는 괜찮지만, Neo4j 생태계의 라이브러리나 도구를 활용할 수 없게 된다. 온톨로지를 Cypher로 질의하는 패턴이 이미 많이 나와 있어서, 생태계 호환성을 우선했다.\nDozerDB의 한계도 알고 있다. Fabric(크로스 DB 쿼리)은 아직 미지원이다. 서로 다른 데이터베이스 간에 한 번의 Cypher로 질의하는 건 불가능하다. Phase 3 이후로 미뤘다. 당장은 단일 테넌트 내 질의만으로 충분하다.\n이 조합이 만드는 것 네 가지를 나란히 놓으면 그냥 도구 네 개다. 연결하면 파이프라인이 된다.\nDataHub에서 Glossary Term이 변경되면 Kafka MCL 이벤트가 발행된다. 이 이벤트를 DozerDB의 온톨로지 그래프에 실시간 동기화한다. 동시에 Vanna의 RAG Store에도 반영되어, NL2SQL 프롬프트에 주입되는 맥락이 자동 갱신된다. ApeRAG의 Entity Extraction은 DataHub Glossary를 Taxonomy로 참조하므로, 문서 검색 결과도 최신 용어 체계와 연결된다.\n한 곳에서 용어를 고치면 네 군데가 동시에 바뀐다. 이전 프로젝트에서 메타데이터 변경을 Excel로 관리하다가 한 곳을 빼먹어서 반나절을 날린 적이 있는데, 그때의 교훈이 이 설계에 들어갔다.\n다음 글 DataHub의 Business Glossary를 온톨로지로 쓸 때의 한계와 우회를 다룬다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/002-architecture-decisions/","summary":"DataNexus의 기술 스택을 DataHub + Vanna + ApeRAG + DozerDB로 결정한 과정. 후보군에서 탈락한 것들과 그 이유.","title":"2. 4개의 오픈소스를 이 조합으로 결정하기까지"},{"content":"\u0026ldquo;VIP 기준이 뭐죠?\u0026rdquo; 작년에 유통사 BI Agent 프로젝트를 하면서 있었던 일이다. 자연어 질의/응답 시스템을 만들고 있었다.\n현업 담당자가 테스트 중에 물었다. \u0026ldquo;지난달 VIP 고객 매출 알려줘.\u0026rdquo; 시스템이 숫자를 뱉어냈다. 담당자 표정이 좋지 않았다. \u0026ldquo;이거 뭔가 이상한데요. VIP 기준이 우리 팀이랑 다른 것 같아요.\u0026rdquo;\n확인해 보니 마케팅의 VIP와 CRM의 VIP가 달랐다. 매출도 문제였다. 순매출이냐 총매출이냐에 따라 수억 단위로 차이가 난다.\n이 장면은 이 프로젝트에서만 본 게 아니다.\n60TB급 대기업 DW를 클라우드로 마이그레이션할 때도, 54억짜리 차세대 정보계를 다수 벤더와 1년 넘게 만들 때도 본질은 같았다. 차세대 정보계에서는 각 벤더가 정의하는 \u0026ldquo;매출\u0026quot;과 \u0026ldquo;원가\u0026quot;의 기준이 달라서, 데이터 정합성 맞추는 데만 몇 달을 날렸다. 수백 명이 투입된 프로젝트에서 용어 정의 불일치가 만드는 비용은 생각보다 크다.\n20년 가까이 데이터 조직에서 일하면서 이 문제를 반복적으로 봤다. 테이블과 컬럼은 있다. 없는 건 맥락이다. \u0026ldquo;이 컬럼이 비즈니스에서 뭘 의미하는지\u0026quot;가 기계가 읽을 수 있는 형태로 어디에도 정의되어 있지 않다.\nDataNexus는 여기서 출발했다.\nNL2SQL은 만능이 아니다 요즘 NL2SQL 도구가 많다. 자연어를 SQL로 바꿔주는 것 자체는 이미 된다.\n문제는 실환경이다. 유통사 프로젝트에서 직접 겪었는데, 학술 벤치마크에서 좋은 점수를 받는 모델이 실제 DW에 연결하면 체감 정확도가 확 떨어졌다. 카드사·통신사·공공데이터까지 내외부 데이터를 통합해 놓은 환경이었다. LLM이 이 복잡도를 감당하지 못했다.\n원인은 이전 프로젝트에서 이미 알고 있었다. 대기업 DW의 DDL을 열어보면 T_CUST_MST.CUST_GRD_CD, T_ORD_DTL.SALE_AMT 같은 약어 테이블이 수천 개다. 벤치마크 DB의 customer_name, order_date와는 차원이 다르다. 같은 회사인데 사업부마다 테이블 네이밍 규칙이 다르고, \u0026ldquo;매출\u0026quot;이라는 단어 하나가 사업부마다 다른 테이블을 가리킨다.\n파생 지표는 더 골치다. \u0026ldquo;순매출\u0026quot;은 단일 컬럼이 아니다. SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT) 같은 계산식인데, 이 공식은 어떤 DDL에도 안 적혀 있다. 현업 머릿속에 있거나, 잘해야 누군가의 Excel 정의서 어딘가에 묻혀 있다.\nNL2SQL의 병목은 SQL 생성 능력이 아니다. 맥락의 부재다.\n온톨로지라는 선택 대화형 BI 솔루션을 직접 만들면서 프롬프트 엔지니어링을 아무리 최적화해도 DDL만으로는 한계가 뚜렷했다. 멀티에이전트 아키텍처를 설계해 보기도 했다. 근본 문제는 LLM에게 줄 맥락 자체가 없다는 것이었다.\n온톨로지를 붙이기로 했다.\n거창한 학술 개념이 아니다. 실용적으로 보면 이런 것이다:\n# 순매출 용어 정의 - term: 순매출 definition: 총매출에서 반품과 에누리를 차감한 금액 formula: SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT) synonyms: [Net Sales, 순매출액, 넷세일즈] related_tables: [T_SALE_DTL, T_RTN_DTL] owner: 재무팀 이런 용어 정의를 메타데이터 카탈로그에 등록하고, NL2SQL 엔진의 RAG Store에 자동 동기화한다. LLM이 \u0026ldquo;순매출\u0026quot;이라는 단어를 봤을 때 어떤 테이블의 어떤 컬럼을 어떤 계산식으로 조합해야 하는지 알게 되는 구조다.\n처리 흐름은 이렇다:\n온톨로지 적용 전후 차이 — 내부 목표치가 EX(Execution Accuracy) 기준 +15~20%p 향상이다. MVP에서 EX 80% 이상, 안정화 단계에서 90% 이상. 이 수치가 현실적인지는 만들어 보면서 검증한다.\n\u0026ldquo;ChatGPT에 DDL 붙여넣으면 되지 않나?\u0026rdquo; 자주 받는 질문이다. 안 된다.\n대기업 DW의 DDL을 다 붙여넣으면 수십만 토큰이다. 내가 겪었던 프로젝트만 해도 테이블이 수천 개였다. 컨텍스트 윈도우에 다 못 넣는다. 넣더라도 LLM이 그 안에서 정확한 테이블을 골라내는 건 Needle-in-a-Haystack 문제다.\n보안 이슈도 있다. 기업 내부 스키마를 외부 API에 보낼 수 없다. Row-level Security도 걸린다. 같은 \u0026ldquo;매출\u0026quot;이라도 A그룹사 사용자와 B그룹사 사용자가 봐야 하는 범위가 다르다.\n지속성이 가장 큰 문제다. DDL은 바뀐다. 비즈니스 용어 정의도 바뀐다. 차세대 정보계 프로젝트에서 EIS 오픈 후에도 단계별 릴리즈를 계속했는데, 매번 메타데이터가 변경됐다. 일회성 프롬프트가 아니라 변경을 감지해서 자동으로 RAG Store를 갱신하는 파이프라인이 필요하다.\n별도의 플랫폼이 필요하다는 결론이었다.\nDataNexus가 하려는 것 네 가지 컴포넌트로 구성된다.\n메타데이터 카탈로그 — 비즈니스 용어 정의, 테이블 메타, 데이터 계보를 한 곳에서 관리한다. 온톨로지의 원천(Source of Truth). NL2SQL 엔진 — 자연어를 SQL로 변환하되, 온톨로지에서 가져온 맥락을 프롬프트에 주입해서 정확도를 높인다. 문서 지식엔진 — 사업보고서, 정책문서 같은 비정형 데이터를 GraphRAG + 벡터 하이브리드로 검색한다. 그래프 DB — 온톨로지를 지식 그래프로 저장하고, 그룹사별 Multi-DB로 데이터를 격리한다. 한 줄로 요약하면: 카탈로그에서 정의한 온톨로지가 NL2SQL과 문서검색에 자동 동기화되어, 사용자의 자연어 질문에 맥락을 입혀준다. 각 컴포넌트에 사용한 구체적인 오픈소스와 선정 이유는 다음 글에서 다룬다.\n왜 지금인가 기술적 동기만으로 이 프로젝트를 시작한 건 아니다.\n이전 직장에서 12년간 DW/BI 컨설팅을 했다. 팀을 2명에서 20명으로 키우고, 고객사 C레벨 대상 발표를 수십 회 하면서 \u0026ldquo;왜 메타데이터가 중요한지\u0026rdquo; 설명하는 데 커리어의 상당 부분을 썼다. 10년 넘게 느낀 건 — 이 문제가 사람의 설득만으로는 안 풀린다는 거였다. 시스템이 필요하다.\nLLM이 나오면서 문제의 프레임이 바뀌었다.\n범용 모델이 빠르게 좋아지고 있다. 단순 기획이나 문서 생성은 곧 commodity가 된다. 20년간 쌓아온 \u0026ldquo;기업 데이터의 맥락을 이해하는 능력\u0026quot;이 가치를 유지하려면, 그 맥락을 구조화해서 기계에 주입하는 시스템이 있어야 한다.\nDataNexus가 노리는 영역은 Non-verifiable Domain + Proprietary Data다. LLM 연구에서 Non-verifiable Domain이란 수학이나 코딩처럼 정답을 자동 검증할 수 있는 영역(Verifiable)의 반대편이다. 품질 평가가 주관적이고 외부에서 즉시 판별하기 어려운 영역. 기업 내부의 암묵적 지식, 역할별 해석 차이, 비공개 운영 데이터가 여기에 해당한다. 이런 데이터 위에 쌓는 경쟁 우위를 AI 전략에서는 Data Moat라고 부른다.\n이 우위가 영구적이라고는 생각하지 않는다. 범용 모델의 일반화 속도를 DataNexus의 데이터 축적 속도가 앞서야 한다. 시간이 중요하다. 올해 상반기까지 MVP를 내고 데이터 축적 루프를 돌리는 게 목표다.\n방어선 요소 구현 방향 축적 방식 온톨로지 기반 맥락 메타데이터 카탈로그 + SKOS 호환 도메인 전문가의 용어 정제 역할별 해석 차이 페르소나별 응답 최적화 사용 패턴 기반 개인화 시간축 지식 그래프 Temporal Knowledge Graph Episode 기반 실시간 축적 비공개 운영 데이터 그래프 DB 격리 + Row-level Security 그룹사별 독립 자산화 이 블로그의 목적 DataNexus를 만들면서 부딪히는 의사결정, 삽질, 해결 과정을 기록한다.\n다룰 것들:\n기술 스택을 선정한 과정 (후보군 탈락 사유 포함) 메타데이터 카탈로그의 Business Glossary를 온톨로지로 쓸 때의 한계와 우회 SKOS 호환 레이어를 넣은 이유 NL2SQL 엔진의 User-Aware 설계와 Row-level Security CQ(Competency Questions)로 온톨로지를 사전 검증하는 법 Query Router에서 결정론적 vs 확률론적 라우팅을 나누는 기준 에이전트 태스크를 쪼개는 79% Rule 이론보다는 실제로 부딪힌 문제와 그걸 어떻게 풀었는지 — 또는 아직 못 풀었는지 — 를 쓸 예정이다.\n다음 글 DataNexus의 기술 스택 — 4개의 오픈소스를 이 조합으로 결정하기까지의 과정. 후보군에서 탈락한 것들과 그 이유를 정리한다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/001-why-datanexus/","summary":"엔터프라이즈 데이터 분석의 구조적 문제를 풀기 위해 온톨로지 기반 데이터 에이전트를 설계하기 시작한 이유.","title":"1. 왜 DataNexus를 만드는가"},{"content":"Junho Lee (이준호) Data \u0026amp; AI Platform Architect.\nWeb/ERP 개발자로 시작해서 DW/BI 엔지니어, Technical Lead, 컨설팅 본부장을 거쳤고, 지금은 AI 기반 데이터 플랫폼을 설계하고 만들고 있다.\n해온 일 커리어 전반부는 대규모 DW/BI 구축과 클라우드 마이그레이션에 집중했다. 수십TB급 DW의 클라우드 전환을 Tech Leader로 수행했고, 대형 차세대 정보계 구축 프로젝트를 멀티벤더 PMO로 리드했다.\n컨설팅 본부를 직접 빌딩한 경험도 있다. 채용, 교육, 기술 조직 운영, Presales, C레벨 대상 세미나까지. 기술만 하는 사람은 아니다.\n최근에는 데이터와 AI의 접점에서 일하고 있다. LLM 기반 BI Agent 구축, NL2SQL 솔루션 설계를 거쳐 지금은 DataNexus라는 온톨로지 기반 통합 데이터 에이전트 플랫폼을 설계/구축하고 있다.\nDataNexus \u0026ldquo;Everyone is an Analyst.\u0026rdquo;\n자연어로 사내 데이터를 탐색하고 분석하는 AI 에이전트 플랫폼. 온톨로지 기반 NL2SQL, GraphRAG, Data Catalog를 결합해서 비정형 문서와 정형 DB를 하나의 인터페이스로 다루는 구조다.\n이 블로그는 DataNexus를 만들어가는 과정을 기록한다. 아키텍처 결정, 기술 선택의 이유, 삽질과 해결 과정을 있는 그대로 남긴다.\n기술 스택 현재 집중: 온톨로지 LLM RAG, NL2SQL, Vanna, Langchain, Neo4j(DozerDB), DataHub, MCP\nDW/Data Lake: Azure Synapse, BigQuery, Redshift, PostgreSQL, Oracle, Yellowbrick\nBI/시각화: Power BI, Tableau, MicroStrategy, Qlik Sense, Looker, Superset\nETL/ELT: SSIS, ADF, SAP Data Services, IBM DataStage, Informatica, Databricks\nCloud: Azure, AWS, GCP\nContact GitHub: @biz-agentic-ai LinkedIn: linkedin.com/in/leejuno ","permalink":"https://biz-agentic-ai.github.io/about/","summary":"이준호 - Data \u0026amp; AI Platform Architect","title":"About"}]