[{"content":"\u0026ldquo;이 점선은 뭔가요?\u0026rdquo; 프로젝트 초반 모델 리뷰에서 자주 벌어지는 일이다. 기간계 모델러가 ERD를 그려왔는데, 옆에 앉은 모델러가 관계선을 보고 묻는다. \u0026ldquo;이 점선은 비식별 관계 맞죠?\u0026rdquo; 원래 모델러가 고개를 갸웃한다. \u0026ldquo;아뇨, 이건 선택적 관계인데요.\u0026rdquo;\n둘 다 맞다. 다른 표기법을 쓰고 있을 뿐이다.\nERD는 모델러와 개발자, 현업이 같은 의미로 이해해야 하는 약속된 언어다. 문제는 그 약속이 하나가 아니라는 점이다. 같은 까마귀발(Crow\u0026rsquo;s Foot) 표기법이라도 IE 방식이냐 Barker 방식이냐에 따라 점선의 의미가 달라진다. IDEF1X는 아예 표현 체계가 다르다.\n도구를 바꿀 때마다, 프로젝트를 옮길 때마다 이 차이에 부딪힌다. 표기법을 모르면 같은 모델을 보고 다른 이야기를 하게 된다.\nCrow\u0026rsquo;s Foot - IE 방식 가장 널리 쓰이는 표기법이다. 1980년대 James Martin과 Clive Finkelstein이 개발한 IE(Information Engineering) 방식에서 사용한다. 관계선 끝에 세 가지 기호를 조합해서 카디널리티를 표현한다.\n──| 대시: 정확히 1 ──○ 원: 0 ──\u0026lt; 까마귀발: N(여럿) 이걸 조합하면 네 가지 패턴이 나온다.\n──|| 정확히 1 (1) ──○| 0 또는 1 (0..1) ──|\u0026lt; 1 이상 (1..N) ──○\u0026lt; 0 이상 (0..N) 식별 관계는 실선, 비식별 관계는 점선 으로 구분한다. 식별 관계란 상위 엔터티의 PK가 하위 엔터티 PK의 일부로 포함되는 것이다. 주문번호가 주문상품의 PK 일부가 되는 경우가 대표적이다.\n대부분의 모델링 툴에서 기본으로 제공하는 방식이라 접할 기회가 가장 많다.\nBarker 표기법 같은 까마귀발 계열이지만 해석이 다르다. Richard Barker가 만든 표기법으로, Oracle 툴셋에 적용되어 있다.\nIE와의 핵심 차이:\n기호 IE 방식 Barker 방식 점선 비식별 관계 선택적 참여 (0 or 1) 실선 식별 관계 정확히 1 (필수 참여) 대시 정확히 1 식별 관계 같은 점선이 IE에서는 \u0026ldquo;비식별 관계\u0026rdquo;, Barker에서는 \u0026ldquo;선택적 참여\u0026quot;를 뜻한다. 이 차이를 모르면 모델을 완전히 다르게 읽는다. DA# 같은 툴이 Barker 방식을 기본으로 쓰고 있어서, 다른 툴과 섞어 쓸 때 혼동이 생기기 쉽다.\nIDEF1X 표기법 1980년대 미 공군에서 개발한 표기법이다. 까마귀발 대신 관계선 끝에 작은 원으로 카디널리티를 표현한다.\n── 원 없음: 정확히 1 ──◇ 빈 원: 0 또는 1 ──● 속이 찬 원: 0 또는 N ──●P 속이 찬 원 + P: 1 또는 N 식별 관계는 실선, 비식별 관계는 점선이다. 이 부분은 IE 방식과 같다.\n변형도 있다. 모두 속이 찬 원을 쓰면서 Z(0 or 1), P(1 or N), N(정확히 N개) 같은 문자를 함께 표시하는 방식이다. 아무 표시가 없으면 0, 1 또는 N을 의미한다. ERwin 같은 툴에서 이 표기법을 쓸 수 있다.\n같은 비즈니스 규칙, 다른 그림 표기법 차이를 체감하려면 같은 비즈니스 규칙을 각 방식으로 읽어보는 게 가장 빠르다.\n비즈니스 규칙이 이렇다고 하자.\n하나의 고객은 여러 건의 주문을 할 수 있다 (안 할 수도 있다) 하나의 주문은 반드시 하나의 고객에 의해 이뤄진다 하나의 주문은 반드시 하나 이상의 주문상품을 포함한다 하나의 주문상품은 반드시 하나의 주문에 포함된다 하나의 상품은 여러 주문상품에 포함될 수 있다 (안 될 수도 있다) 하나의 주문상품은 반드시 하나의 상품이다 IE 방식으로 읽으면 이렇다.\n고객 ─ ─ ─○\u0026lt;──||─ 주문 ──||──|\u0026lt;─ 주문상품 ─||──○\u0026lt; ─ ─ ─ 상품 (비식별, 0:N → 1) (식별, 1 → 1:N) (비식별, 1 → 0:N) 고객과 주문 사이는 점선 이니 비식별 관계다. 고객번호가 주문의 PK에 포함되지 않는다. 까마귀발+원 쪽이 고객이니, 고객은 주문을 안 하거나 여러 번 할 수 있다. 대시 쪽이 주문이니, 하나의 주문에는 정확히 하나의 고객이 있다.\n주문과 주문상품 사이는 실선 이니 식별 관계다. 주문번호가 주문상품 PK의 일부가 된다. 까마귀발+대시 쪽이 주문상품이니, 하나의 주문에는 최소 하나 이상의 주문상품이 있다.\n같은 규칙을 Barker나 IDEF1X로 그리면 선의 스타일과 기호가 달라진다. 비즈니스 규칙은 동일한데 읽는 법이 바뀌는 것이다.\n프로젝트에서 실제로 해야 할 것 표기법을 전부 외우는 게 목적이 아니다. 프로젝트에서 ERD를 공통 언어로 쓰기 위한 준비다.\n현업이 보든, 모델러가 보든, 개발자가 보든 같은 의미로 읽혀야 한다. 그런데 프로젝트마다 쓰는 툴이 다르고, 같은 툴이라도 표기법 설정이 다를 수 있다. DA#은 Barker가 기본이고, ERwin이나 PowerDesigner는 IE나 IDEF1X를 쓴다. MicroDesigner처럼 여러 표기법을 전환할 수 있는 툴도 있는데, 전환할 때 일부 표현이 완벽하게 매핑되지 않는 경우도 있다.\n프로젝트 시작 시 표기법을 통일하는 것이 첫 번째다. 통일이 안 되면 적어도 팀 전원이 사용 중인 툴의 표기법을 숙지해야 한다. 작은 차이 같지만, \u0026ldquo;이 점선이 비식별인지 선택적 참여인지\u0026quot;를 다르게 해석하는 순간 설계 의도가 왜곡된다.\n한 가지 더. 표기법의 차이는 절대적인 것이 아니다. 같은 IE 방식이라도 MicroDesigner에서는 대시 2개를 하나로 표현하는 것처럼 툴에 따라 세부 표현이 다를 수 있다. 반드시 사용하는 툴의 도움말을 통해 확인하는 습관이 필요하다.\n클라우드 시대의 ERD 클라우드 DW 환경에서 ERD의 형태가 조금씩 바뀌고 있다. dbt에서는 SQL 기반으로 모델을 정의하고, ERD를 직접 그리기보다 코드에서 자동 생성하는 방식이 늘고 있다. Mermaid나 DBML 같은 텍스트 기반 다이어그램도 많이 쓰인다.\n도구가 바뀌어도 관계를 표현하는 본질은 같다. 카디널리티가 뭔지, 식별 관계와 비식별 관계가 어떻게 다른지 이해하지 못하면 어떤 도구를 써도 모델을 제대로 읽을 수 없다. 형식은 바뀌지만 표현해야 하는 것은 바뀌지 않는다.\n다음 글에서는 ERD에서 자주 등장하는 수퍼-서브 타입을 다룬다. 고객을 개인고객과 법인고객으로 나누는 것 같은, 일반화와 구체화의 표현 방식이다. 이것도 표기법마다 다르게 그린다.\n","permalink":"https://biz-agentic-ai.github.io/guides/dw-modeling/003-erd-notation/","summary":"Crow\u0026rsquo;s Foot, Barker, IDEF1X - 표기법이 다르면 같은 관계도 다르게 읽힌다. 프로젝트에서 ERD를 공통 언어로 쓰려면 표기법부터 맞춰야 한다.","title":"3. ERD 표기법 - 같은 그림, 다른 해석"},{"content":"\u0026ldquo;이 Unknown은 누가 넣은 건가요?\u0026rdquo; DW 모델 리뷰 자리에서 꼭 나오는 질문이다.\n상품 마스터 테이블을 열어보면 \u0026ldquo;Unknown\u0026quot;이라는 이름의 데이터가 들어 있다. 사원 테이블에도 있다. 기간계 시스템을 해온 사람이라면 당연히 의아하다. 마스터 테이블에 더미 데이터라니.\n비슷한 질문이 뒤따른다. \u0026ldquo;주문실적 테이블에 시점담당사원이라는 컬럼은 뭔가요? 기간계 주문 테이블에는 없던 건데.\u0026rdquo; DW 모델을 처음 접한 사람에게는 이것도 낯설다.\n두 모델의 차이를 키워드로 설명하는 자료는 많다. 비정규화, 스타스키마, 스노우플레이크. 검색하면 바로 나온다. 문제는 키워드만으로 \u0026ldquo;왜 이렇게 설계하는가\u0026quot;가 설명이 안 된다는 점이다. 목적부터 짚어야 한다.\n기간계 모델은 트랜잭션을 지킨다 OLTP 데이터 모델의 목표는 명확하다. 빈번한 입력과 수정 과정에서 정합성을 깨뜨리지 않는 것.\n이 목표가 모델의 생김새를 결정한다. 엔터티 사이의 관계가 엄격하다. 부서가 없으면 사원을 등록할 수 없고, 상품이 없으면 주문이 발생할 수 없다. 고객이 없는 주문도 존재하지 않는다. 모든 관계에는 선행 조건이 있고, 데이터가 발생하는 그 시점에 조건이 충족되어야 한다.\n이걸 보장하기 위해 정규화를 한다. 중복을 줄이면 수정할 곳이 한 군데로 줄고, 정합성이 깨질 여지가 작아진다. 최상위 마스터(코드 테이블 같은)부터 순서대로 등록하고, 그 위에 트랜잭션 데이터를 쌓는다. 순서가 틀어지면 안 된다.\n비유하면 이렇다. 할아버지가 있어야 아버지가 있고, 아버지가 있어야 아들이 있다. 존재 관계다. 사람이 있어야 사람의 행동이 기록된다. 행위 관계다. OLTP 모델은 이런 관계의 제약 조건을 빠짐없이 반영하는 데 집중한다.\nDW 모델은 접근 경로를 설계한다 DW 데이터 모델은 다른 문제를 푼다. 모든 데이터를 빠짐없이 적재하고, 분석 대상에 접근하는 경로를 만드는 것이다.\n\u0026ldquo;접근 경로\u0026quot;가 핵심이다. 주문실적이라는 분석 대상이 있다고 하자. 사원 기준으로도, 상품 기준으로도, 고객 기준으로도 들어갈 수 있어야 한다. 어느 경로로 가든 같은 결과가 나와야 하고, 성능도 비슷해야 한다. 스타스키마가 이 구조를 가장 직관적으로 표현한다.\n[사원] | [상품] — 주문실적 — [고객] | [직업] 주문실적을 중심에 놓고, 접근 경로가 되는 차원 테이블이 주변을 둘러싸는 형태다.\nOLTP 경험이 많은 사람이 이 모델을 보면 \u0026ldquo;비정규화한 OLTP\u0026quot;라고 오해하기 쉽다. ERD라는 도구가 같으니까 결과물도 같은 종류일 거라고 생각한다. 도구가 같을 뿐이다. 설계의 출발점이 다르다.\n시점 데이터라는 낯선 개념 OLTP 주문 테이블에는 \u0026ldquo;담당사원\u0026rdquo; 컬럼이 있다. 현재 담당사원을 가리킨다. DW의 주문실적 테이블에는 시점담당사원 이 있다. 주문이 발생한 바로 그 시점의 담당사원이다.\n왜 이런 게 필요한가. 상품 담당사원이 올해 A에서 B로 바뀌었다고 하자. OLTP에서는 현재 담당이 B다. 그걸로 끝이다. DW에서는 상황이 다르다. \u0026ldquo;작년 실적은 A 기준으로, 올해 실적은 B 기준으로 보고 싶다\u0026quot;는 요구가 자연스럽게 나온다. 상품담당사원이력이나 고객직업이력 같은 이력 데이터를 활용해서, 주문실적 적재 시점에 시점 데이터를 함께 만들어낸다.\nOLTP에서 퇴사한 사원은 마스터에서 비활성화하면 그만이다. DW에서는 과거 시점에만 존재했던 사원도, 더 이상 유효하지 않은 직업 코드도 마스터 테이블에 전부 남겨야 한다. 과거 분석에 필요한 데이터가 빠지면 안 되니까.\nUnknown이 존재하는 이유 DW 프로젝트에서 흔한 상황이 하나 있다. 과거 10년치 주문실적을 분석하려는데, 상품 마스터 관리가 부실해서 최근 상품만 남아 있다. 주문실적에는 상품ID가 찍혀 있는데 상품 테이블에는 해당 ID가 없다.\nOLTP였으면 이런 일 자체가 안 일어난다. 상품이 없으면 주문이 생길 수 없도록 설계했으니까. DW는 입장이 다르다. 이미 발생한 과거 데이터를 있는 그대로 적재해야 한다.\n이때 선택지가 몇 가지 있다.\n주문실적의 상품ID를 Unknown에 해당하는 ID로 바꾸거나 분석용 상품ID 컬럼을 하나 더 두어 이중 관리하거나 매핑 안 되는 상품ID를 적재 시점에 상품 마스터에 먼저 추가하고, 나머지 속성은 NULL이나 대체값으로 채우거나 어떤 방식이든 한 가지는 공통이다. 상품 마스터에 Unknown 이라는 기준 데이터를 미리 넣어 둔다는 것. 해당 상품의 담당사원도 알 수 없으니 사원 테이블에도 Unknown을 넣는다. 엔터티 간 관계를 형식적으로 충족시키되, 데이터가 발생한 시점이 아니라 적재하는 시점에 인위적으로 맞추는 방식이다.\nOLTP 모델러가 보면 불편할 수 있다. 인위적인 더미 데이터로 관계를 맞추다니. DW의 목적을 생각하면 합리적인 판단이다. 분석 대상 데이터를 빠뜨리지 않으면서, 어떤 접근 경로로 들어가든 일관된 구조가 유지되어야 하니까.\n관계를 맞추는 시점이 다르다 정리하면 이렇다.\nOLTP 는 데이터가 발생하는 시점에 관계 조건을 충족시킨다. 부서 없이 사원을 등록할 수 없고, 고객 없이 주문을 넣을 수 없다. 관계를 어기면 데이터 자체가 들어가지 않는다.\nDW 는 데이터를 적재하는 시점에 관계를 맞춘다. 원본에 누락이 있으면 Unknown으로 채운다. 과거 시점 데이터가 필요하면 이력에서 끌어와서 만든다. 적재 과정에서 일정한 개입을 통해 관계를 충족시키는 것이다.\nOLTP DW 목적 트랜잭션 처리, 정합성 보장 분석 데이터 적재, 접근 경로 설계 관계 충족 시점 데이터 발생 시점 데이터 적재 시점 누락 데이터 허용하지 않음 Unknown으로 처리 이력 관리 현재 상태 중심 시점 데이터 생성 설계 방향 정규화 (중복 최소화) 접근 경로 중심 (분석 편의) 이 차이를 이해하고 나면 DW 모델에서 \u0026ldquo;왜 이렇게 했지?\u0026ldquo;라는 의문이 상당 부분 풀린다.\n클라우드 시대에도 같은 이야기 이전 글에서 클라우드 DW의 물리적 제약 변화를 다뤘다. 스토리지가 싸졌고, 컬럼나 스토리지 덕에 조인 패턴이 달라졌고, ELT 패러다임으로 전환됐다.\n물리적 제약은 바뀌었지만 OLTP와 DW의 목적 차이는 여전하다. BigQuery를 쓰든 Synapse를 쓰든, 분석 데이터에 대한 접근 경로를 설계해야 하는 건 마찬가지다. Unknown 레코드가 필요한 상황도, 시점 데이터를 관리해야 하는 요건도 인프라가 바뀐다고 없어지지 않는다.\n달라진 게 있다면 이력 관리를 더 적극적으로 할 수 있게 됐다는 것 정도다. 스토리지 부담이 줄어서 SCD Type 2 방식으로 차원 이력을 쌓아도 부담이 덜하다. SCD 유형별 설계 방식은 시리즈 뒤쪽에서 구체적으로 다룬다.\n다음 글에서는 모델을 표현하는 도구, ERD 표기법의 차이를 짚어본다. 같은 관계를 그려놓아도 Crow\u0026rsquo;s Foot이냐 IDEF1X이냐에 따라 해석이 달라진다. 도구의 언어를 모르면 같은 모델을 보고도 다른 이야기를 하게 된다.\n","permalink":"https://biz-agentic-ai.github.io/guides/dw-modeling/002-oltp-vs-dw-model/","summary":"ERD가 같아 보여도 설계 철학은 완전히 다르다. OLTP는 트랜잭션 정합성, DW는 분석 접근 경로. 그 차이가 Unknown 레코드와 시점 데이터 같은 낯선 것들을 만든다.","title":"2. OLTP vs DW 모델 - 목적이 다르면 설계도 다르다"},{"content":"\u0026ldquo;스타스키마 안 해도 되나요?\u0026rdquo; 클라우드 DW 전환 프로젝트를 하면 꼭 나오는 질문이다.\n온프레미스에서 수년간 운영하던 DW를 BigQuery나 Azure Synapse로 옮기는 자리. 누군가가 묻는다. \u0026ldquo;거기는 Columnar Storage(컬럼기반 저장소)라 조인 비용이 다르다는데, 그러면 스타스키마 안 해도 되는 거 아닌가요?\u0026rdquo;\n답을 먼저 말하면 - 상황에 따라 다르다. 그런데 이 \u0026ldquo;상황에 따라 다르다\u0026quot;가 구체적으로 뭘 따져야 하는 건지를 아는 사람은 많지 않다.\n온프레미스 시절의 공식 Kimball의 Dimensional(Star-Schema) 모델링이 사실상 표준이던 시절이 있었다.\n이유는 단순했다. 디스크 I/O가 비쌌고, 조인은 더 비쌌다. Row 기반 스토리지에서 테이블 10개를 조인하면 쿼리 응답이 분 단위로 넘어갔다. 그래서 미리 조인해 놓는 게 합리적이었다.\n모델링 의사결정이 곧 성능 의사결정이었다. 어디까지 비정규화할 것인가, 집계 테이블을 몇 단계로 쌓을 것인가, 파티션 키를 뭘로 잡을 것인가. 이 결정들이 쿼리 응답 시간을 초 단위에서 분 단위로 갈랐다.\nKimball의 방법론은 이 제약 안에서 비즈니스 가독성과 쿼리 성능을 동시에 잡으려는 시도였다. 부서마다 제각각이던 차원 테이블을 전사 공통 기준으로 통일(Conformed Dimension)해서 일관성을 보장하고, Bus Matrix로 전사 통합을 설계하고. 방법론 자체의 완성도는 지금 봐도 높다.\n문제는 이 방법론이 만들어진 전제가 바뀌었다는 거다.\n클라우드가 바꾼 전제들 클라우드 DW로 오면서 물리적 제약이 근본적으로 달라졌다.\nColumnar Storage. BigQuery, Redshift, Synapse 모두 컬럼 기반이다. SELECT에서 필요한 컬럼만 읽는다. 컬럼이 수백 개인 테이블에서 서너 개만 조회하면 그것만 스캔한다. Row 기반에서는 전부 읽어야 했다.\nCompute/Storage 분리. 스토리지가 싸졌다. 중복 저장해도 비용 부담이 작다. 온프레미스에서 디스크 용량 아끼려고 정규화를 고민하던 것과는 상황이 다르다.\nMPP 아키텍처. 대규모 병렬 처리가 기본이다. 조인 비용이 온프레미스 RDBMS 대비 상대적으로 낮아졌다. 물론 공짜는 아니다 - 셔플이 발생하면 여전히 느리다. 하지만 \u0026ldquo;조인은 무조건 피하라\u0026quot;는 원칙이 더 이상 절대적이지 않다.\nELT 패러다임. 원본을 먼저 적재하고, DW 안에서 변환한다. 변환 로직을 DW 엔진의 컴퓨팅 파워로 처리한다. ETL 시절처럼 변환 서버를 별도로 두고 \u0026ldquo;다 만들어서 넣는\u0026rdquo; 구조가 아니다.\n반정형 데이터 지원. JSON, ARRAY, STRUCT를 네이티브로 다룬다. 전통적인 관계형 모델로 풀기 어려웠던 유연한 스키마를 DW 안에서 직접 처리할 수 있다.\n이 변화들이 기존 모델링 원칙의 근거를 흔든다. 하지만 근거가 약해진 것과 원칙이 틀린 것은 다른 이야기다.\n세 가지 선택지 클라우드 DW에서 자주 비교되는 세 가지 접근법이 있다.\n1. Kimball Dimensional 모델링 스타스키마, 팩트와 디멘션, Conformed Dimension. 여전히 가장 널리 쓰인다.\n클라우드에서도 유효한 이유가 있다. 비즈니스 사용자가 이해하기 쉽다. \u0026ldquo;매출 팩트를 고객 디멘션으로 잘라본다\u0026quot;는 구조는 BI 도구와도 궁합이 좋다. Power BI, Tableau, Looker 전부 이 구조를 전제로 최적화되어 있다.\n달라진 것도 있다. 집계 테이블을 미리 쌓아둘 필요가 줄었다. 컬럼나 스토리지에서 원본 팩트를 바로 집계해도 충분히 빠르다. SCD Type 2 같은 이력 관리도 스토리지 부담이 작아져서 더 적극적으로 쓸 수 있게 됐다.\n약점은 유연성이다. 스키마가 바뀌면 팩트/디멘션 구조를 재설계해야 한다. 애자일하게 빠르게 바뀌는 요구사항에 대응하기가 구조적으로 어렵다.\n2. Data Vault 2.0 Hub(비즈니스 키), Satellite(속성), Link(관계). 원본 데이터를 있는 그대로 이력과 함께 저장하는 데 초점을 맞춘 방법론이다.\n강점은 명확하다. 감사 추적성(auditability). 원본이 언제 어떤 값이었는지를 완전하게 보존한다. 소스 시스템이 추가되거나 스키마가 변경되어도 기존 구조에 영향을 주지 않는다. 병렬 적재가 가능해서 ELT 패러다임과도 잘 맞는다.\n현실적인 걸림돌이 있다. 직접 쿼리하기가 까다롭다. Hub-Satellite 조인을 여러 번 거쳐야 하나의 비즈니스 엔터티가 나온다. 그래서 결국 프레젠테이션 레이어(보통 스타스키마)를 따로 만들어야 한다. 모델링 레이어가 하나 더 생기는 셈이다. 팀이 Data Vault 경험이 없으면 학습 곡선도 가파르다.\n금융, 의료 같은 규제 산업에서 감사 추적이 필수일 때, 또는 소스 시스템이 수시로 추가되는 환경에서 강하다.\n3. One Big Table (OBT) 팩트와 디멘션을 전부 하나의 와이드 테이블에 합친다. 극단적인 비정규화다.\n클라우드에서 이게 통하는 이유가 있다. 컬럼나 스토리지에서는 200개 컬럼이 있어도 쿼리에 쓰는 5개만 읽으니까 성능 저하가 크지 않다. 조인이 없으니 쿼리가 단순하다. 개발 속도도 빠르다. dbt 같은 도구에서 한 번의 SELECT로 만들면 끝이다.\n대가가 있다. 데이터 정합성을 보장할 구조적 장치가 없다. 고객 주소가 바뀌면 모든 OBT를 다시 빌드해야 한다. 같은 디멘션 속성이 여러 OBT에 중복되면 어디가 맞는 건지 알 수 없다. 데이터가 적고 도메인이 단순할 때는 빠르지만, 규모가 커지면 관리가 급격히 어려워진다.\n프로토타이핑이나 단일 도메인의 분석용 마트로는 좋다. 전사 DW의 기반 구조로 쓰기에는 위험하다.\n실무에서의 판단 기준 \u0026ldquo;뭐가 최고냐\u0026quot;는 의미 없는 질문이다. 아래 기준으로 따져야 한다.\n팀 역량. Data Vault를 제대로 하려면 방법론을 아는 사람이 팀에 있어야 한다. 없으면 Kimball이 현실적이다. OBT는 진입 장벽이 낮지만 규모가 커지면 경험 있는 모델러가 더 절실해진다.\n데이터 복잡도. 소스 시스템이 3개인가 30개인가. 도메인이 하나인가 여러 개인가. 복잡도가 높을수록 Kimball의 Conformed Dimension이나 Data Vault의 Hub 구조가 필요하다.\n변경 빈도. 요구사항이 자주 바뀌는 환경이면 Data Vault가 유리하다. 안정적인 환경이면 Kimball로 충분하다.\n규제 요건. 감사 추적이 법적으로 필요하면 Data Vault를 고려해야 한다. 아니라면 오버엔지니어링이 될 수 있다.\n쿼리 패턴. BI 대시보드 중심이면 Kimball 구조가 BI 도구와 궁합이 좋다. Ad-hoc 분석이 많으면 OBT의 단순함이 장점이 된다.\n실무에서 자주 보는 패턴은 레이어드 접근이다.\nRaw (원본 적재) → Staging (정제) → Integration (통합 모델) → Mart (분석용) Integration 레이어를 Data Vault로 설계하고, Mart를 스타스키마로 제공하는 조합이 대표적이다. Data Vault는 허브-링크-위성 구조로 이력 추적과 유연한 확장에 특화된 모델이고, 스타스키마는 중심 팩트 테이블 주위에 차원 테이블을 별 모양으로 배치한 분석 최적화 모델이다. 또는 Integration을 중복 없이 정규화한 관계형 모델(3NF)로 잡고 Mart를 Kimball 방식으로 가는 전통적인 구조도 있다. 어느 쪽이든 핵심은 레이어를 나누는 것이다.\n한 레이어에서 원본 보존과 분석 최적화를 동시에 해결하려는 순간 복잡도가 폭발한다.\n모델링은 여전히 중요하다 클라우드로 오면서 바뀐 건 \u0026ldquo;왜 이렇게 모델링하는가\u0026quot;의 판단 기준이지, \u0026ldquo;모델링이 필요한가\u0026quot;의 여부는 아니다.\n스토리지가 싸졌으니 비정규화를 더 적극적으로 해도 된다. 조인 비용이 줄었으니 집계 테이블을 덜 만들어도 된다. 하지만 비즈니스 용어의 일관성, 데이터 계보(lineage), 도메인 간 통합 - 이런 문제는 인프라가 바뀐다고 사라지지 않는다.\n오히려 클라우드에서 모델링 없이 시작한 팀이 나중에 더 고생한다. OBT로 빠르게 만들어서 처음엔 잘 돌아간다. 1년 지나면 같은 지표의 정의가 테이블마다 다르고, 어디가 원본인지 아무도 모른다. 기술 부채는 조용히 쌓인다.\n도구와 인프라가 좋아진 만큼 모델링의 무게중심이 \u0026ldquo;성능 최적화\u0026quot;에서 \u0026ldquo;의미 체계의 일관성\u0026quot;으로 옮겨가고 있다. 결국 DataNexus에서 온톨로지로 풀려는 문제와 같은 맥락이다 - 기계가 읽을 수 있는 비즈니스 맥락이 없으면, 아무리 좋은 인프라 위에서도 데이터는 의미를 잃는다.\n","permalink":"https://biz-agentic-ai.github.io/guides/dw-modeling/001-cloud-era-dw-modeling/","summary":"Synapse, BigQuery, Redshift로 오면서 DW 모델링 관점이 어떻게 달라졌는지. Kimball, Data Vault, One Big Table - 실무에서의 판단 기준.","title":"1. 클라우드 DW에서 Kimball은 여전히 유효한가"},{"content":"왜 갑자기 외부 시스템 연동을 이야기하나 3편까지는 하나의 관점으로만 글을 썼다. NL2SQL 정확도. \u0026ldquo;LLM에게 비즈니스 맥락을 얼마나 잘 주입할 수 있느냐\u0026quot;가 모든 의사결정의 기준이었다.\n여기서부터 관점이 하나 더 추가된다. 플랫폼이다.\nDataNexus가 한 고객사 안에서만 돌아가는 NL2SQL 도구로 끝난다면, 외부 시스템 연동은 필요 없다. DozerDB 그래프가 잘 돌아가면 그만이다. 문제는 1편에서 이미 그보다 큰 그림을 그려놨다는 거다 — 그룹사별 멀티테넌시, Data Moat, 시간축 지식그래프. 이 단어들은 전부 \u0026ldquo;DataNexus가 단일 시스템이 아니라 여러 조직이 온톨로지를 교환하는 플랫폼이 되어야 한다\u0026quot;는 전제 위에 있다.\n유통 그룹이 백화점·마트·온라인몰을 갖고 있는데, 관계사마다 \u0026ldquo;매출\u0026quot;의 정의가 다르다. 이걸 통합하려면 각 관계사의 온톨로지를 공통 포맷으로 내보내서 매핑해야 한다. DataNexus만의 독자 포맷으로는 이 작업이 안 된다.\nSKOS 호환 레이어가 NL2SQL 정확도를 직접 올려주진 않는다. 대신 다른 방식으로 도움이 된다.\n금융 도메인의 FIBO나 유통의 GPC 같은 산업 표준 온톨로지를 가져오면, 밑바닥부터 용어를 정의하는 시간이 줄어든다. 온톨로지 구축이 빨라지면 NL2SQL 엔진에 맥락이 주입되는 시점이 앞당겨진다. 1편에서 \u0026ldquo;범용 모델의 일반화 속도를 DataNexus의 데이터 축적 속도가 앞서야 한다\u0026quot;고 썼는데, 축적 속도를 올리는 방법 중 하나가 표준을 가져다 쓰는 것이다. 고객사가 이미 Collibra나 Alation을 쓰고 있는 경우, DataNexus 온톨로지를 표준 포맷으로 내보낼 수 없으면 도입 자체가 막힌다. 아무리 NL2SQL 정확도가 높아도 기존 인프라와 공존 못 하면 현장에서 안 쓴다. 이건 유통사 프로젝트에서 겪은 교훈이다 — 기술보다 현장 적합성이 도입을 결정한다. 4편은 NL2SQL 엔진의 내부 성능 이야기가 아니다. DataNexus가 플랫폼으로 기능하기 위한 인터페이스 설계 이야기다. 관점이 다르니까 풀어야 할 문제도 다르다.\n외부 시스템과 연동이 안되었다. 이전 글에서 DataHub + DozerDB 이중 구조로 내부 온톨로지 문제를 풀었다. 내부 시스템에서만 쓰기에는 충분했다.\n문제는 외부 시스템과의 연동이었다. 금융 도메인을 탐색하다가 FIBO(Financial Industry Business Ontology)를 발견했는데, 금융업계 표준 용어 체계로 \u0026ldquo;Financial Product\u0026rdquo;, \u0026ldquo;Loan\u0026rdquo;, \u0026ldquo;Interest Rate\u0026rdquo; 같은 개념이 계층으로 정리돼 있다. 유통 쪽도 마찬가지다. GS1의 GPC(Global Product Classification)에는 \u0026ldquo;의류 → 여성복 → 원피스\u0026quot;처럼 상품 분류 체계가 표준으로 잡혀 있다. 의료엔 SNOMED CT, 제조엔 ISA-95. 도메인마다 수천 개 용어가 이미 정리돼 있는데, 이걸 가져다 쓸 수 있으면 온톨로지를 밑바닥부터 만들 필요가 없다.\nFIBO 파일을 열어봤다. OWL 포맷이었다. DozerDB 그래프에 넣으려니 구조 자체가 안 맞았다. 반대 방향도 마찬가지 — DataNexus 온톨로지를 고객사 기존 시스템(Collibra, TopBraid 같은)에 내보내고 싶어도 표준 포맷이 없으니 방법이 없었다. 내부에서는 잘 돌아가는데 밖으로 꺼내는 순간 무용지물이 되는 상황.\n외부 호환이 안 되면 생기는 문제가 한두 개가 아니다. 대기업은 이미 Collibra나 Alation 같은 메타데이터 관리 툴을 쓰고 있는 경우가 많다. DataNexus를 도입한다고 기존 용어 체계를 버리진 않는다. 표준 포맷으로 내보낼 수 있으면 공존이 가능한데, 못하면 용어 수백 개를 수작업으로 옮겨야 한다. 그것만으로 몇 달이 날아간다.\n유통 그룹처럼 백화점·마트·온라인몰이 각각 \u0026ldquo;매출\u0026quot;을 다르게 정의하는 경우, 그룹 차원에서 용어를 통합하거나 최소한 매핑하려면 공통 포맷이 있어야 한다. 없으면 관계사마다 따로 논다. 금융권은 감독 기관에 데이터 계보(lineage)나 용어 정의를 보고해야 하는 규제 요건도 있다. 거기에 벤더 종속(vendor lock-in) 문제까지. DataNexus를 쓰다가 다른 플랫폼으로 바꿔야 할 수도 있는데, 표준 포맷으로 Export가 되면 옮길 수 있지만 안 되면 갇힌다. 도입을 결정하는 자리에서 이게 꽤 크게 작용한다.\n내부에서만 통하는 언어로는 외부와 대화할 수 없다.\n같은 그래프인데 언어가 다르다 DozerDB는 LPG(Labeled Property Graph) 방식을 쓴다.\n노드(동그라미)에 이름과 속성을 붙인다: 순매출 {definition: \u0026quot;총매출-반품-에누리\u0026quot;} 노드 사이에 화살표를 긋고, 그 화살표에도 속성을 단다: -[MANUFACTURES {since: \u0026quot;2024-01-01\u0026quot;}]-\u0026gt; 핵심은 화살표 자체에 \u0026ldquo;언제부터\u0026rdquo;, \u0026ldquo;신뢰도 얼마\u0026rdquo; 같은 정보를 달 수 있다는 점이다. 이전 글에서 MANUFACTURES, STOCKS 관계를 만들 때 이걸 활용했다.\nSKOS를 포함한 웹 표준들은 완전히 다른 체계를 쓴다. RDF(Resource Description Framework) — 모든 정보를 세 단어짜리 문장으로 쪼갠다.\n순매출 → broader → 매출 (순매출의 상위 개념은 매출이다) 순매출 → prefLabel → \u0026quot;순매출\u0026quot;@ko (한국어 이름은 \u0026ldquo;순매출\u0026quot;이다) 주술목(주어-서술어-목적어), 이 세 단어가 하나의 단위다. 트리플(triple) 이라고 부른다.\n여기서 갈린다. LPG는 관계에 속성을 자유롭게 붙일 수 있지만, RDF는 트리플이 원자 단위라서 관계 자체에 속성을 직접 달 수 없다. 대신 URI 기반이라 전 세계 어디서든 같은 개념을 같은 주소로 가리킬 수 있다. 시스템 간 데이터 교환에는 RDF가 압도적이다.\n내부 표현력의 LPG, 외부 호환성의 RDF. DataNexus에는 둘 다 필요했다.\nOWL은 과하고, RDFS는 부족하고 RDF 세계에도 표준이 여러 개다.\nOWL(Web Ontology Language) 은 가장 강력하다. 클래스 상속, 제약 조건, 자동 추론까지 지원한다. 법률 문서에 비유할 수 있다 — 모든 조항과 예외를 정밀하게 기술할 수 있는 대신 추론 엔진(Reasoner)을 별도로 띄워야 하고 학습 곡선이 가파르다. FIBO가 OWL인 이유도 금융 규제의 복잡성 때문이다.\nDataNexus가 하려는 건 추론이 아니다. \u0026ldquo;객단가가 뭔지, 어떤 테이블의 어떤 컬럼에 있는지\u0026quot;를 NL2SQL 엔진에 알려주는 맥락 제공이다. OWL은 과했다.\nRDFS(RDF Schema) 는 반대로 너무 가볍다. subClassOf 정도는 되는데 동의어나 용어 정의를 달 표준 속성이 없다.\nSKOS(Simple Knowledge Organization System) 가 딱 맞았다. 이름부터 \u0026ldquo;단순한 지식 조직 체계\u0026quot;다. 도서관 분류 체계나 시소러스(Thesaurus: 동의어·유의어·상하위어를 매핑해둔 용어 관계 사전)를 표현하려고 만든 W3C 표준인데 — DataNexus가 하는 일이 정확히 비즈니스 용어 사전 관리다. 핏이 맞을 수밖에 없다.\nSKOS 개념이 DataNexus 구조에 어떻게 대응되는지 정리하면:\nSKOS DataNexus (DataHub + DozerDB) 쉽게 말하면 skos:Concept Glossary Term / Entity 노드 용어 하나 skos:broader IsA 관계 (상위 개념) \u0026ldquo;객단가는 매출지표의 일종\u0026rdquo; skos:narrower IsA 역방향 (하위 개념) \u0026ldquo;매출지표의 하위에 객단가\u0026rdquo; skos:related RelatedTo 계열 \u0026ldquo;관련 있는 용어\u0026rdquo; * skos:prefLabel Term name (한국어 대표명) 공식 이름 skos:altLabel 동의어 (영문, 약어) \u0026ldquo;객단가\u0026rdquo; = \u0026ldquo;ATV\u0026rdquo;, \u0026ldquo;Average Transaction Value\u0026rdquo; skos:definition Term definition 용어 뜻풀이 skos:ConceptScheme 도메인별 용어 묶음 \u0026ldquo;유통 용어집\u0026rdquo;, \u0026ldquo;재무 용어집\u0026rdquo; * 주의할 점이 있다. skos:related는 양방향이다. \u0026ldquo;A related B\u0026quot;이면 자동으로 \u0026ldquo;B related A\u0026quot;도 성립한다. DozerDB의 SELLS나 SUPPLIED_BY 같은 관계는 방향이 있다. A매장이 B상품을 판매한다고 B상품이 A매장을 판매하진 않는다. 이 방향 정보는 SKOS로 내보낼 때 손실된다. 뒤에서 다시 다룬다.\nDozerDB 위에 SKOS를 얹다 원칙은 간단했다. 기존 그래프를 건드리지 않는다.\nDozerDB에 이미 들어간 MANUFACTURES, STOCKS, CALCULATED_FROM 같은 관계를 바꾸면 기존 쿼리가 전부 깨진다. 잘 돌아가는 구조를 표준 맞추겠다고 뒤집는 건 현장에서 가장 흔한 삽질이다.\n기존 노드 위에 SKOS 메타데이터를 오버레이 했다. 투명 필름 한 장 덮는 느낌이다.\n// 기존 Entity 노드에 SKOSConcept 라벨과 SKOS 속성을 추가 MATCH (net:Entity {name: \u0026#39;순매출\u0026#39;}) SET net:SKOSConcept SET net.skos_prefLabel = \u0026#39;순매출\u0026#39; SET net.skos_altLabel = [\u0026#39;Net Sales\u0026#39;, \u0026#39;순매출액\u0026#39;] SET net.skos_definition = \u0026#39;총매출에서 반품과 에누리를 차감한 금액\u0026#39; SET net.skos_inScheme = \u0026#39;finance-terms\u0026#39; 유통 도메인도 똑같다.\n// 유통 도메인 용어 예시 MATCH (atv:Entity {name: \u0026#39;객단가\u0026#39;}) SET atv:SKOSConcept SET atv.skos_prefLabel = \u0026#39;객단가\u0026#39; SET atv.skos_altLabel = [\u0026#39;ATV\u0026#39;, \u0026#39;Average Transaction Value\u0026#39;, \u0026#39;객단\u0026#39;] SET atv.skos_definition = \u0026#39;총매출액을 구매 고객수로 나눈 값\u0026#39; SET atv.skos_inScheme = \u0026#39;retail-terms\u0026#39; 기존 Entity 노드는 그대로다. SKOSConcept이라는 라벨과 skos_ 접두사 속성이 위에 붙을 뿐. 기존 Cypher 쿼리에는 영향이 없다.\nbroader/narrower 관계는 두 가지 방법이 있었다. BROADER, NARROWER 엣지를 IsA와 나란히 미리 만들어두거나, 기존 IsA 관계를 Export 시점에 skos:broader로 바꿔 출력하거나.\n후자를 택했다. 엣지를 이중으로 만들면 IsA가 바뀔 때마다 BROADER도 동기화해야 한다. 동기화가 어긋나면 데이터가 꼬인다. 원천(Source of Truth)은 하나여야 한다. Export 시점에 한 번 변환하는 게 단순하고 안전하다.\n가져오기와 내보내기 표준이 들어가면서 두 가지가 가능해졌다.\n가져오기 — FIBO에서 금융 용어를, GS1 GPC에서 상품 분류 체계를 DataNexus로 끌어오는 경우다. FIBO는 원래 OWL로 배포되지만 SKOS로 변환된 파생 버전도 있다. GPC도 마찬가지로 SKOS 매핑이 가능하다. \u0026ldquo;의류 → 여성복 → 원피스\u0026rdquo; 같은 상품 계층을 그대로 가져와서 유통 고객사 온톨로지의 뼈대로 쓸 수 있다. OWL의 복잡한 제약 조건은 빠지지만, DataNexus에 필요한 건 용어 이름·정의·상하위 관계뿐이다. SKOS 서브셋으로 충분하다.\n내보내기 — DataNexus 용어를 고객사 시스템으로 보내는 경우. DozerDB 그래프에서 특정 도메인(예: retail-terms)의 노드와 관계를 꺼내서 SKOS Turtle 포맷으로 변환한다.\n@prefix skos: \u0026lt;http://www.w3.org/2004/02/skos/core#\u0026gt; . @prefix dnx: \u0026lt;http://datanexus.ai/ontology/\u0026gt; . dnx:atv a skos:Concept ; skos:prefLabel \u0026#34;객단가\u0026#34;@ko ; skos:altLabel \u0026#34;ATV\u0026#34;@en, \u0026#34;Average Transaction Value\u0026#34;@en ; skos:definition \u0026#34;총매출액을 구매 고객수로 나눈 값\u0026#34;@ko ; skos:broader dnx:sales-metrics ; skos:inScheme dnx:retail-terms . dnx:sales-metrics a skos:Concept ; skos:prefLabel \u0026#34;매출지표\u0026#34;@ko ; skos:narrower dnx:atv, dnx:net-sales, dnx:upt ; skos:inScheme dnx:retail-terms . 유통 현장에서 \u0026ldquo;객단가\u0026quot;라고 부르는 걸 어떤 시스템에서는 \u0026ldquo;ATV\u0026quot;로, 어떤 곳에서는 \u0026ldquo;평균구매단가\u0026quot;로 부른다. altLabel에 이 별칭들을 다 넣어두면 NL2SQL 엔진이 어떤 이름으로 질문이 들어와도 같은 테이블을 찾을 수 있다. 이 파일을 Collibra든 TopBraid이든 SKOS를 지원하는 어떤 시스템에든 넣을 수 있다.\n가져오기/내보내기가 되면 앞서 얘기한 문제들이 풀린다. 유통 그룹에서 백화점은 \u0026ldquo;매출\u0026quot;을 점포별 POS 합산으로, 온라인몰은 결제 완료 기준으로, 마트는 반품 차감 후 기준으로 각각 정의하고 있다고 하자. 각 관계사가 DataNexus에 자기 용어를 SKOS로 내보내면, 그룹 본사에서 이걸 받아 매핑 테이블을 만들 수 있다. \u0026ldquo;백화점의 매출 = 온라인몰의 확정매출 = 마트의 순매출\u0026quot;이라는 관계가 표준 포맷으로 잡히는 거다. 금융 고객사라면 감독 기관에 용어 정의와 데이터 계보를 보고해야 할 때 SKOS Turtle 파일을 그대로 제출하거나, 기관이 요구하는 포맷으로 변환할 수 있다. 표준이 없으면 이런 건 전부 수작업이다.\nSchema.org 같은 RDFS/OWL 기반 표준은 이 SKOS 레이어 범위 밖이다. 필요해지면 별도 변환기를 만들면 되지만 당장 우선순위는 아니다.\n남은 한계 SKOS로 전부 해결되진 않는다.\nSKOS에는 레이블 자체에 메타데이터를 붙이는 확장(SKOS-XL)이 있다. \u0026ldquo;순매출\u0026quot;이라는 이름이 언제 등록됐는지, 누가 승인했는지를 기록할 수 있다. 다국어 레이블 관리가 복잡해지면 꺼내 써야 할 수도 있는데, 아직은 안 넣었다.\nOWL 수준의 추론도 SKOS 범위 밖이다. \u0026ldquo;A가 B의 하위이고, B가 C의 하위이면, A는 C의 하위다\u0026rdquo; 같은 자동 추론. 온톨로지 규모가 작을 땐 없어도 되는데, 수천 개 용어가 쌓이면 얘기가 달라질 수 있다.\n가장 아쉬운 건 커스텀 관계 Export다. DozerDB의 SELLS, STOCKS, SUPPLIED_BY 같은 유통 도메인 특화 관계는 SKOS 표준에 대응하는 게 없다. \u0026ldquo;A매장이 B상품을 판매한다\u0026quot;는 방향이 있는 관계인데, skos:related로 뭉뚱그리면 방향과 의미가 사라진다. dnx:sells 같은 커스텀 네임스페이스로 확장하면 정보는 보존되는데, 받는 쪽이 이 커스텀 관계를 이해할 수 있어야 한다. 정보 손실 vs 호환성 — 트레이드오프다.\n커스텀 관계를 내보내는 구체적인 방법 skos:related로 뭉뚱그리면 의미가 사라진다고 했다. 그래서 어떻게 하느냐.\nDataNexus 전용 네임스페이스를 정의한다.\n@prefix dnx: \u0026lt;http://datanexus.ai/ontology/relation/\u0026gt; . dnx:atv-store a skos:Concept ; skos:prefLabel \u0026#34;객단가-매장 관계\u0026#34;@ko ; dnx:relationshipType \u0026#34;SoldBy\u0026#34; ; dnx:direction \u0026#34;outgoing\u0026#34; ; dnx:confidence 0.95 ; dnx:validFrom \u0026#34;2024-01-01\u0026#34; . dnx:relationshipType, dnx:direction, dnx:confidence 같은 커스텀 속성으로 DozerDB의 SELLS 관계가 가진 방향성과 메타데이터를 보존한다. 받는 쪽 시스템이 dnx: 네임스페이스를 이해하면 정보 손실 없이 복원할 수 있고, 이해 못 하면 skos:related로 폴백한다. 정보가 사라지는 게 아니라 읽을 수 있는 시스템에서만 보이는 거다.\n현실적으로는 이렇게 운영한다.\nExport 대상 방식 정보 보존율 SKOS 네이티브 시스템 (Collibra, TopBraid) skos: 표준 속성만 포함 ~80% (방향, 속성 손실) DataNexus 간 교환 (그룹사 ↔ 그룹사) dnx: 커스텀 네임스페이스 포함 ~95% (거의 완전 보존) 규제 보고용 skos: + skos:note에 커스텀 관계 텍스트 기록 ~85% (사람이 읽을 수 있는 수준) DataHub 쪽에서는 Export 시점에 미매핑 속성을 처리하는 규칙도 정해 뒀다.\nDozerDB 속성 SKOS Export 시 처리 confidence dnx:confidence (커스텀) 또는 skos:note에 텍스트로 기록 since / valid_until dnx:validFrom / dnx:validUntil 또는 skos:historyNote cardinality dnx:cardinality (커스텀 전용, SKOS에 대응 없음) operator (CALCULATED_FROM) dnx:calculationOperator 완벽하진 않다. dnx: 네임스페이스는 DataNexus 생태계 안에서만 의미가 있고, 외부 시스템이 이걸 해석하리라는 보장은 없다. 표준의 한계를 커스텀 확장으로 메꾸면 결국 새로운 비표준을 만드는 셈이다. 이 지점에서 더 나아가려면 SKOS-XL이나 별도의 Application Profile을 정의해야 하는데, 지금은 과하다. 필요해지면 그때 넣는다.\n80%는 SKOS 표준으로 커버하고, 20%는 DozerDB 커스텀 관계로 보완한다. 표준이 못 담는 부분은 내부 확장으로 채우되, 무리해서 표준 안에 구겨넣지 않는다.\n다음 글 온톨로지를 만들었는데, 이게 제대로 된 건지 어떻게 알까. 다음 글에서는 CQ(Competency Questions)로 온톨로지를 사전 검증하는 방법을 다룬다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/004-skos-compatibility-layer/","summary":"DataNexus 온톨로지를 외부와 연결하기 위해 SKOS를 선택한 이유. LPG와 RDF, 두 그래프 모델을 잇는 호환 레이어 설계.","title":"4. SKOS 호환 레이어를 왜 넣었는가"},{"content":"\rGoogle Colab에서 실습하기\r왜 Glossary를 온톨로지로 쓰려 했나 DataNexus의 핵심 아이디어는 단순하다. 비즈니스 용어 사이의 관계를 그래프로 정의해두면, NL2SQL 엔진이 그 그래프를 참조해서 자연어를 SQL로 바꿀 수 있다. 이 그래프가 온톨로지다.\n온톨로지라고 하면 학술 논문에나 나올 것 같은데, 실체는 별거 없다. \u0026ldquo;순매출은 매출의 한 종류다(IsA)\u0026rdquo;, \u0026ldquo;매출은 총매출, 반품, 에누리를 포함한다(HasA)\u0026rdquo;. 사람 머릿속에 있는 업무 지식을 기계가 읽을 수 있게 옮긴 것뿐이다.\n이걸 어디에 저장할지가 고민이었다. 온톨로지 전용 시스템을 하나 더 띄우면 관리 포인트가 늘어난다. 이미 DataHub를 메타데이터 플랫폼으로 쓰고 있었고, 거기 Business Glossary 가 딸려 있었다. 용어 등록, 관계 설정 다 된다. 이전 글에서 Glossary의 관계 4종(IsA, HasA, RelatedTo, Values)이면 비즈니스 용어 계층구조를 충분히 표현할 수 있다고 봤었다.\n시스템 하나를 줄일 수 있다는 게 매력적이었다. GraphQL API로 프로그래밍 접근도 되고, 용어가 변경되면 Kafka MCL(Metadata Change Log) 이벤트가 자동으로 나간다. 나쁘지 않은 출발점이었다.\nGlossary에 용어를 넣기 시작했다 DataHub 세팅하고 제일 먼저 한 게 Glossary Term 등록이었다. \u0026ldquo;순매출 IsA 매출\u0026rdquo;, \u0026ldquo;매출 HasA 총매출, 반품, 에누리\u0026rdquo;. 이런 식으로 용어를 넣고 관계를 걸었다.\n기본 계층구조는 깔끔하게 들어갔다. 매출 → 총매출, 순매출 → 실매출.\n문제는 그 다음이었다.\n관계 4종의 한계: \u0026ldquo;공장과 제품\u0026rdquo; 실제 업무 데이터를 모델링하면서 벽에 부딪혔다.\n\u0026ldquo;A 공장에서 생산된 B 제품\u0026quot;과 \u0026ldquo;A 공장에 재고가 있는 B 제품\u0026rdquo;. 둘 다 공장과 제품 사이의 관계인데, 하나는 생산(Manufactures), 하나는 재고(Stocks)다. 의미가 완전히 다르다.\nDataHub Glossary에서 이걸 표현하면? 둘 다 RelatedTo가 된다. \u0026ldquo;공장 RelatedTo 제품\u0026quot;이 두 개 생기는데, 어느 게 생산이고 어느 게 재고인지 구분할 방법이 없다.\n이게 왜 치명적이냐면—DataNexus의 NL2SQL 엔진이 온톨로지를 보고 SQL을 만들기 때문이다. \u0026ldquo;A 공장에서 생산된 제품 목록 보여줘\u0026quot;라는 질문이 들어오면, 엔진은 공장-제품 관계를 찾아서 해당 테이블과 JOIN 경로를 결정한다.\n사용자 질문: \u0026ldquo;A 공장에서 생산된 제품은?\u0026quot;\n온톨로지 조회: 공장 → RelatedTo → 제품 (생산? 재고? 알 수 없음)\n→ LLM이 production 테이블 대신 inventory 테이블을 JOIN할 수 있음 → 잘못된 결과 반환\n관계 유형이 RelatedTo 하나뿐이니 엔진한테는 판단 근거가 없다. 잘못된 JOIN을 타면 사용자에게 엉뚱한 데이터가 나간다.\n확장하려면 재배포가 필요하다 DataHub에서 관계를 세분화하면 되지 않느냐. 안 된다.\nPDL(Persona Data Language)로 새 Aspect를 정의하고, @Relationship 어노테이션으로 관계 유형을 선언하고, DataHub를 빌드해서 재배포해야 한다. 관계 유형 하나 추가할 때마다 이 사이클을 돌려야 한다.\n비즈니스 모델링을 하다 보면 관계는 계속 늘어난다. \u0026ldquo;공급(Supplies)\u0026rdquo;, \u0026ldquo;검수(Inspects)\u0026rdquo;, \u0026ldquo;반품(Returns)\u0026rdquo;\u0026hellip; 업무 맥락에 따라 수십 가지가 필요해지는데, 하나마다 코드 고치고 재배포하는 건 현실적이지 않다.\n파고 들어가니 더 나왔다 관계 유형만 문제가 아니었다.\n동의어 충돌 \u0026ldquo;순매출\u0026quot;과 \u0026ldquo;실매출\u0026quot;을 동의어로 등록했다. 같은 개념인데 이름만 다른 경우다. 그런데 두 용어 모두 \u0026ldquo;Net Sales\u0026quot;라는 영문 동의어를 갖고 있었다. 하나의 영문명에 한글 용어 두 개가 매핑된 상황—DataHub는 이걸 그냥 넘긴다. 경고도 없다.\nNL2SQL에서 동의어 매핑이 꼬이면 엔진이 엉뚱한 용어를 참조한다. 용어가 수백 개를 넘어가면 이런 충돌을 사람 눈으로 잡을 수 없다. 커스텀 검증 로직을 따로 짜야 한다는 뜻이다.\n시각화 DataHub UI는 데이터 계보(Lineage) 탐색에 맞춰져 있다. 테이블 A → 테이블 B로 데이터가 흐르는 방향성 있는 트리.\n온톨로지는 구조가 다르다. 노드 수십~수백 개가 다대다로 엮인 그물망이다. \u0026ldquo;제품\u0026quot;이 \u0026ldquo;공장\u0026rdquo;, \u0026ldquo;창고\u0026rdquo;, \u0026ldquo;거래처\u0026rdquo;, \u0026ldquo;카테고리\u0026quot;와 전부 다른 관계로 연결되어 있고, 그 노드들끼리 또 서로 물려 있다. DataHub에는 이런 그래프를 탐색할 화면 자체가 없다.\n만들어 놓고 전체 그림을 못 보면 관리가 안 된다.\n관계에 속성을 붙일 수 없다 이게 제일 문제였다.\nDataHub Glossary에서 \u0026ldquo;A RelatedTo B\u0026quot;를 설정하면 그 관계에 아무것도 더 달 수 없다. 실무에서는 관계 자체에 정보가 필요한 경우가 많다.\n신뢰도(confidence) 가 대표적이다. 자동 추출된 관계는 0.7, 전문가가 직접 정의한 관계는 0.95—이 차이를 NL2SQL 엔진이 알아야 한다. 유효 기간(temporal) 도 마찬가지다. 조직 개편으로 부서-제품 매핑이 바뀌면, \u0026ldquo;이 관계가 언제부터 언제까지 유효한지\u0026quot;를 추적해야 한다. 카디널리티(cardinality) 는 JOIN 전략에 직접 영향을 준다.\n조직 개편으로 부서-제품 매핑이 바뀌면, 과거 시점 조직 구조로 현재 데이터를 조회하게 된다. 리포트 수치가 안 맞는 전형적인 원인이다. 관계에 시간축이 없으면 이걸 막을 방법이 없다.\n정리: 되는 것과 안 되는 것 되는 것 안 되는 것 용어 정의 (name, definition) 세분화된 관계 유형 (MANUFACTURES, STOCKS 등) 동의어 등록 (커스텀 필드) 동의어 중복/충돌 자동 감지 4종 관계 (IsA, HasA, RelatedTo, Values) 관계에 속성 부여 (신뢰도, 유효 기간) GraphQL API로 프로그래밍 접근 복잡한 그래프 탐색 UI Kafka MCL 이벤트 스트림 재배포 없는 실시간 관계 유형 확장 DataHub Glossary는 용어 사전으로서는 쓸 만하다. 온톨로지 저장소로는 표현력이 모자랐다.\n역할을 나눴다: DataHub + DozerDB Glossary를 통째로 버리는 건 답이 아니었다. 용어 정의의 원천(Source of Truth)으로 DataHub를 대체할 게 없다. GraphQL API, Kafka MCL 이벤트—이 인프라를 다른 도구에서 바닥부터 만드는 건 시간 낭비다.\n각자 잘하는 걸 맡겼다.\nDataHub Glossary → 용어 정의와 기본 관계의 원천 (Source of Truth) DozerDB → 세분화된 관계, 속성 달린 엣지, 그래프 추론 담당 DozerDB를 고른 건 Cypher 쿼리를 쓸 수 있어서다. 관계(엣지)에 속성을 자유롭게 붙일 수 있고, 관계 유형을 추가할 때 스키마 변경이나 재배포가 필요 없다.\n동기화 흐름은 단순하다. DataHub에서 Glossary Term이 바뀌면 Kafka MCL 이벤트가 나간다. 이벤트를 구독하는 Consumer가 DozerDB 온톨로지 그래프에 반영한다. 이름이나 정의 같은 기본 정보는 DataHub가 쥐고 있고, DozerDB는 그 위에 세분화된 관계와 속성을 얹는다.\nDozerDB에서의 관계 정의 아까 문제됐던 \u0026ldquo;공장-제품\u0026rdquo; 관계가 DozerDB에서는 이렇게 풀린다.\n// 엔티티 생성 (DataHub에서 동기화된 용어) CREATE (factory:Entity {name: \u0026#39;A공장\u0026#39;, type: \u0026#39;Factory\u0026#39;}) CREATE (product:Entity {name: \u0026#39;B제품\u0026#39;, type: \u0026#39;Product\u0026#39;}) // 생산 관계 — 시작 시점과 신뢰도를 속성으로 기록 CREATE (factory)-[:MANUFACTURES { since: \u0026#39;2024-01-01\u0026#39;, confidence: 0.95 }]-\u0026gt;(product) // 재고 관계 — 별도 엣지, 수량과 갱신 시점 CREATE (factory)-[:STOCKS { quantity: 500, last_updated: \u0026#39;2026-02-01\u0026#39; }]-\u0026gt;(product) MANUFACTURES와 STOCKS가 별개의 관계 유형이다. \u0026ldquo;A 공장에서 생산된 제품\u0026quot;이라는 질문이 오면 엔진이 MANUFACTURES를 찾아서 production 테이블로 정확히 JOIN한다. RelatedTo 하나로 퉁치던 것과는 근본적으로 다르다.\n파생 지표도 그래프에 넣었다 파생 지표 정의를 Excel로 관리하면 원본 용어가 바뀔 때 파생 시트가 안 따라간다. \u0026ldquo;순매출 = 총매출 - 반품 - 에누리\u0026quot;에서 총매출 정의가 바뀌었는데 순매출 쪽은 그대로—이런 불일치가 리포트까지 올라간다.\n이번에는 CALCULATED_FROM 관계로 계산식 자체를 그래프에 넣었다.\n// 순매출의 계산 구조를 관계로 표현 MATCH (net:Entity {name: \u0026#39;순매출\u0026#39;}) MATCH (gross:Entity {name: \u0026#39;총매출\u0026#39;}) MATCH (returns:Entity {name: \u0026#39;반품\u0026#39;}) MATCH (discounts:Entity {name: \u0026#39;에누리\u0026#39;}) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(gross) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(returns) CREATE (net)-[:CALCULATED_FROM {operator: \u0026#39;subtract\u0026#39;}]-\u0026gt;(discounts) 계산식이 바뀌면 관계를 수정한다. 변경 이력은 그래프 DB가 추적한다. Excel 시트 어딘가에 묻혀서 누가 언제 고쳤는지 모르는 것보다 낫다.\nSource of Truth가 깨진 건 아닌가 여기서 한 가지 짚고 넘어갈 게 있다.\n1편에서 메타데이터 카탈로그를 \u0026ldquo;온톨로지의 원천(Source of Truth)\u0026ldquo;이라고 썼다. 2편에서도 DataHub Glossary의 관계 4종이면 충분하다고 봤다. 그런데 3편에 와서 DozerDB를 추가했다. \u0026ldquo;그러면 Source of Truth가 두 개가 된 거 아닌가?\u0026rdquo; 당연한 질문이다.\n답부터 말하면, SoT의 대상이 달라진 거다.\nSoT라는 개념은 \u0026ldquo;모든 것을 하나의 시스템에 넣는다\u0026quot;가 아니다. \u0026ldquo;특정 데이터 카테고리에 대해 어디가 최종 권위를 가지느냐\u0026quot;를 정하는 거다. DataHub와 DozerDB는 서로 다른 질문에 답한다.\n\u0026ldquo;순매출이 뭐야?\u0026rdquo; → DataHub가 답한다. 이름, 정의, 동의어, 소유 부서. 용어의 정체성에 관한 건 DataHub가 최종 권위다. \u0026ldquo;순매출이 어떤 테이블과 어떤 경로로 연결되어 있어?\u0026rdquo; → DozerDB가 답한다. CALCULATED_FROM, MANUFACTURES 같은 세분화된 관계, 신뢰도, 유효 기간. 용어 간 연결의 의미론은 DozerDB가 쥐고 있다. 둘 사이에 충돌이 생기면? DataHub가 이긴다. DozerDB의 노드 이름이나 정의가 DataHub Glossary와 다르면 DataHub 쪽이 정답이다. Kafka MCL 이벤트가 이 방향으로만 흐른다 — DataHub → DozerDB. 역방향 동기화는 없다.\n처음부터 이 구분을 명확히 했어야 한다. 1편에서 \u0026ldquo;온톨로지의 원천\u0026quot;이라고 쓸 때, 실제로는 \u0026ldquo;용어 정의의 원천\u0026quot;이라고 써야 했다. 용어 정의와 관계 의미론을 하나의 시스템이 전부 감당할 수 있을 거라는 초기 가정이 틀렸다. 3편에서 그게 드러난 거고, DataHub + DozerDB 이중 구조는 그 결과다.\nSoT가 깨진 게 아니라 SoT의 범위가 좁아진 것이다.\n남은 문제: 표준 호환 DataHub Glossary 모델은 DataHub만의 구조다. 업계에는 FIBO(금융), Schema.org(범용) 같은 표준 온톨로지가 있다. 산업 표준을 가져오거나 DataNexus 온톨로지를 밖으로 내보내려면 표준 포맷을 지원해야 하는데, 지금 구조로는 DataNexus 안에서만 통하는 독자 체계다.\n외부 상호운용성 없는 온톨로지는 쓰임이 제한된다.\n다음 글에서 SKOS 호환 레이어를 왜 넣었는지 다룬다.\nGoogle Colab에서 실습하기\rDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/003-datahub-glossary-as-ontology/","summary":"DataHub의 Business Glossary를 온톨로지 저장소로 쓰려고 했다. 되는 것과 안 되는 것, 그리고 우회한 방법.","title":"3. DataHub Glossary를 온톨로지로 쓸 수 있을까"},{"content":"비교 후보군 후보가 너무 많았다.\n메타데이터 카탈로그만 해도 DataHub, Amundsen, Apache Atlas, OpenMetadata. 상용까지 포함하면 Collibra, Alation도 있다. NL2SQL 엔진, 문서 지식엔진, 그래프 DB까지 네 축을 채워야 하는데 조합이 기하급수적으로 불어났다.\n엑셀 시트에 비교표를 만들었다. 행이 후보 도구, 열이 평가 기준. 3주쯤 지나니까 탭이 7개로 늘어나 있었다. 선택지가 많으면 안 고르는 게 문제다. 하나를 고르면 나머지와의 조합이 바뀌고, 다시 처음부터 비교해야 한다.\n네 가지 컴포넌트, 각각의 요건 이전 글에서 DataNexus의 네 가지 컴포넌트를 정의했다. 메타데이터 카탈로그, NL2SQL 엔진, 문서 지식엔진, 그래프 DB.\n양보할 수 없는 공통 기준이 세 가지 있었다. 오픈소스일 것. 멀티테넌시를 지원하거나 구현 가능할 것 — 그룹사별 데이터 격리는 필수다. 프로덕션 레디일 것 — 커뮤니티 활성도, 릴리즈 주기, 문서화 수준까지 봤다.\n컴포넌트마다 추가 요건도 달랐다. 메타데이터 카탈로그는 Business Glossary에서 용어 간 관계를 정의할 수 있어야 하고, 변경 이벤트를 실시간으로 내보낼 수 있어야 했다. NL2SQL 엔진 쪽은 사용자별 컨텍스트 분리와 Row-level Security. 문서 지식엔진은 벡터 검색만으로 안 되고 그래프 검색까지 하이브리드로 돌려야 했다. 그래프 DB는 Multi-DB와 Cypher 쿼리 지원이 전제였다.\n이 기준을 들고 후보를 걸렀다.\n메타데이터 카탈로그 DataHub, OpenMetadata, Amundsen, Apache Atlas, 상용(Collibra/Alation). 다섯을 놓고 봤다.\n상용은 먼저 빠졌다. 라이선스 비용도 문제지만 이 프로젝트에서 필요한 건 카탈로그의 Glossary를 온톨로지 저장소처럼 쓰는 거다. 상용 Glossary가 강력하긴 한데 내부 데이터 모델에 접근해서 커스터마이징하는 데 한계가 있다.\nApache Atlas는 Hadoop 생태계에 묶여 있다. HBase, Solr, Kafka를 전부 띄워야 한다. 2016년 설계 그대로인데 클라우드 네이티브 환경에서 돌리기엔 무겁다. Amundsen은 검색 중심 카탈로그로는 괜찮은데 Glossary에서 용어 간 관계를 정의하는 기능이 빈약하다. 온톨로지 저장소로 쓸 수 없었다.\n끝까지 고민한 건 OpenMetadata다. 아키텍처가 깔끔하고 데이터 품질 측정이 내장돼 있어서 단독 카탈로그로는 훌륭했다. 문제는 Glossary 관계가 Parent-Child와 RelatedTerms 위주라는 점. 상속(IsA)과 포함(HasA)을 명확히 구분해야 하는 온톨로지 표현에는 모자랐다. 실시간 이벤트 동기화도 웹훅 방식이라 대규모 스트리밍에서 Kafka 네이티브 대비 신뢰성이 떨어졌다.\nDataHub를 고른 이유는 명확하다.\nGlossary 관계가 4종이다. IsA(상속), HasA(포함), Values(값 목록), RelatedTo(일반 연관). 이 네 가지면 비즈니스 용어 간 계층을 표현할 수 있다. \u0026ldquo;순매출 IsA 매출\u0026rdquo;, \u0026ldquo;매출 HasA 총매출, 반품, 에누리\u0026rdquo; 같은 식이다.\nGraphQL API도 한몫했다. 메타데이터를 프로그래밍 방식으로 읽고 쓸 수 있어야 NL2SQL 엔진의 RAG Store에 온톨로지를 자동 동기화하는데, GraphQL이면 필요한 필드만 골라서 가져온다.\n결정적이었던 건 Kafka MCL 이벤트다. Metadata Change Log를 Kafka로 내보내는 구조인데, Glossary Term이 바뀌면 이벤트가 발행된다. 이걸 구독해서 그래프 DB 온톨로지를 실시간 동기화할 수 있다. 메타데이터 변경을 수동으로 반영하는 건 규모가 커질수록 반드시 누락이 생긴다. 양보할 수 없는 요건이었다.\nNL2SQL 엔진 처음에는 직접 만들까 생각했다. 대화형 BI 솔루션을 구축하면서 NL2SQL에 GPT와 Gemini를 붙이고, 프롬프트 엔지니어링을 최적화하고, 멀티에이전트 아키텍처까지 설계하는 데까지 갔었다.\n거기서 배운 게 두 가지다. DDL만으로는 LLM이 비즈니스 맥락을 이해할 수 없다는 것. 그리고 처음부터 만들면 사용자 인증, 쿼리 로깅, 데이터 필터링, 응답 스트리밍, 쿼리 학습까지 부수 기능이 한없이 불어난다는 것. 견적을 내보니 1개월 넘게 잡아먹힐 판이었다.\n그때 Vanna가 2.0으로 올라왔다.\n1.x는 단순했다. Python 클래스 하나 상속받아서 train(), ask() 호출하는 방식. 프로토타이핑엔 괜찮은데 프로덕션에 넣기엔 부족했다. 사용자별 컨텍스트 분리도 안 되고 보안 기능도 없었다.\n2.0은 다른 물건이다. Agent 기반 아키텍처로 바뀌면서 독립적인 구성 요소를 조합하는 방식이 됐고, 모든 컴포넌트에 사용자 ID가 자동 전파되는 User-Aware 구조가 들어갔다. Row-level Security가 프레임워크 수준에서 지원된다. 성공한 쿼리를 자동 학습하는 Tool Memory도 내장. 테이블이나 차트 같은 Rich UI Component를 실시간 전송하는 Streaming까지 갖췄다.\nUser-Aware와 Row-level Security가 가장 중요했다. DataNexus는 그룹사별로 데이터를 격리해야 하는데 NL2SQL 엔진 레벨에서 이걸 지원한다는 건 직접 구현할 코드가 대폭 줄어든다는 뜻이다.\nTool Memory도 컸다. NL2SQL 정확도를 올리는 가장 확실한 방법 중 하나가 성공 쿼리를 축적해서 유사 질문에 재활용하는 건데 이게 프레임워크에 내장돼 있다. 별도로 만들면 쿼리 저장, 유사도 매칭, 버전 관리까지 만져야 하는데 그 공수가 통째로 빠진다.\n문서 지식엔진 벡터 검색만으로는 부족하다.\n사업보고서나 내부 정책문서를 검색할 때 벡터 유사도만으로 청크를 가져오면 맥락이 끊긴다. \u0026ldquo;A사업부의 매출 인식 기준\u0026quot;을 찾고 싶은데 벡터 검색은 \u0026ldquo;매출\u0026quot;이 포함된 청크를 유사도 순으로 나열할 뿐이다. A사업부와 매출 인식 기준의 관계라든가, 기준이 언제 바뀌었는지 같은 그래프 구조 정보는 벡터에 안 담긴다.\nApeRAG는 세 가지 검색을 조합해서 이 문제를 푼다. 임베딩 기반 의미 검색인 Vector Search, 고유명사나 코드명처럼 문자열 자체가 중요한 Full-text Search, 문서에서 추출한 엔티티 간 관계를 그래프로 탐색하는 GraphRAG. 이 셋을 동시에 돌린다.\n이 하이브리드가 DataNexus와 특히 잘 맞는 이유가 있다. DataHub의 Glossary Term을 ApeRAG Entity Extraction의 Taxonomy로 주입하면 문서에서 추출된 엔티티가 자동으로 비즈니스 용어와 연결된다. Exact Match → Synonym Match → Fuzzy Match(임계값 0.85) → Context Match, 4단계 Entity Resolution을 거친다.\nMinerU 통합도 빠뜨릴 수 없다. 엔터프라이즈 문서에는 복잡한 테이블, 수식, 다단 레이아웃이 흔한데 일반 PDF 파서로는 테이블 행/열이 깨진다. 특히 사업보고서처럼 테이블 안에 병합 셀이 난무하는 문서는 파싱 결과가 처참하다. MinerU는 문서 구조를 보존하면서 파싱하기 때문에 이 문제를 정면으로 해결한다.\n그래프 DB 가장 큰 변수는 Neo4j 라이선스였다.\nCommunity Edition과 Enterprise Edition의 결정적 차이는 Multi-DB다. Community는 인스턴스 하나에 그래프 하나. Enterprise는 같은 인스턴스 안에서 여러 데이터베이스를 만들 수 있다.\nDataNexus에서 Multi-DB는 필수다. 그룹사별로 온톨로지 그래프를 격리해야 한다. groupA_ontology_db, groupB_ontology_db처럼 테넌트별 데이터베이스를 분리하고 사용자 권한으로 접근을 제어하는 구조. Community 단일 DB에 전부 넣고 라벨로 구분하는 건 보안상 말이 안 된다.\n그렇다고 Neo4j Enterprise 라이선스를 살 수는 없다. 오픈소스 프로젝트의 원칙에 어긋난다.\nDozerDB가 이 딜레마를 풀었다. Neo4j Community Edition 위에 Enterprise 기능을 얹는 오픈소스 플러그인인데 Multi-DB를 지원한다. CREATE DATABASE로 테넌트별 그래프를 만들 수 있고, Cypher 쿼리도 그대로 쓴다.\nArangoDB도 봤다. 멀티모델(문서 + 그래프 + 키밸류)이 매력적인데 Cypher를 쓸 수 없다. 자체 쿼리 언어 AQL이 그래프 탐색에는 괜찮지만 Neo4j 생태계의 라이브러리나 도구를 못 쓰게 된다. 온톨로지를 Cypher로 질의하는 패턴과 레퍼런스가 압도적으로 많기 때문에 생태계 호환성을 택했다.\nDozerDB의 한계도 안다. Fabric — 크로스 DB 쿼리 — 은 아직 미지원이라 서로 다른 데이터베이스를 한 번의 Cypher로 질의하는 건 불가능하다. Phase 3 이후로 미뤘다. 당장은 단일 테넌트 내 질의만으로 충분하다.\n네 개를 연결하면 네 가지를 나란히 놓으면 도구 네 개다. 연결해야 파이프라인이 된다.\nDataHub에서 Glossary Term이 바뀌면 Kafka MCL 이벤트가 발행된다. 이 이벤트가 DozerDB 온톨로지 그래프에 실시간 반영되고, 동시에 Vanna의 RAG Store에도 들어간다. NL2SQL 프롬프트에 주입되는 맥락이 자동 갱신되는 셈이다. ApeRAG의 Entity Extraction은 DataHub Glossary를 Taxonomy로 참조하니까 문서 검색 결과도 최신 용어 체계에 연결된다.\n한 곳에서 용어를 고치면 네 군데가 동시에 바뀐다. 메타데이터 변경을 수동으로 전파하는 방식은 규모가 커질수록 반드시 어딘가 누락된다. 이 파이프라인이 그 문제를 막는다.\n다음 글 DataHub의 Business Glossary를 온톨로지로 쓸 때의 한계와 우회를 다룬다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/002-architecture-decisions/","summary":"DataNexus의 기술 스택을 DataHub + Vanna + ApeRAG + DozerDB로 결정한 과정. 후보군에서 탈락한 것들과 그 이유.","title":"2. 4개의 오픈소스를 이 조합으로 결정하기까지"},{"content":"\u0026ldquo;VIP 기준이 뭐죠?\u0026rdquo; 유통사 BI Agent 프로젝트에서 있었던 일이다.\n현업 담당자가 테스트 중에 Agent에게 물었다. \u0026ldquo;지난달 VIP 고객 매출 알려줘.\u0026rdquo; 시스템이 숫자를 뱉어냈는데, 담당자 표정이 좋지 않았다. \u0026ldquo;이거 뭔가 이상한데요. VIP 기준이 우리 팀이랑 다른 것 같아요.\u0026rdquo;\n마케팅의 VIP와 CRM의 VIP가 달랐다. 매출도 마찬가지. 순매출이냐 총매출이냐에 따라 수억 단위로 차이가 난다.\n처음 겪는 문제가 아니었다. DW를 클라우드로 옮기는 프로젝트에서도 봤고, 차세대 정보계를 여러 벤더와 1년 넘게 만들 때도 똑같았다. 벤더마다 \u0026ldquo;매출\u0026rdquo;, \u0026ldquo;원가\u0026quot;의 기준이 달라서 데이터 정합성 잡느라 몇 주씩 지연됐다. 용어 하나 안 맞으면 전체 일정이 밀린다. DW/BI 프로젝트를 하면서 이 문제가 안 나온 적이 없다.\n엔터프라이즈 DW에는 테이블과 컬럼이 있다. 없는 건 맥락이다. \u0026ldquo;이 컬럼이 비즈니스에서 뭘 의미하는지\u0026quot;가 기계가 읽을 수 있는 형태로 어디에도 정의되어 있지 않다.\n그래서 직접 만들기로 했다.\nNL2SQL은 만능이 아니다 요즘 NL2SQL 도구가 많다. 자연어를 SQL로 바꿔주는 것 자체는 이미 된다.\n실환경에 붙여보면 얘기가 달라진다. 유통사 프로젝트에서 벤치마크 점수가 높은 모델을 실제 DW에 연결하니까 체감 정확도가 확 떨어졌다. 카드사·통신사·공공데이터까지 내외부 데이터를 통합해 놓은 환경이었다. LLM이 이 복잡도(테이블 구조와 질문의 난이도)를 감당하지 못했다.\nDW의 DDL을 열어보면 원인이 보인다. T_CUST_MST.CUST_GRD_CD, T_ORD_DTL.SALE_AMT 같은 약어 테이블이 수천 개다. 벤치마크 DB의 customer_name, order_date와는 차원이 다르다. 같은 회사인데도 사업부마다 테이블 네이밍 규칙이 다르고, \u0026ldquo;매출\u0026quot;이라는 단어 하나가 사업부마다 다른 테이블을 가리킨다.\n파생 지표는 더 골치다. \u0026ldquo;순매출\u0026quot;은 단일 컬럼이 아니다. SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT) 같은 계산식인데, 이 공식은 어떤 DDL에도 안 적혀 있다. 현업 머릿속에 있거나, 잘해야 누군가의 Excel 정의서 어딘가에 묻혀 있다.\nNL2SQL의 병목은 SQL 생성 능력이 아니다. 맥락이 없다.\n온톨로지라는 선택 대화형 BI에서 프롬프트 엔지니어링을 아무리 최적화해도 DDL만으로는 한계가 뚜렷했다. 멀티에이전트 아키텍처도 설계해 봤는데, 근본 문제는 같았다. LLM에게 줄 맥락 자체가 없다.\n온톨로지를 붙이기로 했다.\n거창한 얘기가 아니다. 실용적으로 보면 이런 것이다:\n# 순매출 용어 정의 - term: 순매출 definition: 총매출에서 반품과 에누리를 차감한 금액 formula: SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT) synonyms: [Net Sales, 순매출액, 넷세일즈] related_tables: [T_SALE_DTL, T_RTN_DTL] owner: 재무팀 이런 용어 정의를 메타데이터 카탈로그에 등록하고, NL2SQL 엔진의 RAG Store에 자동 동기화한다. LLM이 \u0026ldquo;순매출\u0026quot;이라는 단어를 봤을 때 어떤 테이블의 어떤 컬럼을 어떤 계산식으로 조합해야 하는지 알게 되는 구조다.\n처리 흐름은 이렇다:\n온톨로지 적용 전후 차이 — 내부 목표치가 EX(Execution Accuracy) 기준 +15~20%p 향상이다. MVP에서 EX 80% 이상, 안정화 단계에서 90% 이상. 현실적인 수치인지는 만들어 보면서 검증한다.\nDDL 붙여넣기로는 안 되는 이유 엔터프라이즈 DW의 DDL을 다 붙여넣으면 수만수십만 토큰이다. 테이블이 수백수천 개인 환경에서는 컨텍스트 윈도우에 다 못 넣는다. 넣더라도 LLM이 그 안에서 정확한 테이블을 골라내는 건 Needle-in-a-Haystack 문제다.\n보안도 걸린다. 기업 내부 스키마를 외부 API에 통째로 보낼 수 없다. 같은 \u0026ldquo;매출\u0026quot;이라도 A그룹사 사용자와 B그룹사 사용자가 봐야 하는 범위가 다르다. Row-level Security가 필요한 환경이다.\n가장 큰 문제는 지속성이다. DDL은 바뀐다. 비즈니스 용어 정의도 바뀐다. 차세대 정보계를 오픈하고 나서도 단계별 릴리즈가 이어지면 매번 메타데이터가 바뀐다. 일회성 프롬프트가 아니라, 변경을 감지해서 자동으로 RAG Store를 갱신하는 파이프라인이 필요하다.\n따로 플랫폼을 만들어야겠다고 생각했다.\nDataNexus가 하려는 것 네 가지 컴포넌트로 구성된다.\n메타데이터 카탈로그 — 비즈니스 용어 정의, 테이블 메타, 데이터 계보를 한 곳에서 관리한다. 온톨로지의 원천(Source of Truth). NL2SQL 엔진 — 자연어를 SQL로 변환하되, 온톨로지에서 가져온 맥락을 프롬프트에 주입한다. DDL만 던져주는 방식과 정확도 차이가 확 난다. 문서 지식엔진 — 사업보고서, 정책문서 같은 비정형 데이터를 GraphRAG + 벡터 하이브리드로 검색한다. 그래프 DB — 온톨로지를 지식 그래프로 저장한다. 그룹사별 Multi-DB 격리까지. 카탈로그에서 정의한 온톨로지가 NL2SQL과 문서검색에 자동 동기화되어, 사용자의 자연어 질문에 맥락을 입혀주는 구조다. 각 컴포넌트에 사용한 오픈소스와 선정 이유는 다음 글에서 다룬다.\n왜 지금인가 LLM이 나오면서 판이 바뀌었다. 범용 모델은 빠르게 좋아지고 있고, 단순 기획이나 문서 생성은 곧 commodity가 된다. 차이를 만들려면 기업 데이터의 맥락을 구조화해서 모델에 주입할 수 있는 시스템이 있어야 한다.\n우리 회사의 \u0026ldquo;순매출\u0026rdquo; 정의가 뭔지, LLM이 아무리 똑똑해져도 모른다. 기업 내부에만 있는 지식이기 때문이다.\n이건 LLM 연구에서 말하는 \u0026ldquo;Non-verifiable Domain\u0026rdquo; 에 해당한다. 수학이나 코딩은 정답을 자동 검증할 수 있지만 기업 내부의 암묵적 지식, 역할별 해석 차이, 비공개 운영 데이터는 그렇지 않다. 외부에서 즉시 판별하기 어려운 영역. 이런 데이터 위에 쌓는 경쟁 우위를 AI 전략에서는 \u0026ldquo;Data Moat\u0026rdquo; 라고 부른다.\n이 우위가 영구적이라고는 생각하지 않는다. 범용 모델의 일반화 속도를 DataNexus의 데이터 축적 속도가 앞서야 한다. 시간이 중요하다.\nData Moat를 쌓는 방법은 이렇다:\n온톨로지 기반 맥락 — 도메인 전문가가 용어를 정제할수록 두꺼워지는 메타데이터 카탈로그 역할별 해석 — 같은 질문이라도 재무팀과 마케팅팀에 다른 응답을 주는 페르소나 최적화. 사용 패턴이 쌓일수록 개인화된다. 시간축 지식 그래프 — Temporal Knowledge Graph로 \u0026ldquo;작년 4분기 기준 VIP 정의\u0026quot;와 \u0026ldquo;올해 기준 VIP 정의\u0026quot;를 구분 비공개 데이터 자산 — 그룹사별 그래프 DB 격리 + Row-level Security. 각 그룹사의 데이터가 독립 자산이 된다. 올해 상반기까지 MVP를 내고 데이터 축적 루프를 돌리는 게 목표다.\n이 블로그의 목적 DataNexus를 만들면서 부딪히는 의사결정, 삽질, 해결 과정을 기록한다.\n다룰 것들:\n기술 스택을 선정한 과정 (후보군 탈락 사유 포함) 메타데이터 카탈로그의 Business Glossary를 온톨로지로 쓸 때의 한계와 우회 SKOS 호환 레이어를 넣은 이유 NL2SQL 엔진의 User-Aware 설계와 Row-level Security CQ(Competency Questions)로 온톨로지를 사전 검증하는 법 Query Router에서 결정론적 vs 확률론적 라우팅을 나누는 기준 에이전트 태스크를 쪼개는 79% Rule 이론보다는 실제로 부딪힌 문제와 그걸 어떻게 풀었는지 (또는 아직 못 풀었는지)를 쓸 예정이다.\n다음 글 DataNexus의 기술 스택 — 4개의 오픈소스를 이 조합으로 결정하기까지의 과정. 후보군에서 탈락한 것들과 그 이유를 정리한다.\nDataNexus를 설계하고 구축하는 과정을 기록합니다. GitHub | LinkedIn\n","permalink":"https://biz-agentic-ai.github.io/posts/datanexus/001-why-datanexus/","summary":"\u003ch2 id=\"vip-기준이-뭐죠\"\u003e\u0026ldquo;VIP 기준이 뭐죠?\u0026rdquo;\u003c/h2\u003e\n\u003cp\u003e유통사 BI Agent 프로젝트에서 있었던 일이다.\u003c/p\u003e\n\u003cp\u003e현업 담당자가 테스트 중에 Agent에게 물었다. \u0026ldquo;지난달 VIP 고객 매출 알려줘.\u0026rdquo; 시스템이 숫자를 뱉어냈는데, 담당자 표정이 좋지 않았다. \u0026ldquo;이거 뭔가 이상한데요. VIP 기준이 우리 팀이랑 다른 것 같아요.\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e마케팅의 VIP와 CRM의 VIP가 달랐다. 매출도 마찬가지. 순매출이냐 총매출이냐에 따라 수억 단위로 차이가 난다.\u003c/p\u003e\n\u003cp\u003e처음 겪는 문제가 아니었다. DW를 클라우드로 옮기는 프로젝트에서도 봤고, 차세대 정보계를 여러 벤더와 1년 넘게 만들 때도 똑같았다. 벤더마다 \u0026ldquo;매출\u0026rdquo;, \u0026ldquo;원가\u0026quot;의 기준이 달라서 데이터 정합성 잡느라 몇 주씩 지연됐다. 용어 하나 안 맞으면 전체 일정이 밀린다. DW/BI 프로젝트를 하면서 이 문제가 안 나온 적이 없다.\u003c/p\u003e","title":"1. 왜 DataNexus를 만드는가"},{"content":"Junho Lee (이준호) Data \u0026amp; AI Platform Architect | PM\nDW/BI 현장에서 대규모 DW 클라우드 전환부터 차세대 정보계 구축까지 설계하고 리드해왔습니다. Web/ERP 개발자로 시작해서 DW/BI 엔지니어, Technical Lead, 컨설팅 본부장을 거쳤고, 지금은 온톨로지 기반 AI 데이터 플랫폼을 만들고 있습니다.\n경력 요약 커리어 전반부는 엔터프라이즈 DW/BI에 집중했습니다. 대용량 DW의 클라우드 전환을 Tech Leader로 수행했고, 차세대 정보계 프로젝트를 멀티벤더 PMO로 운영했습니다. 소매·통신·제조·건설 등 산업 도메인을 가리지 않고 프로젝트를 수행해왔습니다.\n컨설팅 조직을 빌딩한 경험도 있습니다. 소수로 시작한 팀을 20명 규모까지 키우고, 매출도 수배 이상 성장시켰습니다. 채용, 교육, 기술 조직 운영, Presales, C레벨 대상 세미나까지 - 기술만 하는 사람은 아닙니다.\n최근에는 데이터와 AI의 접점에서 일하고 있습니다. LLM 기반 BI Agent를 구축하면서 NL2SQL의 실환경 한계를 경험했고, 그 과정에서 온톨로지 접근의 필요성을 확신하게 됐습니다. 지금은 DataNexus라는 통합 데이터 에이전트 플랫폼을 설계/구축 중입니다.\nDataNexus \u0026ldquo;Everyone is an Analyst.\u0026rdquo;\n엔터프라이즈 데이터 분석의 구조적 문제를 풀기 위한 플랫폼입니다. 자연어로 사내 데이터를 탐색하고 분석하는 AI 에이전트 — 말은 쉬운데, 실환경에서는 테이블명이 T_CUST_MST 같은 약어 투성이고, \u0026ldquo;순매출\u0026quot;이라는 단어 하나에도 부서마다 계산 로직이 다릅니다. DDL만으로는 LLM이 비즈니스 맥락을 이해할 수 없습니다.\nDataNexus는 온톨로지 기반 NL2SQL 엔진, GraphRAG, Data Catalog를 결합해서 이 문제를 풀어갑니다. 오픈소스를 조합한 아키텍처로, 비정형 문서와 정형 DB를 하나의 인터페이스로 다루는 구조입니다.\n이 블로그는 DataNexus를 만들어가는 과정을 기록합니다. 아키텍처 결정, 기술 선택의 이유, 삽질과 해결 과정을 있는 그대로 남깁니다.\n기술 영역 AI/ML — 온톨로지 LLM RAG, NL2SQL, Langchain, MCP, 멀티에이전트 시스템 설계 DW/Data Platform — Azure Synapse, BigQuery, Redshift, PostgreSQL, Oracle, Yellowbrick, Palantir Foundry BI — Power BI, Tableau, MicroStrategy, Qlik Sense, Looker, Superset ETL/ELT — ADF, SAP Data Services, IBM DataStage, Informatica, Databricks, SSIS Cloud — Azure (Synapse, ADF, ML), AWS (Redshift, S3, Glue), GCP (BigQuery, Gemini) Graph/Catalog — DataHub, Neo4j(DozerDB), ApeRAG Contact GitHub: @biz-agentic-ai LinkedIn: linkedin.com/in/leejuno ","permalink":"https://biz-agentic-ai.github.io/about/","summary":"이준호 - Data \u0026amp; AI Platform Architect","title":"About"}]