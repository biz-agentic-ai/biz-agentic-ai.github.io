---
title: "왜 DataNexus를 만드는가"
date: 2026-02-16
draft: false
summary: "엔터프라이즈 데이터 분석의 구조적 문제를 풀기 위해 온톨로지 기반 데이터 에이전트를 설계하기 시작한 이유."
categories: ["architecture"]
tags: ["datanexus", "ontology", "nl2sql", "graphrag"]
series: ["datanexus-building-log"]
series_order: 1
ShowToc: true
---

## 반복되는 장면

엔터프라이즈 데이터 조직이라면 어디서든 반복되는 장면이 있다.

현업이 "지난달 VIP 고객 매출이 얼마야?"라고 물으면, 분석가가 "VIP 기준이 뭐죠?"라고 되묻는다. 같은 회사인데 마케팅의 VIP와 CRM의 VIP가 다르다. 매출도 순매출인지 총매출인지에 따라 숫자가 달라진다. 결국 한 줄짜리 질문에 2~3일이 걸린다.

이건 특정 회사의 문제가 아니다. 54억 규모 차세대 정보계를 구축할 때도, 8억 규모 BI Agent를 만들 때도, 삼성전자 60TB DW를 클라우드로 마이그레이션할 때도 본질은 같았다. 테이블과 컬럼은 있는데, 그게 비즈니스에서 무슨 의미인지 기계가 읽을 수 있는 형태로 어디에도 정의되어 있지 않다.

이 문제를 풀기 위해 DataNexus를 만들기 시작했다.

## NL2SQL의 현실

요즘 NL2SQL 도구가 많다. 자연어를 SQL로 바꿔주는 것 자체는 이미 가능하다. 문제는 벤치마크 정확도와 실환경 정확도의 간극이다.

학술 벤치마크(Spider, BIRD 등)에서 80~90%를 찍는 도구들이, 실제 기업 DW에 넣으면 체감 40~50% 수준으로 떨어진다. 이유는 명확하다.

첫째, **테이블/컬럼명의 난독화**. 벤치마크 DB는 `customer_name`, `order_date`처럼 직관적이다. 실제 DW에는 `T_CUST_MST.CUST_GRD_CD`, `T_ORD_DTL.SALE_AMT` 같은 약어 테이블이 수백 개 있다. LLM이 DDL만 보고 이것들의 비즈니스 의미를 추론하는 건 불가능에 가깝다.

둘째, **파생 지표의 존재**. "순매출"은 단일 컬럼이 아니라 `SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT)` 같은 계산식이다. 이 계산식은 어떤 DDL에도 적혀 있지 않다. 현업 담당자의 머릿속에만 있거나, 잘해야 Excel 정의서 어딘가에 묻혀 있다.

셋째, **동일 용어의 다의성**. "고객"이 CRM에서는 회원 테이블, 물류에서는 거래처 테이블을 가리킨다. "매출"도 CMO가 보는 매출과 CFO가 보는 매출이 다른 테이블에서 나온다. Few-shot 예제 몇 개로는 이런 맥락을 커버할 수 없다.

결론적으로 NL2SQL의 병목은 SQL 생성 능력이 아니라 **맥락(Context)의 부재**다.

## 온톨로지라는 선택

이 맥락을 기계가 읽을 수 있는 형태로 구조화하는 것이 온톨로지다. 거창한 학술 개념이 아니라, 실용적으로 보면 이런 것이다:

```yaml
# 예시: 순매출 용어 정의
- term: 순매출
  definition: 총매출에서 반품과 에누리를 차감한 금액
  formula: SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT)
  synonyms: [Net Sales, 순매출액, 넷세일즈]
  related_tables: [T_SALE_DTL, T_RTN_DTL]
  owner: 재무팀
```

이걸 DataHub의 Business Glossary에 정의하고, NL2SQL 엔진(Vanna)의 RAG Store에 동기화하면, LLM이 "순매출"이라는 단어를 봤을 때 어떤 테이블의 어떤 컬럼을 어떤 계산식으로 조합해야 하는지 알 수 있다.

처리 흐름을 그리면 이렇다:

```
[사용자: "지난달 VIP 매출 알려줘"]
        │
        ▼
[Query Router: 질의 유형 분류]
        │
        ▼
[온톨로지 조회]
  ├─ VIP고객 → CUST_GRD_CD IN ('V1','V2')  (DataHub Glossary)
  ├─ 매출 → 순매출 = SUM(SALE_AMT) - SUM(RTN_AMT)  (formula 필드)
  └─ 지난달 → DATE_TRUNC('month', CURRENT_DATE - INTERVAL '1 month')
        │
        ▼
[Vanna: 온톨로지 컨텍스트를 포함한 SQL 생성]
        │
        ▼
[실행 → 결과 + 해석 반환]
```

온톨로지 없이 NL2SQL을 돌리는 것과, 온톨로지를 주입한 NL2SQL을 돌리는 것의 차이는 생각보다 크다. PRD에서 설정한 목표치는 온톨로지 미적용 대비 EX(Execution Accuracy) +15~20%p 향상이다. MVP 기준 EX 80% 이상, Phase 2에서 90% 이상을 목표로 잡았다.

## 왜 기존 도구로는 안 되는가

"그냥 ChatGPT에 DDL 붙여넣으면 되지 않나?"라는 질문을 자주 받는다. 안 되는 이유가 몇 가지 있다.

**컨텍스트 윈도우 한계.** 대기업 DW의 DDL을 다 붙여넣으면 수십만 토큰이다. 프롬프트에 다 넣을 수 없고, 넣더라도 LLM이 수백 개 테이블 중에서 정확한 것을 골라내는 건 Needle-in-a-Haystack 문제다.

**보안.** 기업 내부 데이터 스키마를 외부 API에 보낼 수 없다. Row-level Security도 필요하다. 같은 "매출" 질문이라도 A그룹사 사용자와 B그룹사 사용자가 봐야 하는 데이터 범위가 다르다.

**지속적 학습.** DDL은 바뀐다. 비즈니스 용어 정의도 바뀐다. 일회성 프롬프트가 아니라, 메타데이터 변경을 감지해서 자동으로 RAG Store를 갱신하는 파이프라인이 필요하다.

이런 요구사항을 종합하면, 결국 별도의 플랫폼이 필요하다는 결론에 도달한다. DataNexus는 이 결론에서 출발했다.

## DataNexus의 구조

DataNexus는 네 가지 오픈소스를 조합해서 만든다:

| 컴포넌트 | 역할 |
|----------|------|
| **DataHub** | 메타데이터 카탈로그. 비즈니스 용어(Glossary), 테이블 메타, 데이터 계보 관리 |
| **Vanna** | NL2SQL 엔진. 자연어 → SQL 변환, 온톨로지 컨텍스트 활용 |
| **ApeRAG** | 문서 기반 지식엔진. GraphRAG + 벡터 하이브리드 검색 |
| **DozerDB** | Neo4j에 엔터프라이즈 기능 추가. Multi-DB로 그룹사별 데이터 격리 |

이 조합에 도달하기까지 꽤 많은 후보를 검토하고 탈락시켰다. 그 과정은 다음 글에서 정리한다.

전체 구조를 한 줄로 요약하면: **DataHub에서 정의한 온톨로지가 Vanna와 ApeRAG에 자동 동기화되어, 사용자의 자연어 질문에 맥락을 입힌 정확한 응답을 만든다.**

```
┌─────────┐      ┌─────────┐      ┌─────────┐
│   DW    │      │  문서   │      │   BI    │
│ (정형)  │      │(비정형) │      │ 리포트  │
└────┬────┘      └────┬────┘      └────┬────┘
     │                │                │
     └────────────────┼────────────────┘
                      │
               ┌──────▼──────┐
               │  DataNexus  │  ← 연결점 (Nexus)
               └──────┬──────┘
                      │
         ┌────────────┼────────────┐
         │            │            │
    ┌────▼────┐  ┌────▼────┐  ┌────▼────┐
    │ 통합    │  │ 지식    │  │ AI      │
    │ 카탈로그│  │ 베이스  │  │ 인사이트│
    └─────────┘  └─────────┘  └─────────┘
```

## 방어선에 대한 생각

솔직히 말하면, 이 프로젝트에는 기술적 동기만 있는 게 아니다.

LLM이 빠르게 범용화되고 있다. Frontier Lab들이 Compute + RL Environment에 집중하면서, 모델 간 Agentic self-improvement가 본격화되면 외부 플레이어의 범용 업무 가치는 급격히 떨어질 수 있다. 단순 기획이나 문서 생성 같은 작업은 빠르게 commoditization될 가능성이 높다.

DataNexus가 노리는 영역은 **Non-verifiable Domain + Proprietary Data**다.

기업 내부의 암묵적 지식, 역할별 해석 차이(동일한 매출 데이터를 CMO와 PM이 다르게 해석하는 맥락), 비공개 운영 데이터, 시간축을 가진 조직 고유의 분석 패턴 — 이런 데이터는 공인된 외부 검증 절차로 즉시 판별하기 어렵다. 해당 도메인에서의 온톨로지 설계 역량, 신뢰 기반 관계, 내부 데이터 축적이 경쟁 우위가 된다.

이 우위가 영구적이라고 생각하지는 않는다. 범용 모델의 일반화 속도를 DataNexus의 데이터 축적 속도가 앞서야 한다. 그래서 시간이 중요하다.

| 방어선 요소 | 구현 | 축적 메커니즘 |
|------------|------|-------------|
| 온톨로지 기반 맥락 이해 | DataHub Glossary + SKOS 호환 | 도메인 전문가의 지속적 용어 정제 |
| 역할별 해석 차이 | Role-optimized Response (5개 페르소나) | 사용 패턴 기반 개인화 누적 |
| 시간축 지식 그래프 | Graphiti Temporal KG (Phase 3) | Episode 기반 실시간 지식 축적 |
| 비공개 운영 데이터 | DozerDB 격리 + Row-level Security | 그룹사별 독립 데이터 자산화 |

핵심은 **2026 Q1~Q2에 MVP를 선점하고, 데이터 축적 루프를 조기에 가동하는 것**이다. Phase 1.0 MVP가 Q2를 넘기면 축적 루프 가동이 늦어져서 방어선 구축 시간이 부족해진다. 그래서 이 일정은 Hard Deadline으로 관리하고 있다.

## 이 블로그의 목적

DataNexus를 만들어가면서 부딪히는 기술적 의사결정, 삽질, 해결 과정을 기록하려고 한다.

다룰 내용은 대략 이런 것들이다:
- 아키텍처 의사결정 과정 (왜 이 4개 오픈소스 조합인가)
- DataHub Glossary를 온톨로지로 쓸 때의 한계와 우회
- SKOS 호환 레이어를 넣은 이유
- Vanna 2.0의 User-Aware 설계와 Row-level Security
- CQ(Competency Questions)로 온톨로지를 사전 검증하는 방법
- Query Router에서 결정론적 vs 확률론적 라우팅을 나누는 기준
- 에이전트 태스크를 쪼개는 79% Rule

이론이나 개념 설명보다는, 실제로 부딪힌 문제와 그걸 어떻게 풀었는지(또는 아직 못 풀었는지)를 중심으로 쓸 예정이다.

## 다음 글

아키텍처를 구성하는 4개 오픈소스(DataHub, Vanna, ApeRAG, DozerDB)를 이 조합으로 결정하기까지의 과정을 정리한다. 후보군에서 탈락한 것들과 그 이유도 포함.

---

*이 시리즈는 DataNexus를 설계하고 구축하는 과정을 기록합니다. [GitHub](https://github.com/biz-agentic-ai) | [LinkedIn](https://www.linkedin.com/in/leejuno/)*
