---
title: "왜 DataNexus를 만드는가"
date: 2026-02-16
draft: false
summary: "엔터프라이즈 데이터 분석의 구조적 문제를 풀기 위해 온톨로지 기반 데이터 에이전트를 설계하기 시작한 이유."
categories: ["architecture"]
tags: ["datanexus", "ontology", "nl2sql", "graphrag"]
series: ["datanexus-building-log"]
series_order: 1
ShowToc: true
---

## "VIP 기준이 뭐죠?"

작년에 대형 유통사의 BI Agent 프로젝트를 하면서 있었던 일이다. 자연어 질의/응답 시스템을 만드는 게 목표였다.

현업 담당자가 테스트 중에 물었다. "지난달 VIP 고객 매출 알려줘." 시스템이 숫자를 뱉어냈다. 근데 담당자 표정이 좋지 않았다. "이거 뭔가 이상한데요. VIP 기준이 우리 팀이랑 다른 것 같아요."

확인해 보니 마케팅의 VIP와 CRM의 VIP가 달랐다. 매출도 문제였다. 순매출인지 총매출인지에 따라 숫자가 수억 단위로 차이가 났다.

이 장면은 이 프로젝트에서만 본 게 아니다.

대기업 제조사의 대용량 DW를 클라우드로 마이그레이션할 때도, 식품 계열사의 차세대 정보계를 다수 벤더와 1년 넘게 만들 때도 본질은 같았다. 차세대 정보계 프로젝트에서는 각 벤더가 정의하는 "매출"과 "원가"의 기준이 달라서, 데이터 정합성 맞추는 데만 상당한 시간을 날렸다. 수백 명이 투입된 프로젝트에서, 용어 정의 불일치가 만들어내는 비용은 생각보다 컸다.

데이터 조직에서 20년 가까이 일하면서 이 문제를 반복적으로 봤다. 테이블과 컬럼은 있다. 없는 건 맥락이다. "이 컬럼이 비즈니스에서 뭘 의미하는지"가 기계가 읽을 수 있는 형태로 어디에도 정의되어 있지 않다.

DataNexus는 이 문제에서 출발했다.

## NL2SQL은 만능이 아니다

요즘 NL2SQL 도구가 많다. 자연어를 SQL로 바꿔주는 것 자체는 이미 가능하다.

문제는 실환경에 넣으면 벌어지는 일이다. 유통사 프로젝트에서 직접 겪었다. 학술 벤치마크에서 좋은 점수를 받는 모델이, 실제 DW에 연결하면 체감 정확도가 확 떨어졌다. 카드사/통신사/공공데이터까지 내외부 데이터를 통합해 놓은 환경이었는데, LLM이 이 복잡도를 감당하지 못했다.

왜 그런지는 이전 프로젝트에서 이미 알고 있었다. 대기업 DW의 DDL을 열어보면 `T_CUST_MST.CUST_GRD_CD`, `T_ORD_DTL.SALE_AMT` 같은 약어 테이블이 수천 개다. 벤치마크 DB의 `customer_name`, `order_date`와는 차원이 다르다. 같은 회사인데 사업부마다 테이블 네이밍 규칙이 달랐다. "매출"이라는 단어 하나가 사업부마다 다른 테이블을 가리켰다.

파생 지표도 문제다. "순매출"은 단일 컬럼이 아니다. `SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT)` 같은 계산식인데, 이 공식은 어떤 DDL에도 안 적혀 있다. 현업 머릿속에 있거나, 잘해야 누군가의 Excel 정의서 어딘가에 묻혀 있다.

NL2SQL의 병목은 SQL 생성 능력이 아니다. 맥락의 부재다.

## 온톨로지라는 선택

별도로 대화형 BI 솔루션을 직접 만들면서 프롬프트 엔지니어링을 아무리 최적화해도 DDL만으로는 한계가 있다는 걸 확인했다. 멀티에이전트 아키텍처를 설계해 보기도 했지만, 근본적인 문제는 LLM에게 줄 맥락 자체가 없다는 것이었다.

그래서 온톨로지를 붙이기로 했다.

거창한 학술 개념은 아니다. 실용적으로 보면 이런 것이다:

```yaml
# 순매출 용어 정의
- term: 순매출
  definition: 총매출에서 반품과 에누리를 차감한 금액
  formula: SUM(SALE_AMT) - SUM(RTN_AMT) - SUM(DC_AMT)
  synonyms: [Net Sales, 순매출액, 넷세일즈]
  related_tables: [T_SALE_DTL, T_RTN_DTL]
  owner: 재무팀
```

이런 용어 정의를 메타데이터 카탈로그에 등록하고, NL2SQL 엔진의 RAG Store에 자동 동기화한다. 그러면 LLM이 "순매출"이라는 단어를 봤을 때 어떤 테이블의 어떤 컬럼을 어떤 계산식으로 조합해야 하는지 알 수 있다.

처리 흐름은 이렇다:

![DataNexus 질의 처리 흐름](/images/datanexus/query-flow.png)

온톨로지 적용 전후의 차이가 어느 정도냐면, 내부 목표치가 [EX(Execution Accuracy)](https://arxiv.org/abs/2407.04255) 기준 +15~20%p 향상이다. MVP에서 EX 80% 이상, 안정화 단계에서 90% 이상. 이 수치가 현실적인지는 만들어 보면서 검증할 생각이다.

## "ChatGPT에 DDL 붙여넣으면 되지 않나?"

자주 받는 질문이다. 안 된다.

대기업 DW의 DDL을 다 붙여넣으면 수십만 토큰이다. 내가 겪었던 프로젝트만 해도 테이블이 수천 개였다. 컨텍스트 윈도우에 다 못 넣고, 넣더라도 LLM이 그 안에서 정확한 테이블을 골라내는 건 [Needle-in-a-Haystack](https://arxiv.org/abs/2407.11963) 문제다.

보안도 있다. 기업 내부 스키마를 외부 API에 보낼 수 없다. Row-level Security 문제도 있다. 같은 "매출"이라도 A그룹사 사용자와 B그룹사 사용자가 봐야 하는 범위가 다르다.

지속성도 문제다. DDL은 바뀐다. 비즈니스 용어 정의도 바뀐다. 차세대 정보계 프로젝트에서 EIS 오픈 후에도 단계별 릴리즈를 계속했는데, 매번 메타데이터가 변경됐다. 일회성 프롬프트가 아니라 변경을 감지해서 자동으로 RAG Store를 갱신하는 파이프라인이 필요하다.

결국 별도의 플랫폼이 필요하다는 결론에 도달했다.

## DataNexus가 하려는 것

DataNexus는 네 가지 기능 축으로 구성된다.

![DataNexus 전체 구성도](/images/datanexus/architecture.png)

- **메타데이터 카탈로그** — 비즈니스 용어 정의, 테이블 메타, 데이터 계보를 한 곳에서 관리한다. 온톨로지의 원천(Source of Truth).
- **NL2SQL 엔진** — 자연어를 SQL로 변환하되, 온톨로지에서 가져온 맥락을 프롬프트에 주입해서 정확도를 높인다.
- **문서 지식엔진** — 사업보고서, 정책문서 같은 비정형 데이터를 GraphRAG + 벡터 하이브리드로 검색한다.
- **그래프 DB** — 온톨로지를 지식 그래프로 저장하고, 그룹사별 Multi-DB로 데이터를 격리한다.

한 줄로 요약하면: **카탈로그에서 정의한 온톨로지가 NL2SQL과 문서검색에 자동 동기화되어, 사용자의 자연어 질문에 맥락을 입혀준다.** 이 조합에 사용한 구체적인 오픈소스와 선정 이유는 다음 글에서 다룬다.

## 왜 지금인가

기술적 동기만으로 이 프로젝트를 시작한 건 아니다.

이전 직장에서 10년 넘게 DW/BI 컨설팅을 하면서 고객사 C레벨 대상 발표를 수십 회 했다. "왜 메타데이터가 중요한지" 설명하는 데 커리어의 상당 부분을 썼다. 팀을 직접 빌딩해서 키우고, 기술 조직을 이끌면서 느낀 건 — 이 문제가 사람의 설득만으로는 안 풀린다는 거였다. 시스템이 필요하다.

그런데 LLM이 나오면서 이 문제의 프레임이 바뀌었다.

범용 모델이 빠르게 좋아지고 있다. 단순 기획이나 문서 생성 같은 작업은 곧 commodity가 된다. 내가 쌓아온 "기업 데이터의 맥락을 이해하는 능력"이 가치를 유지하려면, 그 맥락을 구조화해서 기계에 주입하는 시스템이 있어야 한다.

DataNexus가 노리는 영역은 Non-verifiable Domain + Proprietary Data다. LLM 연구에서 [Non-verifiable Domain](https://openreview.net/forum?id=ki4pPq66KR)이란 수학이나 코딩처럼 정답을 자동 검증할 수 있는 영역(Verifiable)의 반대편 — 품질 평가가 주관적이고 외부에서 즉시 판별하기 어려운 영역을 말한다. 기업 내부의 암묵적 지식, 역할별 해석 차이, 비공개 운영 데이터, 시간축을 가진 조직 고유의 분석 패턴이 여기에 해당한다. 이런 데이터 위에 쌓는 경쟁 우위를 AI 전략에서는 [Data Moat](https://review.insignia.vc/2025/03/10/ai-moat/)라고 부른다 — 외부 모델이 접근할 수 없는 독점 데이터가 만드는 방어선이다.

이 우위가 영구적이라고는 생각하지 않는다. 범용 모델의 일반화 속도를 DataNexus의 데이터 축적 속도가 앞서야 한다. 그래서 시간이 중요하다. 올해 상반기까지 MVP를 내고 데이터 축적 루프를 돌리는 게 목표다.

| 방어선 요소 | 구현 방향 | 축적 방식 |
|------------|----------|----------|
| 온톨로지 기반 맥락 | 메타데이터 카탈로그 + SKOS 호환 | 도메인 전문가의 용어 정제 |
| 역할별 해석 차이 | 페르소나별 응답 최적화 | 사용 패턴 기반 개인화 |
| 시간축 지식 그래프 | Temporal Knowledge Graph | Episode 기반 실시간 축적 |
| 비공개 운영 데이터 | 그래프 DB 격리 + Row-level Security | 그룹사별 독립 자산화 |

## 이 블로그의 목적

DataNexus를 만들면서 부딪히는 의사결정, 삽질, 해결 과정을 기록한다.

다룰 것들:
- 기술 스택을 선정한 과정 (후보군 탈락 사유 포함)
- 메타데이터 카탈로그의 Business Glossary를 온톨로지로 쓸 때의 한계와 우회
- SKOS 호환 레이어를 넣은 이유
- NL2SQL 엔진의 User-Aware 설계와 Row-level Security
- CQ(Competency Questions)로 온톨로지를 사전 검증하는 법
- Query Router에서 결정론적 vs 확률론적 라우팅을 나누는 기준
- 에이전트 태스크를 쪼개는 79% Rule

이론보다는 실제로 부딪힌 문제와 그걸 어떻게 풀었는지(또는 아직 못 풀었는지)를 쓸 예정이다.

## 다음 글

DataNexus의 기술 스택 — 4개의 오픈소스를 이 조합으로 결정하기까지의 과정. 후보군에서 탈락한 것들과 그 이유를 정리한다.

---

*DataNexus를 설계하고 구축하는 과정을 기록합니다. [GitHub](https://github.com/biz-agentic-ai) | [LinkedIn](https://www.linkedin.com/in/leejuno/)*
